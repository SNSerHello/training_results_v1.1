+ : DGXA100_multi_8x8x51
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/resnetv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211105211403385305917
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data
+ : /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342
+ : ''
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ echo

+ '[' '!' -z ']'
+ LOGBASE=rsnt50_8x8x51_211105211403385305917
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _seed_override=
+ _seed_override=
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342/rsnt50_8x8x51_211105211403385305917
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342/rsnt50_8x8x51_211105211403385305917
+ readonly _cont_name=image_classification
+ _cont_name=image_classification
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data:/data,/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job10874/slurm_script: line 48: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342
+ srun --ntasks=8 mkdir -p /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342
+ srun --ntasks=8 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/resnetv11.sqsh --container-name=image_classification true
+ echo 'RUN_NCCL_BW_TEST = 0'
RUN_NCCL_BW_TEST = 0
+ [[ 0 -eq 1 ]]
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342/rsnt50_8x8x51_211105211403385305917_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ srun -N1 -n1 --container-name=image_classification python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.RESNET)'
:::MLLOG {"namespace": "", "time_ms": 1636146846755, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "resnet", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 70}}
:::MLLOG {"namespace": "", "time_ms": 1636146846762, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1636146846762, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 79}}
:::MLLOG {"namespace": "", "time_ms": 1636146846762, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 83}}
:::MLLOG {"namespace": "", "time_ms": 1636146846762, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 87}}
[1636146846.736353] [ip-0A0C0406:97187:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C0406
Clearing cache on ip-0A0C040D
Clearing cache on ip-0A0C040F
Clearing cache on ip-0A0C040A
Clearing cache on ip-0A0C0409
Clearing cache on ip-0A0C0407
Clearing cache on ip-0A0C0408
Clearing cache on ip-0A0C040C
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=image_classification python -c '
from mlperf_logging.mllog import constants
from mlperf_log_utils import mx_resnet_print_event
mx_resnet_print_event(key=constants.CACHE_CLEAR, val=True)'
:::MLLOG {"namespace": "", "time_ms": 1636146851788, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
[1636146851.627294] [ip-0A0C040D:94841:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146851.689082] [ip-0A0C040A:94601:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146851.720697] [ip-0A0C0408:95004:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146851.612180] [ip-0A0C0409:94062:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146851.533419] [ip-0A0C040C:94239:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146851.575904] [ip-0A0C040F:94898:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146851.765117] [ip-0A0C0407:94781:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146851.733889] [ip-0A0C0406:97702:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
+ export SEED=4405
+ SEED=4405
+ srun --kill-on-bad-exit=0 --mpi=pmix --ntasks=64 --ntasks-per-node=8 --container-name=image_classification --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data:/data,/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:14:13 PM
running benchmark
running benchmark
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 -+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 -dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
--dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
--dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 -+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
-dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 + exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
--dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 -num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
--dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 num_sockets = 2 num_nodes=4 cores_per_socket=48
--dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
-dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 4405 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
:::MLLOG {"namespace": "", "time_ms": 1636146858538, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858538, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858538, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858538, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858539, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858539, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858539, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858539, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858542, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858541, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858541, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858542, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858542, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858542, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858542, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858542, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858543, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858543, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858538, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858543, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858542, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858542, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858543, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858542, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858542, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858542, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858538, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858537, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858537, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858537, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858537, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858543, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858538, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858537, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858543, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858543, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858543, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858543, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858543, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858543, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858543, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146858545, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
[1636146858.212280] [ip-0A0C040C:95104:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.025037] [ip-0A0C040C:95106:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.230721] [ip-0A0C040C:95102:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.191646] [ip-0A0C040C:95103:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.151747] [ip-0A0C040C:95105:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.156136] [ip-0A0C040C:95108:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.249244] [ip-0A0C040C:95101:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.243903] [ip-0A0C040C:95107:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.381623] [ip-0A0C0409:94918:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.392095] [ip-0A0C0409:94925:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.366752] [ip-0A0C0408:95873:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.354134] [ip-0A0C0409:94922:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.337598] [ip-0A0C040A:95461:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.399773] [ip-0A0C0409:94917:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.343161] [ip-0A0C040A:95459:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.164738] [ip-0A0C040A:95457:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.391485] [ip-0A0C0409:94919:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.366654] [ip-0A0C0409:94923:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.202570] [ip-0A0C0409:94920:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.212597] [ip-0A0C0409:94921:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.123135] [ip-0A0C040A:95456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.353396] [ip-0A0C040A:95460:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.249793] [ip-0A0C040A:95462:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.353018] [ip-0A0C040A:95458:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.294679] [ip-0A0C040A:95455:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.356814] [ip-0A0C0408:95872:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.359285] [ip-0A0C0408:95870:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.340069] [ip-0A0C0408:95871:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.321178] [ip-0A0C0408:95869:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.212164] [ip-0A0C0408:95866:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.281628] [ip-0A0C0408:95867:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.142939] [ip-0A0C0408:95868:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.429319] [ip-0A0C040D:95698:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.214852] [ip-0A0C040D:95697:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.395068] [ip-0A0C040D:95695:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.151437] [ip-0A0C0406:816  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.301752] [ip-0A0C040D:95696:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.351965] [ip-0A0C0406:817  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.426183] [ip-0A0C040D:95694:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.353913] [ip-0A0C0406:818  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.343249] [ip-0A0C0406:819  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.250983] [ip-0A0C040D:95693:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.414451] [ip-0A0C040D:95699:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.385693] [ip-0A0C040D:95692:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.180723] [ip-0A0C0406:821  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
:::MLLOG {"namespace": "", "time_ms": 1636146871676, "event_type": "POINT_IN_TIME", "key": "seed", "value": 4405, "metadata": {"file": "train_imagenet.py", "lineno": 176}}
[1636146858.151259] [ip-0A0C0406:815  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.324113] [ip-0A0C0406:822  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.303421] [ip-0A0C0406:820  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.509342] [ip-0A0C0407:95649:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.460584] [ip-0A0C0407:95648:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.479638] [ip-0A0C0407:95646:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.519454] [ip-0A0C0407:95642:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.512755] [ip-0A0C0407:95645:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.464010] [ip-0A0C0407:95647:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.412304] [ip-0A0C0407:95650:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.296469] [ip-0A0C0407:95644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.425872] [ip-0A0C040F:95768:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.426428] [ip-0A0C040F:95760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.291591] [ip-0A0C040F:95761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.314068] [ip-0A0C040F:95767:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.432484] [ip-0A0C040F:95766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.331457] [ip-0A0C040F:95759:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.210253] [ip-0A0C040F:95779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146858.426034] [ip-0A0C040F:95764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:14:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
NCCL version 2.11.4+cuda11.4

ip-0A0C040F:95761:95960 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94919:95111 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95103:95302 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95694:95893 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95870:96064 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95647:95843 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95456:95652 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:821 - context.c:584] INFO job (ID: 867530475911844656) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:821 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:821 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:821:1015 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95107:95296 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95779:95957 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95695:95894 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95642:95842 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94923:95118 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95457:95651 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95872:96063 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:815 - context.c:584] INFO job (ID: 867530534695243646) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:815 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:815 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:815:1011 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95650:95845 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95105:95301 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95760:95959 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94921:95115 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95697:95890 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95868:96061 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95460:95653 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:816 - context.c:584] INFO job (ID: 867531265090883038) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:816 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:816 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:816:1018 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95767:95963 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94925:95113 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95693:95887 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95646:95841 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95102:95295 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95867:96066 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95458:95655 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:818 - context.c:584] INFO job (ID: 867531425496169131) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:818 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:818 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:818:1017 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95106:95298 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95759:95958 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95696:95889 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94917:95112 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95873:96067 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95455:95656 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95644:95844 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:817 - context.c:584] INFO job (ID: 867530740576331066) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:817 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:817 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:817:1016 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95101:95297 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95768:95956 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95692:95892 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94922:95117 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95648:95840 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95866:96062 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95462:95657 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:822 - context.c:584] INFO job (ID: 867530566207325541) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:822 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:822 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:822:1012 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95108:95299 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95764:95961 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95698:95891 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95649:95846 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95871:96065 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95461:95654 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94920:95114 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:820 - context.c:584] INFO job (ID: 867530811474881244) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:820 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:820 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:820:1014 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95104:95300 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95766:95962 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95699:95888 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95645:95839 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95869:96068 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95459:95650 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94918:95116 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95694:95893 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040C:95103:95302 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0407:95647:95843 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0408:95870:96064 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0409:94919:95111 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040A:95456:95652 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040F:95761:95960 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
[ip-0A0C0406:0:819 - context.c:584] INFO job (ID: 867531530817210238) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:819 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:819 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:819:1013 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0406:821:1015 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0407:95647:95843 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95761:95960 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95694:95893 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95870:96064 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94919:95111 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95456:95652 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95103:95302 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:821 - context.c:584] INFO job (ID: 867530477112444675) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:821 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:821 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:821:1015 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95779:95957 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95107:95296 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95695:95894 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94923:95118 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95872:96063 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95457:95651 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95642:95842 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:815 - context.c:584] INFO job (ID: 867530533571586800) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:815 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:815 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:815:1011 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94921:95115 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95105:95301 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95760:95959 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95697:95890 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95868:96061 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95460:95653 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95650:95845 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:816 - context.c:584] INFO job (ID: 867531265095604181) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:816 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:816 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:816:1018 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95767:95963 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94925:95113 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95693:95887 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95102:95295 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95867:96066 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95646:95841 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95458:95655 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:818 - context.c:584] INFO job (ID: 867531425874466222) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:818 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:818 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:818:1017 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94917:95112 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95759:95958 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95106:95298 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95696:95889 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95455:95656 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95873:96067 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95644:95844 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:817 - context.c:584] INFO job (ID: 867530740340242360) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:817 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:817 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:817:1016 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95101:95297 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95692:95892 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95462:95657 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95648:95840 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95768:95956 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94922:95117 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95866:96062 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:822 - context.c:584] INFO job (ID: 867530567541243891) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:822 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:822 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:822:1012 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95108:95299 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95764:95961 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94920:95114 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95698:95891 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95649:95846 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95461:95654 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95871:96065 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:820 - context.c:584] INFO job (ID: 867530812447442405) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:820 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:820 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:820:1014 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:95766:95962 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:95699:95888 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95459:95650 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:95645:95839 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:94918:95116 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:95869:96068 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:95104:95300 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:95456:95652 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040F:95761:95960 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040D:95694:95893 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0409:94919:95111 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040C:95103:95302 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0407:95647:95843 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0408:95870:96064 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
[ip-0A0C0406:0:819 - context.c:584] INFO job (ID: 867531530685922530) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:819 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:819 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:819:1013 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0406:821:1015 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
:::MLLOG {"namespace": "", "time_ms": 1636146945713, "event_type": "POINT_IN_TIME", "key": "model_bn_span", "value": 51, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 309}}
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1636146951900, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "bn0_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951901, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "bn0_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951901, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "conv0_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951901, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 81, "tensor": "fc1_bias"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951901, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 72, "tensor": "fc1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951902, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951902, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951902, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951902, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951903, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951903, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951903, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951904, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951904, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951904, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951904, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951905, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951905, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951905, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951905, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951906, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951906, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951906, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951906, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951907, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951907, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951907, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951907, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951907, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951908, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951908, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951908, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951908, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951909, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951909, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951909, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951909, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951909, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951910, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951910, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951910, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951910, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951911, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951911, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951911, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951911, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951911, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951912, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951912, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951912, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951912, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951913, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951913, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951913, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951913, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951913, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951914, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951914, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951914, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951914, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951914, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951915, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951915, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951915, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951915, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951915, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951916, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951916, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951916, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951916, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951917, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951917, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951917, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951917, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951917, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951918, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951918, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951918, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951918, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951919, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951919, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951919, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951919, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951919, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951920, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951920, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951920, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951920, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951921, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951921, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951921, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951921, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951921, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951922, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951922, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951922, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951922, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951923, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951923, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951923, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951923, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951923, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951924, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951924, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951924, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951924, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951924, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951925, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951925, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951925, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951925, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951926, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951926, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951926, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951926, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951926, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951927, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951927, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951927, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951927, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951927, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951928, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951928, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951928, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951928, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951929, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951929, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951929, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951929, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951929, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951930, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951930, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951930, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951930, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951931, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951931, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951931, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951931, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951931, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951932, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951932, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951932, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951932, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951932, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951933, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951933, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951933, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951933, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951934, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951934, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951934, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv2_weight"}}
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1636146951934, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951934, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951935, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn1_gamma"}}
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1636146951935, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn2_beta"}}
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1636146951935, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951935, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951936, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951936, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951936, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146951936, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv3_weight"}}
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:15:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1636146953567, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 233}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,567 Node[6] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=45190, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,567 Node[7] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=51299, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,567 Node[0] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=27104, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,567 Node[4] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=19925, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,565 Node[10] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=62868, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,566 Node[14] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=9023, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,566 Node[13] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=46029, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,566 Node[8] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=15198, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,566 Node[12] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=63999, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,563 Node[49] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=6187, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,568 Node[35] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=63433, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:15:53,563 Node[51] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:15:53,569 Node[17] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=35914, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=24815, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,568 Node[44] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=906, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:15:53,567 Node[11] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:15:53,569 Node[56] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=35182, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=54806, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:15:53,568 Node[33] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=10828, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:15:53,570 Node[22] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=1395, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,569 Node[39] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=48744, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:15:53,570 Node[21] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=47847, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,569 Node[37] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=5202, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:15:53,567 Node[15] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=44734, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:15:53,569 Node[61] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=60388, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,569 Node[59] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=23752, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:15:53,569 Node[42] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=9868, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:15:53,564 Node[54] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=7894, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,564 Node[55] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=31144, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,569 Node[46] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=36275, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,569 Node[38] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:15:53,569 Node[28] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=1835, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=35670, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,569 Node[31] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:15:53,569 Node[40] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=39777, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:15:53,571 Node[20] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=21771, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=1117, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,569 Node[26] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=38841, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:15:53,570 Node[41] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=1936, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:15:53,570 Node[47] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=22511, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,570 Node[58] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=3826, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,568 Node[9] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=43256, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,570 Node[62] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=37605, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:15:53,569 Node[30] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=8100, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,571 Node[19] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=34925, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,571 Node[23] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=42676, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:15:53,570 Node[32] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=8201, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,565 Node[50] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=34909, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:15:53,570 Node[34] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=51705, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:15:53,565 Node[48] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=47368, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,572 Node[16] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=18282, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,572 Node[18] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=23584, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,571 Node[29] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=12257, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,571 Node[27] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=23611, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:15:53,571 Node[60] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=11975, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,571 Node[63] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=39973, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:15:53,571 Node[25] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=15782, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,571 Node[57] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=1146, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,571 Node[43] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:15:53,566 Node[53] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=13824, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=63392, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:15:53,571 Node[36] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=45633, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,571 Node[24] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:15:53,567 Node[52] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=29694, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=51848, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,573 Node[45] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=13102, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,567 Node[1] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=58764, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,567 Node[2] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=22100, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,568 Node[5] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=15890, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
:::MLLOG {"namespace": "", "time_ms": 1636146953567, "event_type": "POINT_IN_TIME", "key": "sgd_opt_learning_rate_decay_poly_power", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 711}}
:::MLLOG {"namespace": "", "time_ms": 1636146953568, "event_type": "POINT_IN_TIME", "key": "sgd_opt_end_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 712}}
:::MLLOG {"namespace": "", "time_ms": 1636146953568, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_decay_poly_power", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 713}}
:::MLLOG {"namespace": "", "time_ms": 1636146953568, "event_type": "POINT_IN_TIME", "key": "lars_opt_end_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 714}}
:::MLLOG {"namespace": "", "time_ms": 1636146953568, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 51, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1164}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "s_optimizer", "value": "sgdwfastlars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1165}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "s_network", "value": "resnet-v1b-fl", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1166}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "s_process", "value": "horovod", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1167}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 3264, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1168}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "s_optimizer", "value": "sgdwfastlars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1169}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "s_network", "value": "resnet-v1b-fl", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1170}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "s_process", "value": "horovod", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1171}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1172}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "lars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1178}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "lars_epsilon", "value": 0, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "lars_opt_weight_decay", "value": 5e-05, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1182}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "lars_opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1184}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "lars_opt_base_learning_rate", "value": 10.5, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1185}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_warmup_epochs", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1186}}
:::MLLOG {"namespace": "", "time_ms": 1636146953569, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_decay_steps", "value": 37, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1187}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:15:53,569 Node[3] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=52737, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:16:15] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
:::MLLOG {"namespace": "", "time_ms": 1636146987741, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1336}}
:::MLLOG {"namespace": "", "time_ms": 1636146987742, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1281167, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 486}}
:::MLLOG {"namespace": "", "time_ms": 1636146987964, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 50000, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 508}}
:::MLLOG {"namespace": "", "time_ms": 1636146987964, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 903, "first_epoch_num": 1, "epoch_count": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636146987964, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 1}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:28,820 Node[0] Epoch[0] Batch [0-20]	Speed: 117766.04 samples/sec	accuracy=nan
2021-11-05 21:16:29,341 Node[0] Epoch[0] Batch [20-40]	Speed: 125348.18 samples/sec	accuracy=nan
2021-11-05 21:16:29,877 Node[0] Epoch[0] Batch [40-60]	Speed: 121710.16 samples/sec	accuracy=nan
2021-11-05 21:16:30,355 Node[0] Epoch[0] Batch [60-80]	Speed: 136749.47 samples/sec	accuracy=nan
2021-11-05 21:16:30,833 Node[0] Epoch[0] Batch [80-100]	Speed: 136596.79 samples/sec	accuracy=nan
2021-11-05 21:16:31,295 Node[0] Epoch[0] Batch [100-120]	Speed: 141066.07 samples/sec	accuracy=nan
2021-11-05 21:16:31,856 Node[0] Epoch[0] Batch [120-140]	Speed: 116439.08 samples/sec	accuracy=nan
2021-11-05 21:16:32,370 Node[0] Epoch[0] Batch [140-160]	Speed: 127038.26 samples/sec	accuracy=nan
2021-11-05 21:16:32,850 Node[0] Epoch[0] Batch [160-180]	Speed: 136063.59 samples/sec	accuracy=nan
2021-11-05 21:16:33,319 Node[0] Epoch[0] Batch [180-200]	Speed: 139059.10 samples/sec	accuracy=nan
2021-11-05 21:16:33,802 Node[0] Epoch[0] Batch [200-220]	Speed: 135145.26 samples/sec	accuracy=nan
2021-11-05 21:16:34,279 Node[0] Epoch[0] Batch [220-240]	Speed: 136865.40 samples/sec	accuracy=nan
2021-11-05 21:16:34,748 Node[0] Epoch[0] Batch [240-260]	Speed: 139211.60 samples/sec	accuracy=nan
2021-11-05 21:16:35,241 Node[0] Epoch[0] Batch [260-280]	Speed: 132493.56 samples/sec	accuracy=nan
2021-11-05 21:16:35,702 Node[0] Epoch[0] Batch [280-300]	Speed: 141412.65 samples/sec	accuracy=nan
2021-11-05 21:16:36,207 Node[0] Epoch[0] Batch [300-320]	Speed: 129416.38 samples/sec	accuracy=nan
2021-11-05 21:16:36,678 Node[0] Epoch[0] Batch [320-340]	Speed: 138566.47 samples/sec	accuracy=nan
2021-11-05 21:16:37,146 Node[0] Epoch[0] Batch [340-360]	Speed: 139296.45 samples/sec	accuracy=nan
2021-11-05 21:16:37,586 Node[0] Epoch[0] Batch [360-380]	Speed: 148358.39 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146997836, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 1}}
2021-11-05 21:16:37,837 Node[0] Epoch[0] Time cost=9.872
:::MLLOG {"namespace": "", "time_ms": 1636146997837, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 129773.38439951936}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1636146997837, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 129773.38439951936, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146997837, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 2}}
2021-11-05 21:16:38,266 Node[0] Epoch[1] Batch [0-20]	Speed: 159163.58 samples/sec	accuracy=nan
2021-11-05 21:16:38,661 Node[0] Epoch[1] Batch [20-40]	Speed: 165381.93 samples/sec	accuracy=nan
2021-11-05 21:16:39,060 Node[0] Epoch[1] Batch [40-60]	Speed: 163461.95 samples/sec	accuracy=nan
2021-11-05 21:16:39,455 Node[0] Epoch[1] Batch [60-80]	Speed: 165386.02 samples/sec	accuracy=nan
2021-11-05 21:16:39,851 Node[0] Epoch[1] Batch [80-100]	Speed: 164866.09 samples/sec	accuracy=nan
2021-11-05 21:16:40,244 Node[0] Epoch[1] Batch [100-120]	Speed: 165806.86 samples/sec	accuracy=nan
2021-11-05 21:16:40,646 Node[0] Epoch[1] Batch [120-140]	Speed: 162503.06 samples/sec	accuracy=nan
2021-11-05 21:16:41,042 Node[0] Epoch[1] Batch [140-160]	Speed: 164705.33 samples/sec	accuracy=nan
2021-11-05 21:16:41,439 Node[0] Epoch[1] Batch [160-180]	Speed: 164581.58 samples/sec	accuracy=nan
2021-11-05 21:16:41,840 Node[0] Epoch[1] Batch [180-200]	Speed: 163003.61 samples/sec	accuracy=nan
2021-11-05 21:16:42,236 Node[0] Epoch[1] Batch [200-220]	Speed: 164686.11 samples/sec	accuracy=nan
2021-11-05 21:16:42,637 Node[0] Epoch[1] Batch [220-240]	Speed: 162914.96 samples/sec	accuracy=nan
2021-11-05 21:16:43,034 Node[0] Epoch[1] Batch [240-260]	Speed: 164169.48 samples/sec	accuracy=nan
2021-11-05 21:16:43,432 Node[0] Epoch[1] Batch [260-280]	Speed: 164063.05 samples/sec	accuracy=nan
2021-11-05 21:16:43,829 Node[0] Epoch[1] Batch [280-300]	Speed: 164597.60 samples/sec	accuracy=nan
2021-11-05 21:16:44,223 Node[0] Epoch[1] Batch [300-320]	Speed: 165651.58 samples/sec	accuracy=nan
2021-11-05 21:16:44,619 Node[0] Epoch[1] Batch [320-340]	Speed: 164946.04 samples/sec	accuracy=nan
2021-11-05 21:16:45,017 Node[0] Epoch[1] Batch [340-360]	Speed: 163673.01 samples/sec	accuracy=nan
2021-11-05 21:16:45,419 Node[0] Epoch[1] Batch [360-380]	Speed: 162753.24 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147005658, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 2}}
2021-11-05 21:16:45,659 Node[0] Epoch[1] Time cost=7.821
:::MLLOG {"namespace": "", "time_ms": 1636147005659, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 163800.95591237777}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1636147005659, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 163800.95591237777, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147005659, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 3}}
2021-11-05 21:16:46,075 Node[0] Epoch[2] Batch [0-20]	Speed: 164695.03 samples/sec	accuracy=nan
2021-11-05 21:16:46,473 Node[0] Epoch[2] Batch [20-40]	Speed: 163972.85 samples/sec	accuracy=nan
2021-11-05 21:16:46,870 Node[0] Epoch[2] Batch [40-60]	Speed: 164483.60 samples/sec	accuracy=nan
2021-11-05 21:16:47,262 Node[0] Epoch[2] Batch [60-80]	Speed: 166144.31 samples/sec	accuracy=nan
2021-11-05 21:16:47,656 Node[0] Epoch[2] Batch [80-100]	Speed: 165745.23 samples/sec	accuracy=nan
2021-11-05 21:16:48,049 Node[0] Epoch[2] Batch [100-120]	Speed: 166193.93 samples/sec	accuracy=nan
2021-11-05 21:16:48,445 Node[0] Epoch[2] Batch [120-140]	Speed: 164950.71 samples/sec	accuracy=nan
2021-11-05 21:16:48,845 Node[0] Epoch[2] Batch [140-160]	Speed: 163207.26 samples/sec	accuracy=nan
2021-11-05 21:16:49,243 Node[0] Epoch[2] Batch [160-180]	Speed: 163906.79 samples/sec	accuracy=nan
2021-11-05 21:16:49,640 Node[0] Epoch[2] Batch [180-200]	Speed: 164305.53 samples/sec	accuracy=nan
2021-11-05 21:16:50,036 Node[0] Epoch[2] Batch [200-220]	Speed: 165098.12 samples/sec	accuracy=nan
2021-11-05 21:16:50,434 Node[0] Epoch[2] Batch [220-240]	Speed: 163773.16 samples/sec	accuracy=nan
2021-11-05 21:16:50,829 Node[0] Epoch[2] Batch [240-260]	Speed: 165480.58 samples/sec	accuracy=nan
2021-11-05 21:16:51,226 Node[0] Epoch[2] Batch [260-280]	Speed: 164316.68 samples/sec	accuracy=nan
2021-11-05 21:16:51,621 Node[0] Epoch[2] Batch [280-300]	Speed: 165439.68 samples/sec	accuracy=nan
2021-11-05 21:16:52,016 Node[0] Epoch[2] Batch [300-320]	Speed: 165044.58 samples/sec	accuracy=nan
2021-11-05 21:16:52,418 Node[0] Epoch[2] Batch [320-340]	Speed: 162475.00 samples/sec	accuracy=nan
2021-11-05 21:16:52,821 Node[0] Epoch[2] Batch [340-360]	Speed: 161811.99 samples/sec	accuracy=nan
2021-11-05 21:16:53,222 Node[0] Epoch[2] Batch [360-380]	Speed: 163019.52 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147013461, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 3}}
2021-11-05 21:16:53,461 Node[0] Epoch[2] Time cost=7.802
:::MLLOG {"namespace": "", "time_ms": 1636147013461, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164208.41242268626}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636147013461, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164208.41242268626, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147013478, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 3}}
2021-11-05 21:16:53,478 Node[0] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[4] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[1] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[2] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[3] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[5] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[6] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,473 Node[52] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[7] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,473 Node[48] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[40] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,473 Node[49] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[41] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,473 Node[50] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[42] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,473 Node[51] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[43] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[44] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,476 Node[8] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[58] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[24] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,479 Node[18] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[36] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,476 Node[12] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[61] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[25] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,479 Node[19] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[38] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,476 Node[14] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[46] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[62] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[28] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,473 Node[55] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,479 Node[20] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[39] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,476 Node[15] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[47] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[63] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[30] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,473 Node[53] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,479 Node[22] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[32] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,476 Node[9] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[45] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[56] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[31] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,473 Node[54] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,479 Node[23] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[33] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,476 Node[10] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[57] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,479 Node[16] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[34] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,476 Node[11] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[59] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[26] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,479 Node[17] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[35] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,476 Node[13] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[60] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[27] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,479 Node[21] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[37] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:16:53,478 Node[29] DALI iterator does not support resetting while epoch is not finished. Ignoring...
2021-11-05 21:16:53,833 Node[0] Epoch[2] Validation-accuracy=0.317542
2021-11-05 21:16:53,833 Node[0] Epoch[2] Validation-correct-count=248.000000
2021-11-05 21:16:53,833 Node[0] Epoch[2] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636147013954, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636147013954, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.33574, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636147013954, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1636147013954, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 4, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636147013954, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 4}}
2021-11-05 21:16:54,363 Node[0] Epoch[3] Batch [0-20]	Speed: 161766.29 samples/sec	accuracy=nan
2021-11-05 21:16:54,764 Node[0] Epoch[3] Batch [20-40]	Speed: 162625.35 samples/sec	accuracy=nan
2021-11-05 21:16:55,160 Node[0] Epoch[3] Batch [40-60]	Speed: 164806.65 samples/sec	accuracy=nan
2021-11-05 21:16:55,558 Node[0] Epoch[3] Batch [60-80]	Speed: 164229.35 samples/sec	accuracy=nan
2021-11-05 21:16:55,953 Node[0] Epoch[3] Batch [80-100]	Speed: 165355.86 samples/sec	accuracy=nan
2021-11-05 21:16:56,344 Node[0] Epoch[3] Batch [100-120]	Speed: 166817.56 samples/sec	accuracy=nan
2021-11-05 21:16:56,736 Node[0] Epoch[3] Batch [120-140]	Speed: 166442.76 samples/sec	accuracy=nan
2021-11-05 21:16:57,130 Node[0] Epoch[3] Batch [140-160]	Speed: 165565.13 samples/sec	accuracy=nan
2021-11-05 21:16:57,525 Node[0] Epoch[3] Batch [160-180]	Speed: 165618.41 samples/sec	accuracy=nan
2021-11-05 21:16:57,919 Node[0] Epoch[3] Batch [180-200]	Speed: 165348.97 samples/sec	accuracy=nan
2021-11-05 21:16:58,320 Node[0] Epoch[3] Batch [200-220]	Speed: 162981.39 samples/sec	accuracy=nan
2021-11-05 21:16:58,717 Node[0] Epoch[3] Batch [220-240]	Speed: 164607.99 samples/sec	accuracy=nan
2021-11-05 21:16:59,111 Node[0] Epoch[3] Batch [240-260]	Speed: 165328.60 samples/sec	accuracy=nan
2021-11-05 21:16:59,505 Node[0] Epoch[3] Batch [260-280]	Speed: 165828.75 samples/sec	accuracy=nan
2021-11-05 21:16:59,900 Node[0] Epoch[3] Batch [280-300]	Speed: 165482.48 samples/sec	accuracy=nan
2021-11-05 21:17:00,294 Node[0] Epoch[3] Batch [300-320]	Speed: 165477.68 samples/sec	accuracy=nan
2021-11-05 21:17:00,689 Node[0] Epoch[3] Batch [320-340]	Speed: 165103.79 samples/sec	accuracy=nan
2021-11-05 21:17:01,089 Node[0] Epoch[3] Batch [340-360]	Speed: 163428.88 samples/sec	accuracy=nan
2021-11-05 21:17:01,491 Node[0] Epoch[3] Batch [360-380]	Speed: 162164.08 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147021732, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636147021733, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164711.76940908376}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 4}}
2021-11-05 21:17:01,733 Node[0] Epoch[3] Time cost=7.778
:::MLLOG {"namespace": "", "time_ms": 1636147021733, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164711.76940908376, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147021733, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 5}}
2021-11-05 21:17:02,146 Node[0] Epoch[4] Batch [0-20]	Speed: 165926.53 samples/sec	accuracy=nan
2021-11-05 21:17:02,541 Node[0] Epoch[4] Batch [20-40]	Speed: 165308.14 samples/sec	accuracy=nan
2021-11-05 21:17:02,936 Node[0] Epoch[4] Batch [40-60]	Speed: 165227.53 samples/sec	accuracy=nan
2021-11-05 21:17:03,333 Node[0] Epoch[4] Batch [60-80]	Speed: 164573.07 samples/sec	accuracy=nan
2021-11-05 21:17:03,725 Node[0] Epoch[4] Batch [80-100]	Speed: 166533.77 samples/sec	accuracy=nan
2021-11-05 21:17:04,117 Node[0] Epoch[4] Batch [100-120]	Speed: 166266.89 samples/sec	accuracy=nan
2021-11-05 21:17:04,511 Node[0] Epoch[4] Batch [120-140]	Speed: 165750.85 samples/sec	accuracy=nan
2021-11-05 21:17:04,903 Node[0] Epoch[4] Batch [140-160]	Speed: 166577.94 samples/sec	accuracy=nan
2021-11-05 21:17:05,297 Node[0] Epoch[4] Batch [160-180]	Speed: 165921.71 samples/sec	accuracy=nan
2021-11-05 21:17:05,692 Node[0] Epoch[4] Batch [180-200]	Speed: 165215.37 samples/sec	accuracy=nan
2021-11-05 21:17:06,086 Node[0] Epoch[4] Batch [200-220]	Speed: 165384.42 samples/sec	accuracy=nan
2021-11-05 21:17:06,482 Node[0] Epoch[4] Batch [220-240]	Speed: 164925.87 samples/sec	accuracy=nan
2021-11-05 21:17:06,876 Node[0] Epoch[4] Batch [240-260]	Speed: 165903.01 samples/sec	accuracy=nan
2021-11-05 21:17:07,271 Node[0] Epoch[4] Batch [260-280]	Speed: 165345.47 samples/sec	accuracy=nan
2021-11-05 21:17:07,666 Node[0] Epoch[4] Batch [280-300]	Speed: 164975.96 samples/sec	accuracy=nan
2021-11-05 21:17:08,061 Node[0] Epoch[4] Batch [300-320]	Speed: 165537.51 samples/sec	accuracy=nan
2021-11-05 21:17:08,456 Node[0] Epoch[4] Batch [320-340]	Speed: 165128.19 samples/sec	accuracy=nan
2021-11-05 21:17:08,856 Node[0] Epoch[4] Batch [340-360]	Speed: 163394.74 samples/sec	accuracy=nan
2021-11-05 21:17:09,256 Node[0] Epoch[4] Batch [360-380]	Speed: 162831.06 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147029498, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 5}}
2021-11-05 21:17:09,498 Node[0] Epoch[4] Time cost=7.765
:::MLLOG {"namespace": "", "time_ms": 1636147029498, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164985.79088741544}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 5}}
:::MLLOG {"namespace": "", "time_ms": 1636147029499, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164985.79088741544, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147029499, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 6}}
2021-11-05 21:17:09,910 Node[0] Epoch[5] Batch [0-20]	Speed: 166286.38 samples/sec	accuracy=nan
2021-11-05 21:17:10,309 Node[0] Epoch[5] Batch [20-40]	Speed: 163899.73 samples/sec	accuracy=nan
2021-11-05 21:17:10,704 Node[0] Epoch[5] Batch [40-60]	Speed: 165239.30 samples/sec	accuracy=nan
2021-11-05 21:17:11,096 Node[0] Epoch[5] Batch [60-80]	Speed: 166582.50 samples/sec	accuracy=nan
2021-11-05 21:17:11,489 Node[0] Epoch[5] Batch [80-100]	Speed: 165928.24 samples/sec	accuracy=nan
2021-11-05 21:17:11,884 Node[0] Epoch[5] Batch [100-120]	Speed: 165393.31 samples/sec	accuracy=nan
2021-11-05 21:17:12,277 Node[0] Epoch[5] Batch [120-140]	Speed: 166063.50 samples/sec	accuracy=nan
2021-11-05 21:17:12,670 Node[0] Epoch[5] Batch [140-160]	Speed: 166048.09 samples/sec	accuracy=nan
2021-11-05 21:17:13,065 Node[0] Epoch[5] Batch [160-180]	Speed: 165154.68 samples/sec	accuracy=nan
2021-11-05 21:17:13,457 Node[0] Epoch[5] Batch [180-200]	Speed: 166599.03 samples/sec	accuracy=nan
2021-11-05 21:17:13,855 Node[0] Epoch[5] Batch [200-220]	Speed: 164196.46 samples/sec	accuracy=nan
2021-11-05 21:17:14,248 Node[0] Epoch[5] Batch [220-240]	Speed: 166030.37 samples/sec	accuracy=nan
2021-11-05 21:17:14,643 Node[0] Epoch[5] Batch [240-260]	Speed: 165271.22 samples/sec	accuracy=nan
2021-11-05 21:17:15,035 Node[0] Epoch[5] Batch [260-280]	Speed: 166515.34 samples/sec	accuracy=nan
2021-11-05 21:17:15,430 Node[0] Epoch[5] Batch [280-300]	Speed: 165071.64 samples/sec	accuracy=nan
2021-11-05 21:17:15,825 Node[0] Epoch[5] Batch [300-320]	Speed: 165253.46 samples/sec	accuracy=nan
2021-11-05 21:17:16,220 Node[0] Epoch[5] Batch [320-340]	Speed: 165596.57 samples/sec	accuracy=nan
2021-11-05 21:17:16,616 Node[0] Epoch[5] Batch [340-360]	Speed: 164503.95 samples/sec	accuracy=nan
2021-11-05 21:17:17,015 Node[0] Epoch[5] Batch [360-380]	Speed: 163647.97 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147037253, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1636147037254, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165209.4392385663}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 6}}
2021-11-05 21:17:17,254 Node[0] Epoch[5] Time cost=7.755
:::MLLOG {"namespace": "", "time_ms": 1636147037254, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165209.4392385663, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147037254, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 7}}
2021-11-05 21:17:17,673 Node[0] Epoch[6] Batch [0-20]	Speed: 163992.49 samples/sec	accuracy=nan
2021-11-05 21:17:18,065 Node[0] Epoch[6] Batch [20-40]	Speed: 166367.62 samples/sec	accuracy=nan
2021-11-05 21:17:18,460 Node[0] Epoch[6] Batch [40-60]	Speed: 165221.35 samples/sec	accuracy=nan
2021-11-05 21:17:18,855 Node[0] Epoch[6] Batch [60-80]	Speed: 165435.19 samples/sec	accuracy=nan
2021-11-05 21:17:19,251 Node[0] Epoch[6] Batch [80-100]	Speed: 164938.29 samples/sec	accuracy=nan
2021-11-05 21:17:19,643 Node[0] Epoch[6] Batch [100-120]	Speed: 166155.40 samples/sec	accuracy=nan
2021-11-05 21:17:20,038 Node[0] Epoch[6] Batch [120-140]	Speed: 165480.28 samples/sec	accuracy=nan
2021-11-05 21:17:20,434 Node[0] Epoch[6] Batch [140-160]	Speed: 165026.87 samples/sec	accuracy=nan
2021-11-05 21:17:20,829 Node[0] Epoch[6] Batch [160-180]	Speed: 164869.17 samples/sec	accuracy=nan
2021-11-05 21:17:21,224 Node[0] Epoch[6] Batch [180-200]	Speed: 165569.74 samples/sec	accuracy=nan
2021-11-05 21:17:21,621 Node[0] Epoch[6] Batch [200-220]	Speed: 164435.69 samples/sec	accuracy=nan
2021-11-05 21:17:22,019 Node[0] Epoch[6] Batch [220-240]	Speed: 163853.43 samples/sec	accuracy=nan
2021-11-05 21:17:22,415 Node[0] Epoch[6] Batch [240-260]	Speed: 164725.35 samples/sec	accuracy=nan
2021-11-05 21:17:22,813 Node[0] Epoch[6] Batch [260-280]	Speed: 164106.81 samples/sec	accuracy=nan
2021-11-05 21:17:23,208 Node[0] Epoch[6] Batch [280-300]	Speed: 165382.52 samples/sec	accuracy=nan
2021-11-05 21:17:23,602 Node[0] Epoch[6] Batch [300-320]	Speed: 165688.87 samples/sec	accuracy=nan
2021-11-05 21:17:23,999 Node[0] Epoch[6] Batch [320-340]	Speed: 164596.71 samples/sec	accuracy=nan
2021-11-05 21:17:24,400 Node[0] Epoch[6] Batch [340-360]	Speed: 162473.45 samples/sec	accuracy=nan
2021-11-05 21:17:24,801 Node[0] Epoch[6] Batch [360-380]	Speed: 163102.84 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147045038, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 7}}
2021-11-05 21:17:25,038 Node[0] Epoch[6] Time cost=7.784
:::MLLOG {"namespace": "", "time_ms": 1636147045038, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164583.41423807837}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636147045039, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164583.41423807837, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147045055, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 7}}
2021-11-05 21:17:25,171 Node[0] Epoch[6] Validation-accuracy=0.430218
2021-11-05 21:17:25,172 Node[0] Epoch[6] Validation-correct-count=336.000000
2021-11-05 21:17:25,172 Node[0] Epoch[6] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636147045189, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636147045190, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.45276, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636147045190, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636147045190, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 8, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636147045190, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 8}}
2021-11-05 21:17:25,588 Node[0] Epoch[7] Batch [0-20]	Speed: 166183.54 samples/sec	accuracy=nan
2021-11-05 21:17:25,981 Node[0] Epoch[7] Batch [20-40]	Speed: 165862.30 samples/sec	accuracy=nan
2021-11-05 21:17:26,378 Node[0] Epoch[7] Batch [40-60]	Speed: 164472.23 samples/sec	accuracy=nan
2021-11-05 21:17:26,771 Node[0] Epoch[7] Batch [60-80]	Speed: 166103.39 samples/sec	accuracy=nan
2021-11-05 21:17:27,165 Node[0] Epoch[7] Batch [80-100]	Speed: 165867.53 samples/sec	accuracy=nan
2021-11-05 21:17:27,557 Node[0] Epoch[7] Batch [100-120]	Speed: 166305.88 samples/sec	accuracy=nan
2021-11-05 21:17:27,952 Node[0] Epoch[7] Batch [120-140]	Speed: 165340.98 samples/sec	accuracy=nan
2021-11-05 21:17:28,344 Node[0] Epoch[7] Batch [140-160]	Speed: 166424.35 samples/sec	accuracy=nan
2021-11-05 21:17:28,738 Node[0] Epoch[7] Batch [160-180]	Speed: 165675.03 samples/sec	accuracy=nan
2021-11-05 21:17:29,130 Node[0] Epoch[7] Batch [180-200]	Speed: 166841.14 samples/sec	accuracy=nan
2021-11-05 21:17:29,524 Node[0] Epoch[7] Batch [200-220]	Speed: 165364.15 samples/sec	accuracy=nan
2021-11-05 21:17:29,916 Node[0] Epoch[7] Batch [220-240]	Speed: 166592.23 samples/sec	accuracy=nan
2021-11-05 21:17:30,310 Node[0] Epoch[7] Batch [240-260]	Speed: 165718.55 samples/sec	accuracy=nan
2021-11-05 21:17:30,706 Node[0] Epoch[7] Batch [260-280]	Speed: 165067.46 samples/sec	accuracy=nan
2021-11-05 21:17:31,098 Node[0] Epoch[7] Batch [280-300]	Speed: 166379.34 samples/sec	accuracy=nan
2021-11-05 21:17:31,495 Node[0] Epoch[7] Batch [300-320]	Speed: 164213.50 samples/sec	accuracy=nan
2021-11-05 21:17:31,893 Node[0] Epoch[7] Batch [320-340]	Speed: 164270.34 samples/sec	accuracy=nan
2021-11-05 21:17:32,289 Node[0] Epoch[7] Batch [340-360]	Speed: 164845.94 samples/sec	accuracy=nan
2021-11-05 21:17:32,686 Node[0] Epoch[7] Batch [360-380]	Speed: 164186.22 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147052924, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1636147052925, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165636.14850267477}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 8}}
2021-11-05 21:17:32,925 Node[0] Epoch[7] Time cost=7.735
:::MLLOG {"namespace": "", "time_ms": 1636147052925, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165636.14850267477, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147052925, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 9}}
2021-11-05 21:17:33,338 Node[0] Epoch[8] Batch [0-20]	Speed: 165325.30 samples/sec	accuracy=nan
2021-11-05 21:17:33,733 Node[0] Epoch[8] Batch [20-40]	Speed: 165254.36 samples/sec	accuracy=nan
2021-11-05 21:17:34,126 Node[0] Epoch[8] Batch [40-60]	Speed: 166250.24 samples/sec	accuracy=nan
2021-11-05 21:17:34,521 Node[0] Epoch[8] Batch [60-80]	Speed: 165316.92 samples/sec	accuracy=nan
2021-11-05 21:17:34,914 Node[0] Epoch[8] Batch [80-100]	Speed: 166258.92 samples/sec	accuracy=nan
2021-11-05 21:17:35,309 Node[0] Epoch[8] Batch [100-120]	Speed: 164922.70 samples/sec	accuracy=nan
2021-11-05 21:17:35,700 Node[0] Epoch[8] Batch [120-140]	Speed: 166938.90 samples/sec	accuracy=nan
2021-11-05 21:17:36,094 Node[0] Epoch[8] Batch [140-160]	Speed: 166071.86 samples/sec	accuracy=nan
2021-11-05 21:17:36,489 Node[0] Epoch[8] Batch [160-180]	Speed: 165163.75 samples/sec	accuracy=nan
2021-11-05 21:17:36,884 Node[0] Epoch[8] Batch [180-200]	Speed: 165373.93 samples/sec	accuracy=nan
2021-11-05 21:17:37,276 Node[0] Epoch[8] Batch [200-220]	Speed: 166491.85 samples/sec	accuracy=nan
2021-11-05 21:17:37,672 Node[0] Epoch[8] Batch [220-240]	Speed: 164588.50 samples/sec	accuracy=nan
2021-11-05 21:17:38,068 Node[0] Epoch[8] Batch [240-260]	Speed: 164887.14 samples/sec	accuracy=nan
2021-11-05 21:17:38,462 Node[0] Epoch[8] Batch [260-280]	Speed: 165695.08 samples/sec	accuracy=nan
2021-11-05 21:17:38,854 Node[0] Epoch[8] Batch [280-300]	Speed: 166618.08 samples/sec	accuracy=nan
2021-11-05 21:17:39,252 Node[0] Epoch[8] Batch [300-320]	Speed: 164137.40 samples/sec	accuracy=nan
2021-11-05 21:17:39,646 Node[0] Epoch[8] Batch [320-340]	Speed: 165560.63 samples/sec	accuracy=nan
2021-11-05 21:17:40,046 Node[0] Epoch[8] Batch [340-360]	Speed: 163353.02 samples/sec	accuracy=nan
2021-11-05 21:17:40,443 Node[0] Epoch[8] Batch [360-380]	Speed: 164188.19 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147060681, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 9}}
2021-11-05 21:17:40,681 Node[0] Epoch[8] Time cost=7.756
:::MLLOG {"namespace": "", "time_ms": 1636147060681, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165186.80388965827}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 9}}
:::MLLOG {"namespace": "", "time_ms": 1636147060681, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165186.80388965827, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147060681, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 10}}
2021-11-05 21:17:41,094 Node[0] Epoch[9] Batch [0-20]	Speed: 165665.01 samples/sec	accuracy=nan
2021-11-05 21:17:41,487 Node[0] Epoch[9] Batch [20-40]	Speed: 166041.64 samples/sec	accuracy=nan
2021-11-05 21:17:41,881 Node[0] Epoch[9] Batch [40-60]	Speed: 165906.32 samples/sec	accuracy=nan
2021-11-05 21:17:42,275 Node[0] Epoch[9] Batch [60-80]	Speed: 165832.47 samples/sec	accuracy=nan
2021-11-05 21:17:42,668 Node[0] Epoch[9] Batch [80-100]	Speed: 165966.76 samples/sec	accuracy=nan
2021-11-05 21:17:43,060 Node[0] Epoch[9] Batch [100-120]	Speed: 166336.69 samples/sec	accuracy=nan
2021-11-05 21:17:43,455 Node[0] Epoch[9] Batch [120-140]	Speed: 165627.13 samples/sec	accuracy=nan
2021-11-05 21:17:43,847 Node[0] Epoch[9] Batch [140-160]	Speed: 166193.42 samples/sec	accuracy=nan
2021-11-05 21:17:44,244 Node[0] Epoch[9] Batch [160-180]	Speed: 164509.79 samples/sec	accuracy=nan
2021-11-05 21:17:44,636 Node[0] Epoch[9] Batch [180-200]	Speed: 166433.76 samples/sec	accuracy=nan
2021-11-05 21:17:45,032 Node[0] Epoch[9] Batch [200-220]	Speed: 165160.56 samples/sec	accuracy=nan
2021-11-05 21:17:45,425 Node[0] Epoch[9] Batch [220-240]	Speed: 166010.44 samples/sec	accuracy=nan
2021-11-05 21:17:45,819 Node[0] Epoch[9] Batch [240-260]	Speed: 165676.84 samples/sec	accuracy=nan
2021-11-05 21:17:46,215 Node[0] Epoch[9] Batch [260-280]	Speed: 164613.64 samples/sec	accuracy=nan
2021-11-05 21:17:46,609 Node[0] Epoch[9] Batch [280-300]	Speed: 165664.71 samples/sec	accuracy=nan
2021-11-05 21:17:47,003 Node[0] Epoch[9] Batch [300-320]	Speed: 165881.70 samples/sec	accuracy=nan
2021-11-05 21:17:47,401 Node[0] Epoch[9] Batch [320-340]	Speed: 164180.41 samples/sec	accuracy=nan
2021-11-05 21:17:47,796 Node[0] Epoch[9] Batch [340-360]	Speed: 165145.22 samples/sec	accuracy=nan
2021-11-05 21:17:48,194 Node[0] Epoch[9] Batch [360-380]	Speed: 163851.18 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147068432, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 10}}
2021-11-05 21:17:48,432 Node[0] Epoch[9] Time cost=7.751
:::MLLOG {"namespace": "", "time_ms": 1636147068432, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165301.00883401226}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 10}}
:::MLLOG {"namespace": "", "time_ms": 1636147068432, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165301.00883401226, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147068432, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 11}}
2021-11-05 21:17:48,847 Node[0] Epoch[10] Batch [0-20]	Speed: 164866.69 samples/sec	accuracy=nan
2021-11-05 21:17:49,238 Node[0] Epoch[10] Batch [20-40]	Speed: 166838.90 samples/sec	accuracy=nan
2021-11-05 21:17:49,634 Node[0] Epoch[10] Batch [40-60]	Speed: 165061.99 samples/sec	accuracy=nan
2021-11-05 21:17:50,026 Node[0] Epoch[10] Batch [60-80]	Speed: 166481.42 samples/sec	accuracy=nan
2021-11-05 21:17:50,418 Node[0] Epoch[10] Batch [80-100]	Speed: 166320.22 samples/sec	accuracy=nan
2021-11-05 21:17:50,811 Node[0] Epoch[10] Batch [100-120]	Speed: 166255.08 samples/sec	accuracy=nan
2021-11-05 21:17:51,204 Node[0] Epoch[10] Batch [120-140]	Speed: 166007.52 samples/sec	accuracy=nan
2021-11-05 21:17:51,597 Node[0] Epoch[10] Batch [140-160]	Speed: 166454.29 samples/sec	accuracy=nan
2021-11-05 21:17:51,995 Node[0] Epoch[10] Batch [160-180]	Speed: 163961.27 samples/sec	accuracy=nan
2021-11-05 21:17:52,390 Node[0] Epoch[10] Batch [180-200]	Speed: 165169.43 samples/sec	accuracy=nan
2021-11-05 21:17:52,785 Node[0] Epoch[10] Batch [200-220]	Speed: 165129.58 samples/sec	accuracy=nan
2021-11-05 21:17:53,181 Node[0] Epoch[10] Batch [220-240]	Speed: 164800.60 samples/sec	accuracy=nan
2021-11-05 21:17:53,574 Node[0] Epoch[10] Batch [240-260]	Speed: 166303.65 samples/sec	accuracy=nan
2021-11-05 21:17:53,968 Node[0] Epoch[10] Batch [260-280]	Speed: 165462.38 samples/sec	accuracy=nan
2021-11-05 21:17:54,362 Node[0] Epoch[10] Batch [280-300]	Speed: 165798.93 samples/sec	accuracy=nan
2021-11-05 21:17:54,756 Node[0] Epoch[10] Batch [300-320]	Speed: 165948.15 samples/sec	accuracy=nan
2021-11-05 21:17:55,152 Node[0] Epoch[10] Batch [320-340]	Speed: 164760.73 samples/sec	accuracy=nan
2021-11-05 21:17:55,550 Node[0] Epoch[10] Batch [340-360]	Speed: 163884.42 samples/sec	accuracy=nan
2021-11-05 21:17:55,947 Node[0] Epoch[10] Batch [360-380]	Speed: 164628.38 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147076185, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 11}}
2021-11-05 21:17:56,185 Node[0] Epoch[10] Time cost=7.753
:::MLLOG {"namespace": "", "time_ms": 1636147076185, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165254.38805248786}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636147076185, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165254.38805248786, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147076201, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 11}}
2021-11-05 21:17:56,317 Node[0] Epoch[10] Validation-accuracy=0.537772
2021-11-05 21:17:56,318 Node[0] Epoch[10] Validation-correct-count=420.000000
2021-11-05 21:17:56,318 Node[0] Epoch[10] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636147076334, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636147076335, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.53596, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636147076335, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1636147076335, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 12, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636147076335, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 12}}
2021-11-05 21:17:56,732 Node[0] Epoch[11] Batch [0-20]	Speed: 166466.74 samples/sec	accuracy=nan
2021-11-05 21:17:57,122 Node[0] Epoch[11] Batch [20-40]	Speed: 167159.86 samples/sec	accuracy=nan
2021-11-05 21:17:57,515 Node[0] Epoch[11] Batch [40-60]	Speed: 166381.37 samples/sec	accuracy=nan
2021-11-05 21:17:57,909 Node[0] Epoch[11] Batch [60-80]	Speed: 165461.68 samples/sec	accuracy=nan
2021-11-05 21:17:58,304 Node[0] Epoch[11] Batch [80-100]	Speed: 165471.68 samples/sec	accuracy=nan
2021-11-05 21:17:58,697 Node[0] Epoch[11] Batch [100-120]	Speed: 166000.67 samples/sec	accuracy=nan
2021-11-05 21:17:59,089 Node[0] Epoch[11] Batch [120-140]	Speed: 166586.15 samples/sec	accuracy=nan
2021-11-05 21:17:59,483 Node[0] Epoch[11] Batch [140-160]	Speed: 165770.32 samples/sec	accuracy=nan
2021-11-05 21:17:59,876 Node[0] Epoch[11] Batch [160-180]	Speed: 166105.31 samples/sec	accuracy=nan
2021-11-05 21:18:00,269 Node[0] Epoch[11] Batch [180-200]	Speed: 166053.53 samples/sec	accuracy=nan
2021-11-05 21:18:00,663 Node[0] Epoch[11] Batch [200-220]	Speed: 165660.20 samples/sec	accuracy=nan
2021-11-05 21:18:01,056 Node[0] Epoch[11] Batch [220-240]	Speed: 166163.27 samples/sec	accuracy=nan
2021-11-05 21:18:01,452 Node[0] Epoch[11] Batch [240-260]	Speed: 164746.26 samples/sec	accuracy=nan
2021-11-05 21:18:01,845 Node[0] Epoch[11] Batch [260-280]	Speed: 166234.19 samples/sec	accuracy=nan
2021-11-05 21:18:02,237 Node[0] Epoch[11] Batch [280-300]	Speed: 166563.45 samples/sec	accuracy=nan
2021-11-05 21:18:02,630 Node[0] Epoch[11] Batch [300-320]	Speed: 165953.28 samples/sec	accuracy=nan
2021-11-05 21:18:03,027 Node[0] Epoch[11] Batch [320-340]	Speed: 164636.90 samples/sec	accuracy=nan
2021-11-05 21:18:03,424 Node[0] Epoch[11] Batch [340-360]	Speed: 164346.96 samples/sec	accuracy=nan
2021-11-05 21:18:03,827 Node[0] Epoch[11] Batch [360-380]	Speed: 161900.59 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147084064, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 12}}
2021-11-05 21:18:04,064 Node[0] Epoch[11] Time cost=7.729
:::MLLOG {"namespace": "", "time_ms": 1636147084064, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165759.49395540933}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 12}}
:::MLLOG {"namespace": "", "time_ms": 1636147084064, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165759.49395540933, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147084064, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 13}}
2021-11-05 21:18:04,486 Node[0] Epoch[12] Batch [0-20]	Speed: 162266.15 samples/sec	accuracy=nan
2021-11-05 21:18:04,880 Node[0] Epoch[12] Batch [20-40]	Speed: 165490.88 samples/sec	accuracy=nan
2021-11-05 21:18:05,272 Node[0] Epoch[12] Batch [40-60]	Speed: 166712.33 samples/sec	accuracy=nan
2021-11-05 21:18:05,665 Node[0] Epoch[12] Batch [60-80]	Speed: 165979.34 samples/sec	accuracy=nan
2021-11-05 21:18:06,058 Node[0] Epoch[12] Batch [80-100]	Speed: 165852.66 samples/sec	accuracy=nan
2021-11-05 21:18:06,450 Node[0] Epoch[12] Batch [100-120]	Speed: 166751.32 samples/sec	accuracy=nan
2021-11-05 21:18:06,843 Node[0] Epoch[12] Batch [120-140]	Speed: 166187.47 samples/sec	accuracy=nan
2021-11-05 21:18:07,235 Node[0] Epoch[12] Batch [140-160]	Speed: 166517.36 samples/sec	accuracy=nan
2021-11-05 21:18:07,627 Node[0] Epoch[12] Batch [160-180]	Speed: 166512.70 samples/sec	accuracy=nan
2021-11-05 21:18:08,020 Node[0] Epoch[12] Batch [180-200]	Speed: 166135.84 samples/sec	accuracy=nan
2021-11-05 21:18:08,416 Node[0] Epoch[12] Batch [200-220]	Speed: 164818.85 samples/sec	accuracy=nan
2021-11-05 21:18:08,810 Node[0] Epoch[12] Batch [220-240]	Speed: 165635.44 samples/sec	accuracy=nan
2021-11-05 21:18:09,203 Node[0] Epoch[12] Batch [240-260]	Speed: 166161.55 samples/sec	accuracy=nan
2021-11-05 21:18:09,596 Node[0] Epoch[12] Batch [260-280]	Speed: 166238.83 samples/sec	accuracy=nan
2021-11-05 21:18:09,989 Node[0] Epoch[12] Batch [280-300]	Speed: 166044.66 samples/sec	accuracy=nan
2021-11-05 21:18:10,382 Node[0] Epoch[12] Batch [300-320]	Speed: 165818.91 samples/sec	accuracy=nan
2021-11-05 21:18:10,775 Node[0] Epoch[12] Batch [320-340]	Speed: 166118.10 samples/sec	accuracy=nan
2021-11-05 21:18:11,172 Node[0] Epoch[12] Batch [340-360]	Speed: 164541.32 samples/sec	accuracy=nan
2021-11-05 21:18:11,571 Node[0] Epoch[12] Batch [360-380]	Speed: 163652.37 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147091807, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 13}}
2021-11-05 21:18:11,807 Node[0] Epoch[12] Time cost=7.743
:::MLLOG {"namespace": "", "time_ms": 1636147091808, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165461.0543204284}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 13}}
:::MLLOG {"namespace": "", "time_ms": 1636147091808, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165461.0543204284, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147091808, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 14}}
2021-11-05 21:18:12,223 Node[0] Epoch[13] Batch [0-20]	Speed: 164643.53 samples/sec	accuracy=nan
2021-11-05 21:18:12,617 Node[0] Epoch[13] Batch [20-40]	Speed: 165836.29 samples/sec	accuracy=nan
2021-11-05 21:18:13,011 Node[0] Epoch[13] Batch [40-60]	Speed: 165847.64 samples/sec	accuracy=nan
2021-11-05 21:18:13,407 Node[0] Epoch[13] Batch [60-80]	Speed: 164745.17 samples/sec	accuracy=nan
2021-11-05 21:18:13,799 Node[0] Epoch[13] Batch [80-100]	Speed: 166362.77 samples/sec	accuracy=nan
2021-11-05 21:18:14,197 Node[0] Epoch[13] Batch [100-120]	Speed: 164173.72 samples/sec	accuracy=nan
2021-11-05 21:18:14,590 Node[0] Epoch[13] Batch [120-140]	Speed: 166208.36 samples/sec	accuracy=nan
2021-11-05 21:18:14,983 Node[0] Epoch[13] Batch [140-160]	Speed: 166116.09 samples/sec	accuracy=nan
2021-11-05 21:18:15,378 Node[0] Epoch[13] Batch [160-180]	Speed: 165359.75 samples/sec	accuracy=nan
2021-11-05 21:18:15,770 Node[0] Epoch[13] Batch [180-200]	Speed: 166267.00 samples/sec	accuracy=nan
2021-11-05 21:18:16,163 Node[0] Epoch[13] Batch [200-220]	Speed: 166071.35 samples/sec	accuracy=nan
2021-11-05 21:18:16,556 Node[0] Epoch[13] Batch [220-240]	Speed: 166237.32 samples/sec	accuracy=nan
2021-11-05 21:18:16,948 Node[0] Epoch[13] Batch [240-260]	Speed: 166432.54 samples/sec	accuracy=nan
2021-11-05 21:18:17,341 Node[0] Epoch[13] Batch [260-280]	Speed: 166062.19 samples/sec	accuracy=nan
2021-11-05 21:18:17,734 Node[0] Epoch[13] Batch [280-300]	Speed: 166395.42 samples/sec	accuracy=nan
2021-11-05 21:18:18,128 Node[0] Epoch[13] Batch [300-320]	Speed: 165578.65 samples/sec	accuracy=nan
2021-11-05 21:18:18,525 Node[0] Epoch[13] Batch [320-340]	Speed: 164530.64 samples/sec	accuracy=nan
2021-11-05 21:18:18,921 Node[0] Epoch[13] Batch [340-360]	Speed: 164682.64 samples/sec	accuracy=nan
2021-11-05 21:18:19,318 Node[0] Epoch[13] Batch [360-380]	Speed: 164526.49 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147099553, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1636147099553, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165409.11400507763}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 14}}
2021-11-05 21:18:19,553 Node[0] Epoch[13] Time cost=7.745
:::MLLOG {"namespace": "", "time_ms": 1636147099553, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165409.11400507763, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147099554, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 15}}
2021-11-05 21:18:19,966 Node[0] Epoch[14] Batch [0-20]	Speed: 165838.90 samples/sec	accuracy=nan
2021-11-05 21:18:20,360 Node[0] Epoch[14] Batch [20-40]	Speed: 165520.99 samples/sec	accuracy=nan
2021-11-05 21:18:20,752 Node[0] Epoch[14] Batch [40-60]	Speed: 166782.30 samples/sec	accuracy=nan
2021-11-05 21:18:21,144 Node[0] Epoch[14] Batch [60-80]	Speed: 166329.62 samples/sec	accuracy=nan
2021-11-05 21:18:21,538 Node[0] Epoch[14] Batch [80-100]	Speed: 165750.85 samples/sec	accuracy=nan
2021-11-05 21:18:21,935 Node[0] Epoch[14] Batch [100-120]	Speed: 164282.96 samples/sec	accuracy=nan
2021-11-05 21:18:22,329 Node[0] Epoch[14] Batch [120-140]	Speed: 165764.00 samples/sec	accuracy=nan
2021-11-05 21:18:22,722 Node[0] Epoch[14] Batch [140-160]	Speed: 166106.41 samples/sec	accuracy=nan
2021-11-05 21:18:23,116 Node[0] Epoch[14] Batch [160-180]	Speed: 165661.80 samples/sec	accuracy=nan
2021-11-05 21:18:23,510 Node[0] Epoch[14] Batch [180-200]	Speed: 165846.73 samples/sec	accuracy=nan
2021-11-05 21:18:23,906 Node[0] Epoch[14] Batch [200-220]	Speed: 165001.61 samples/sec	accuracy=nan
2021-11-05 21:18:24,298 Node[0] Epoch[14] Batch [220-240]	Speed: 166397.95 samples/sec	accuracy=nan
2021-11-05 21:18:24,691 Node[0] Epoch[14] Batch [240-260]	Speed: 166242.46 samples/sec	accuracy=nan
2021-11-05 21:18:25,089 Node[0] Epoch[14] Batch [260-280]	Speed: 163730.07 samples/sec	accuracy=nan
2021-11-05 21:18:25,482 Node[0] Epoch[14] Batch [280-300]	Speed: 166046.88 samples/sec	accuracy=nan
2021-11-05 21:18:25,876 Node[0] Epoch[14] Batch [300-320]	Speed: 165933.77 samples/sec	accuracy=nan
2021-11-05 21:18:26,273 Node[0] Epoch[14] Batch [320-340]	Speed: 164330.68 samples/sec	accuracy=nan
2021-11-05 21:18:26,674 Node[0] Epoch[14] Batch [340-360]	Speed: 162842.29 samples/sec	accuracy=nan
2021-11-05 21:18:27,072 Node[0] Epoch[14] Batch [360-380]	Speed: 163852.84 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147107308, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 15}}
2021-11-05 21:18:27,308 Node[0] Epoch[14] Time cost=7.755
:::MLLOG {"namespace": "", "time_ms": 1636147107308, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165210.67351826016}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636147107309, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165210.67351826016, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147107325, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 15}}
2021-11-05 21:18:27,439 Node[0] Epoch[14] Validation-accuracy=0.586428
2021-11-05 21:18:27,439 Node[0] Epoch[14] Validation-correct-count=458.000000
2021-11-05 21:18:27,439 Node[0] Epoch[14] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636147107463, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636147107463, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.57872, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636147107463, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1636147107464, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 16, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636147107464, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 16}}
2021-11-05 21:18:27,862 Node[0] Epoch[15] Batch [0-20]	Speed: 166134.74 samples/sec	accuracy=nan
2021-11-05 21:18:28,259 Node[0] Epoch[15] Batch [20-40]	Speed: 164201.78 samples/sec	accuracy=nan
2021-11-05 21:18:28,652 Node[0] Epoch[15] Batch [40-60]	Speed: 166103.09 samples/sec	accuracy=nan
2021-11-05 21:18:29,045 Node[0] Epoch[15] Batch [60-80]	Speed: 166040.74 samples/sec	accuracy=nan
2021-11-05 21:18:29,437 Node[0] Epoch[15] Batch [80-100]	Speed: 166560.51 samples/sec	accuracy=nan
2021-11-05 21:18:29,830 Node[0] Epoch[15] Batch [100-120]	Speed: 166425.06 samples/sec	accuracy=nan
2021-11-05 21:18:30,223 Node[0] Epoch[15] Batch [120-140]	Speed: 165715.74 samples/sec	accuracy=nan
2021-11-05 21:18:30,616 Node[0] Epoch[15] Batch [140-160]	Speed: 166255.59 samples/sec	accuracy=nan
2021-11-05 21:18:31,011 Node[0] Epoch[15] Batch [160-180]	Speed: 165280.89 samples/sec	accuracy=nan
2021-11-05 21:18:31,404 Node[0] Epoch[15] Batch [180-200]	Speed: 165988.09 samples/sec	accuracy=nan
2021-11-05 21:18:31,797 Node[0] Epoch[15] Batch [200-220]	Speed: 166193.73 samples/sec	accuracy=nan
2021-11-05 21:18:32,189 Node[0] Epoch[15] Batch [220-240]	Speed: 166563.76 samples/sec	accuracy=nan
2021-11-05 21:18:32,582 Node[0] Epoch[15] Batch [240-260]	Speed: 166151.27 samples/sec	accuracy=nan
2021-11-05 21:18:32,976 Node[0] Epoch[15] Batch [260-280]	Speed: 165858.29 samples/sec	accuracy=nan
2021-11-05 21:18:33,371 Node[0] Epoch[15] Batch [280-300]	Speed: 164984.11 samples/sec	accuracy=nan
2021-11-05 21:18:33,766 Node[0] Epoch[15] Batch [300-320]	Speed: 165443.88 samples/sec	accuracy=nan
2021-11-05 21:18:34,161 Node[0] Epoch[15] Batch [320-340]	Speed: 165286.38 samples/sec	accuracy=nan
2021-11-05 21:18:34,557 Node[0] Epoch[15] Batch [340-360]	Speed: 164566.74 samples/sec	accuracy=nan
2021-11-05 21:18:34,957 Node[0] Epoch[15] Batch [360-380]	Speed: 163434.15 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147115193, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 16}}
2021-11-05 21:18:35,193 Node[0] Epoch[15] Time cost=7.730
:::MLLOG {"namespace": "", "time_ms": 1636147115194, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165746.60974054888}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 16}}
:::MLLOG {"namespace": "", "time_ms": 1636147115194, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165746.60974054888, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147115194, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 17}}
2021-11-05 21:18:35,607 Node[0] Epoch[16] Batch [0-20]	Speed: 165905.32 samples/sec	accuracy=nan
2021-11-05 21:18:36,001 Node[0] Epoch[16] Batch [20-40]	Speed: 165554.92 samples/sec	accuracy=nan
2021-11-05 21:18:36,394 Node[0] Epoch[16] Batch [40-60]	Speed: 166014.76 samples/sec	accuracy=nan
2021-11-05 21:18:36,788 Node[0] Epoch[16] Batch [60-80]	Speed: 165790.09 samples/sec	accuracy=nan
2021-11-05 21:18:37,179 Node[0] Epoch[16] Batch [80-100]	Speed: 167071.22 samples/sec	accuracy=nan
2021-11-05 21:18:37,572 Node[0] Epoch[16] Batch [100-120]	Speed: 166049.40 samples/sec	accuracy=nan
2021-11-05 21:18:37,966 Node[0] Epoch[16] Batch [120-140]	Speed: 165476.98 samples/sec	accuracy=nan
2021-11-05 21:18:38,359 Node[0] Epoch[16] Batch [140-160]	Speed: 166342.45 samples/sec	accuracy=nan
2021-11-05 21:18:38,752 Node[0] Epoch[16] Batch [160-180]	Speed: 165966.86 samples/sec	accuracy=nan
2021-11-05 21:18:39,146 Node[0] Epoch[16] Batch [180-200]	Speed: 165691.47 samples/sec	accuracy=nan
2021-11-05 21:18:39,537 Node[0] Epoch[16] Batch [200-220]	Speed: 166725.63 samples/sec	accuracy=nan
2021-11-05 21:18:39,932 Node[0] Epoch[16] Batch [220-240]	Speed: 165313.63 samples/sec	accuracy=nan
2021-11-05 21:18:40,325 Node[0] Epoch[16] Batch [240-260]	Speed: 166392.59 samples/sec	accuracy=nan
2021-11-05 21:18:40,719 Node[0] Epoch[16] Batch [260-280]	Speed: 165341.28 samples/sec	accuracy=nan
2021-11-05 21:18:41,112 Node[0] Epoch[16] Batch [280-300]	Speed: 166252.96 samples/sec	accuracy=nan
2021-11-05 21:18:41,505 Node[0] Epoch[16] Batch [300-320]	Speed: 166063.80 samples/sec	accuracy=nan
2021-11-05 21:18:41,905 Node[0] Epoch[16] Batch [320-340]	Speed: 163498.46 samples/sec	accuracy=nan
2021-11-05 21:18:42,302 Node[0] Epoch[16] Batch [340-360]	Speed: 164416.53 samples/sec	accuracy=nan
2021-11-05 21:18:42,700 Node[0] Epoch[16] Batch [360-380]	Speed: 163652.67 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147122939, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 17}}
2021-11-05 21:18:42,939 Node[0] Epoch[16] Time cost=7.745
:::MLLOG {"namespace": "", "time_ms": 1636147122939, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165419.85795278728}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 17}}
:::MLLOG {"namespace": "", "time_ms": 1636147122939, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165419.85795278728, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147122939, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 18}}
2021-11-05 21:18:43,354 Node[0] Epoch[17] Batch [0-20]	Speed: 164777.39 samples/sec	accuracy=nan
2021-11-05 21:18:43,748 Node[0] Epoch[17] Batch [20-40]	Speed: 165669.72 samples/sec	accuracy=nan
2021-11-05 21:18:44,144 Node[0] Epoch[17] Batch [40-60]	Speed: 165157.47 samples/sec	accuracy=nan
2021-11-05 21:18:44,540 Node[0] Epoch[17] Batch [60-80]	Speed: 164812.30 samples/sec	accuracy=nan
2021-11-05 21:18:44,935 Node[0] Epoch[17] Batch [80-100]	Speed: 165385.32 samples/sec	accuracy=nan
2021-11-05 21:18:45,328 Node[0] Epoch[17] Batch [100-120]	Speed: 166116.89 samples/sec	accuracy=nan
2021-11-05 21:18:45,719 Node[0] Epoch[17] Batch [120-140]	Speed: 166641.51 samples/sec	accuracy=nan
2021-11-05 21:18:46,112 Node[0] Epoch[17] Batch [140-160]	Speed: 166045.37 samples/sec	accuracy=nan
2021-11-05 21:18:46,505 Node[0] Epoch[17] Batch [160-180]	Speed: 166140.68 samples/sec	accuracy=nan
2021-11-05 21:18:46,898 Node[0] Epoch[17] Batch [180-200]	Speed: 166355.69 samples/sec	accuracy=nan
2021-11-05 21:18:47,291 Node[0] Epoch[17] Batch [200-220]	Speed: 166149.45 samples/sec	accuracy=nan
2021-11-05 21:18:47,685 Node[0] Epoch[17] Batch [220-240]	Speed: 165560.53 samples/sec	accuracy=nan
2021-11-05 21:18:48,078 Node[0] Epoch[17] Batch [240-260]	Speed: 166005.60 samples/sec	accuracy=nan
2021-11-05 21:18:48,470 Node[0] Epoch[17] Batch [260-280]	Speed: 166631.77 samples/sec	accuracy=nan
2021-11-05 21:18:48,863 Node[0] Epoch[17] Batch [280-300]	Speed: 166143.40 samples/sec	accuracy=nan
2021-11-05 21:18:49,257 Node[0] Epoch[17] Batch [300-320]	Speed: 165706.61 samples/sec	accuracy=nan
2021-11-05 21:18:49,654 Node[0] Epoch[17] Batch [320-340]	Speed: 164280.30 samples/sec	accuracy=nan
2021-11-05 21:18:50,050 Node[0] Epoch[17] Batch [340-360]	Speed: 164722.67 samples/sec	accuracy=nan
2021-11-05 21:18:50,448 Node[0] Epoch[17] Batch [360-380]	Speed: 164401.03 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147130682, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 18}}
2021-11-05 21:18:50,683 Node[0] Epoch[17] Time cost=7.743
:::MLLOG {"namespace": "", "time_ms": 1636147130683, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165450.78896403144}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 18}}
:::MLLOG {"namespace": "", "time_ms": 1636147130683, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165450.78896403144, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147130683, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 19}}
2021-11-05 21:18:51,095 Node[0] Epoch[18] Batch [0-20]	Speed: 166105.71 samples/sec	accuracy=nan
2021-11-05 21:18:51,487 Node[0] Epoch[18] Batch [20-40]	Speed: 166760.15 samples/sec	accuracy=nan
2021-11-05 21:18:51,883 Node[0] Epoch[18] Batch [40-60]	Speed: 164878.60 samples/sec	accuracy=nan
2021-11-05 21:18:52,276 Node[0] Epoch[18] Batch [60-80]	Speed: 166137.56 samples/sec	accuracy=nan
2021-11-05 21:18:52,669 Node[0] Epoch[18] Batch [80-100]	Speed: 165935.88 samples/sec	accuracy=nan
2021-11-05 21:18:53,063 Node[0] Epoch[18] Batch [100-120]	Speed: 165884.31 samples/sec	accuracy=nan
2021-11-05 21:18:53,456 Node[0] Epoch[18] Batch [120-140]	Speed: 165811.68 samples/sec	accuracy=nan
2021-11-05 21:18:53,849 Node[0] Epoch[18] Batch [140-160]	Speed: 166176.78 samples/sec	accuracy=nan
2021-11-05 21:18:54,243 Node[0] Epoch[18] Batch [160-180]	Speed: 165791.50 samples/sec	accuracy=nan
2021-11-05 21:18:54,636 Node[0] Epoch[18] Batch [180-200]	Speed: 165988.90 samples/sec	accuracy=nan
2021-11-05 21:18:55,029 Node[0] Epoch[18] Batch [200-220]	Speed: 166039.33 samples/sec	accuracy=nan
2021-11-05 21:18:55,423 Node[0] Epoch[18] Batch [220-240]	Speed: 165773.93 samples/sec	accuracy=nan
2021-11-05 21:18:55,814 Node[0] Epoch[18] Batch [240-260]	Speed: 166886.60 samples/sec	accuracy=nan
2021-11-05 21:18:56,207 Node[0] Epoch[18] Batch [260-280]	Speed: 166000.87 samples/sec	accuracy=nan
2021-11-05 21:18:56,601 Node[0] Epoch[18] Batch [280-300]	Speed: 165851.76 samples/sec	accuracy=nan
2021-11-05 21:18:56,994 Node[0] Epoch[18] Batch [300-320]	Speed: 166270.33 samples/sec	accuracy=nan
2021-11-05 21:18:57,388 Node[0] Epoch[18] Batch [320-340]	Speed: 165422.29 samples/sec	accuracy=nan
2021-11-05 21:18:57,784 Node[0] Epoch[18] Batch [340-360]	Speed: 164906.21 samples/sec	accuracy=nan
2021-11-05 21:18:58,181 Node[0] Epoch[18] Batch [360-380]	Speed: 164618.39 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147138417, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636147138417, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165655.38343441195}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 19}}
2021-11-05 21:18:58,417 Node[0] Epoch[18] Time cost=7.734
:::MLLOG {"namespace": "", "time_ms": 1636147138417, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165655.38343441195, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147138433, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 19}}
2021-11-05 21:18:58,552 Node[0] Epoch[18] Validation-accuracy=0.635083
2021-11-05 21:18:58,552 Node[0] Epoch[18] Validation-correct-count=496.000000
2021-11-05 21:18:58,552 Node[0] Epoch[18] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636147138565, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636147138565, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.64992, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636147138565, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1636147138565, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 20, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636147138565, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 20}}
2021-11-05 21:18:58,961 Node[0] Epoch[19] Batch [0-20]	Speed: 167065.61 samples/sec	accuracy=nan
2021-11-05 21:18:59,354 Node[0] Epoch[19] Batch [20-40]	Speed: 166282.75 samples/sec	accuracy=nan
2021-11-05 21:18:59,747 Node[0] Epoch[19] Batch [40-60]	Speed: 165895.67 samples/sec	accuracy=nan
2021-11-05 21:19:00,139 Node[0] Epoch[19] Batch [60-80]	Speed: 166471.90 samples/sec	accuracy=nan
2021-11-05 21:19:00,532 Node[0] Epoch[19] Batch [80-100]	Speed: 166382.07 samples/sec	accuracy=nan
2021-11-05 21:19:00,923 Node[0] Epoch[19] Batch [100-120]	Speed: 166805.36 samples/sec	accuracy=nan
2021-11-05 21:19:01,315 Node[0] Epoch[19] Batch [120-140]	Speed: 166522.43 samples/sec	accuracy=nan
2021-11-05 21:19:01,708 Node[0] Epoch[19] Batch [140-160]	Speed: 166178.60 samples/sec	accuracy=nan
2021-11-05 21:19:02,101 Node[0] Epoch[19] Batch [160-180]	Speed: 166165.79 samples/sec	accuracy=nan
2021-11-05 21:19:02,497 Node[0] Epoch[19] Batch [180-200]	Speed: 164927.37 samples/sec	accuracy=nan
2021-11-05 21:19:02,889 Node[0] Epoch[19] Batch [200-220]	Speed: 166448.02 samples/sec	accuracy=nan
2021-11-05 21:19:03,282 Node[0] Epoch[19] Batch [220-240]	Speed: 165823.93 samples/sec	accuracy=nan
2021-11-05 21:19:03,675 Node[0] Epoch[19] Batch [240-260]	Speed: 166295.67 samples/sec	accuracy=nan
2021-11-05 21:19:04,070 Node[0] Epoch[19] Batch [260-280]	Speed: 165257.25 samples/sec	accuracy=nan
2021-11-05 21:19:04,464 Node[0] Epoch[19] Batch [280-300]	Speed: 165835.88 samples/sec	accuracy=nan
2021-11-05 21:19:04,857 Node[0] Epoch[19] Batch [300-320]	Speed: 165844.42 samples/sec	accuracy=nan
2021-11-05 21:19:05,252 Node[0] Epoch[19] Batch [320-340]	Speed: 165428.49 samples/sec	accuracy=nan
2021-11-05 21:19:05,651 Node[0] Epoch[19] Batch [340-360]	Speed: 163388.80 samples/sec	accuracy=nan
2021-11-05 21:19:06,050 Node[0] Epoch[19] Batch [360-380]	Speed: 163685.93 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147146286, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 20}}
2021-11-05 21:19:06,286 Node[0] Epoch[19] Time cost=7.720
:::MLLOG {"namespace": "", "time_ms": 1636147146286, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165944.11646195268}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1636147146286, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165944.11646195268, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147146286, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 21}}
2021-11-05 21:19:06,699 Node[0] Epoch[20] Batch [0-20]	Speed: 166017.68 samples/sec	accuracy=nan
2021-11-05 21:19:07,095 Node[0] Epoch[20] Batch [20-40]	Speed: 164925.78 samples/sec	accuracy=nan
2021-11-05 21:19:07,487 Node[0] Epoch[20] Batch [40-60]	Speed: 166305.27 samples/sec	accuracy=nan
2021-11-05 21:19:07,881 Node[0] Epoch[20] Batch [60-80]	Speed: 165822.02 samples/sec	accuracy=nan
2021-11-05 21:19:08,275 Node[0] Epoch[20] Batch [80-100]	Speed: 165766.81 samples/sec	accuracy=nan
2021-11-05 21:19:08,667 Node[0] Epoch[20] Batch [100-120]	Speed: 166367.01 samples/sec	accuracy=nan
2021-11-05 21:19:09,058 Node[0] Epoch[20] Batch [120-140]	Speed: 166866.97 samples/sec	accuracy=nan
2021-11-05 21:19:09,450 Node[0] Epoch[20] Batch [140-160]	Speed: 166425.06 samples/sec	accuracy=nan
2021-11-05 21:19:09,845 Node[0] Epoch[20] Batch [160-180]	Speed: 165464.88 samples/sec	accuracy=nan
2021-11-05 21:19:10,239 Node[0] Epoch[20] Batch [180-200]	Speed: 165630.83 samples/sec	accuracy=nan
2021-11-05 21:19:10,634 Node[0] Epoch[20] Batch [200-220]	Speed: 165397.61 samples/sec	accuracy=nan
2021-11-05 21:19:11,027 Node[0] Epoch[20] Batch [220-240]	Speed: 165894.26 samples/sec	accuracy=nan
2021-11-05 21:19:11,419 Node[0] Epoch[20] Batch [240-260]	Speed: 166799.47 samples/sec	accuracy=nan
2021-11-05 21:19:11,814 Node[0] Epoch[20] Batch [260-280]	Speed: 165145.02 samples/sec	accuracy=nan
2021-11-05 21:19:12,207 Node[0] Epoch[20] Batch [280-300]	Speed: 166100.27 samples/sec	accuracy=nan
2021-11-05 21:19:12,601 Node[0] Epoch[20] Batch [300-320]	Speed: 165835.28 samples/sec	accuracy=nan
2021-11-05 21:19:12,998 Node[0] Epoch[20] Batch [320-340]	Speed: 164461.86 samples/sec	accuracy=nan
2021-11-05 21:19:13,392 Node[0] Epoch[20] Batch [340-360]	Speed: 165347.47 samples/sec	accuracy=nan
2021-11-05 21:19:13,791 Node[0] Epoch[20] Batch [360-380]	Speed: 163741.82 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147154026, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 21}}
2021-11-05 21:19:14,026 Node[0] Epoch[20] Time cost=7.740
:::MLLOG {"namespace": "", "time_ms": 1636147154026, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165524.20280753932}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 21}}
:::MLLOG {"namespace": "", "time_ms": 1636147154026, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165524.20280753932, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147154027, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 22}}
2021-11-05 21:19:14,439 Node[0] Epoch[21] Batch [0-20]	Speed: 165905.22 samples/sec	accuracy=nan
2021-11-05 21:19:14,833 Node[0] Epoch[21] Batch [20-40]	Speed: 165695.18 samples/sec	accuracy=nan
2021-11-05 21:19:15,228 Node[0] Epoch[21] Batch [40-60]	Speed: 165503.08 samples/sec	accuracy=nan
2021-11-05 21:19:15,621 Node[0] Epoch[21] Batch [60-80]	Speed: 166019.60 samples/sec	accuracy=nan
2021-11-05 21:19:16,014 Node[0] Epoch[21] Batch [80-100]	Speed: 166199.78 samples/sec	accuracy=nan
2021-11-05 21:19:16,408 Node[0] Epoch[21] Batch [100-120]	Speed: 165799.73 samples/sec	accuracy=nan
2021-11-05 21:19:16,803 Node[0] Epoch[21] Batch [120-140]	Speed: 165288.08 samples/sec	accuracy=nan
2021-11-05 21:19:17,195 Node[0] Epoch[21] Batch [140-160]	Speed: 166189.89 samples/sec	accuracy=nan
2021-11-05 21:19:17,589 Node[0] Epoch[21] Batch [160-180]	Speed: 166014.56 samples/sec	accuracy=nan
2021-11-05 21:19:17,982 Node[0] Epoch[21] Batch [180-200]	Speed: 166026.74 samples/sec	accuracy=nan
2021-11-05 21:19:18,375 Node[0] Epoch[21] Batch [200-220]	Speed: 165810.27 samples/sec	accuracy=nan
2021-11-05 21:19:18,769 Node[0] Epoch[21] Batch [220-240]	Speed: 165700.80 samples/sec	accuracy=nan
2021-11-05 21:19:19,161 Node[0] Epoch[21] Batch [240-260]	Speed: 166634.82 samples/sec	accuracy=nan
2021-11-05 21:19:19,554 Node[0] Epoch[21] Batch [260-280]	Speed: 166151.87 samples/sec	accuracy=nan
2021-11-05 21:19:19,947 Node[0] Epoch[21] Batch [280-300]	Speed: 166039.73 samples/sec	accuracy=nan
2021-11-05 21:19:20,341 Node[0] Epoch[21] Batch [300-320]	Speed: 165896.77 samples/sec	accuracy=nan
2021-11-05 21:19:20,735 Node[0] Epoch[21] Batch [320-340]	Speed: 165407.70 samples/sec	accuracy=nan
2021-11-05 21:19:21,136 Node[0] Epoch[21] Batch [340-360]	Speed: 162938.71 samples/sec	accuracy=nan
2021-11-05 21:19:21,532 Node[0] Epoch[21] Batch [360-380]	Speed: 164671.16 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147161769, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 22}}
2021-11-05 21:19:21,769 Node[0] Epoch[21] Time cost=7.742
:::MLLOG {"namespace": "", "time_ms": 1636147161769, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165473.5476783711}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 22}}
:::MLLOG {"namespace": "", "time_ms": 1636147161769, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165473.5476783711, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147161769, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 23}}
2021-11-05 21:19:22,181 Node[0] Epoch[22] Batch [0-20]	Speed: 166309.41 samples/sec	accuracy=nan
2021-11-05 21:19:22,576 Node[0] Epoch[22] Batch [20-40]	Speed: 165367.64 samples/sec	accuracy=nan
2021-11-05 21:19:22,972 Node[0] Epoch[22] Batch [40-60]	Speed: 164808.04 samples/sec	accuracy=nan
2021-11-05 21:19:23,366 Node[0] Epoch[22] Batch [60-80]	Speed: 165420.49 samples/sec	accuracy=nan
2021-11-05 21:19:23,758 Node[0] Epoch[22] Batch [80-100]	Speed: 166749.08 samples/sec	accuracy=nan
2021-11-05 21:19:24,151 Node[0] Epoch[22] Batch [100-120]	Speed: 166048.39 samples/sec	accuracy=nan
2021-11-05 21:19:24,542 Node[0] Epoch[22] Batch [120-140]	Speed: 166791.34 samples/sec	accuracy=nan
2021-11-05 21:19:24,934 Node[0] Epoch[22] Batch [140-160]	Speed: 166559.70 samples/sec	accuracy=nan
2021-11-05 21:19:25,330 Node[0] Epoch[22] Batch [160-180]	Speed: 165206.00 samples/sec	accuracy=nan
2021-11-05 21:19:25,722 Node[0] Epoch[22] Batch [180-200]	Speed: 166459.05 samples/sec	accuracy=nan
2021-11-05 21:19:26,120 Node[0] Epoch[22] Batch [200-220]	Speed: 163849.80 samples/sec	accuracy=nan
2021-11-05 21:19:26,514 Node[0] Epoch[22] Batch [220-240]	Speed: 165906.83 samples/sec	accuracy=nan
2021-11-05 21:19:26,907 Node[0] Epoch[22] Batch [240-260]	Speed: 166067.93 samples/sec	accuracy=nan
2021-11-05 21:19:27,302 Node[0] Epoch[22] Batch [260-280]	Speed: 165184.97 samples/sec	accuracy=nan
2021-11-05 21:19:27,698 Node[0] Epoch[22] Batch [280-300]	Speed: 164734.66 samples/sec	accuracy=nan
2021-11-05 21:19:28,091 Node[0] Epoch[22] Batch [300-320]	Speed: 166237.42 samples/sec	accuracy=nan
2021-11-05 21:19:28,487 Node[0] Epoch[22] Batch [320-340]	Speed: 164789.99 samples/sec	accuracy=nan
2021-11-05 21:19:28,885 Node[0] Epoch[22] Batch [340-360]	Speed: 164195.28 samples/sec	accuracy=nan
2021-11-05 21:19:29,282 Node[0] Epoch[22] Batch [360-380]	Speed: 164073.37 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147169520, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 23}}
2021-11-05 21:19:29,520 Node[0] Epoch[22] Time cost=7.750
:::MLLOG {"namespace": "", "time_ms": 1636147169520, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165306.09392490084}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636147169520, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165306.09392490084, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147169536, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 23}}
2021-11-05 21:19:29,651 Node[0] Epoch[22] Validation-accuracy=0.702945
2021-11-05 21:19:29,651 Node[0] Epoch[22] Validation-correct-count=549.000000
2021-11-05 21:19:29,651 Node[0] Epoch[22] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636147169666, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636147169666, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.69852, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636147169666, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1636147169667, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 24, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636147169667, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 24}}
2021-11-05 21:19:30,064 Node[0] Epoch[23] Batch [0-20]	Speed: 166253.87 samples/sec	accuracy=nan
2021-11-05 21:19:30,458 Node[0] Epoch[23] Batch [20-40]	Speed: 165626.53 samples/sec	accuracy=nan
2021-11-05 21:19:30,852 Node[0] Epoch[23] Batch [40-60]	Speed: 165982.76 samples/sec	accuracy=nan
2021-11-05 21:19:31,247 Node[0] Epoch[23] Batch [60-80]	Speed: 165025.97 samples/sec	accuracy=nan
2021-11-05 21:19:31,643 Node[0] Epoch[23] Batch [80-100]	Speed: 165024.08 samples/sec	accuracy=nan
2021-11-05 21:19:32,034 Node[0] Epoch[23] Batch [100-120]	Speed: 166873.38 samples/sec	accuracy=nan
2021-11-05 21:19:32,428 Node[0] Epoch[23] Batch [120-140]	Speed: 165812.89 samples/sec	accuracy=nan
2021-11-05 21:19:32,821 Node[0] Epoch[23] Batch [140-160]	Speed: 165909.74 samples/sec	accuracy=nan
2021-11-05 21:19:33,216 Node[0] Epoch[23] Batch [160-180]	Speed: 165475.78 samples/sec	accuracy=nan
2021-11-05 21:19:33,609 Node[0] Epoch[23] Batch [180-200]	Speed: 165883.81 samples/sec	accuracy=nan
2021-11-05 21:19:34,004 Node[0] Epoch[23] Batch [200-220]	Speed: 165419.29 samples/sec	accuracy=nan
2021-11-05 21:19:34,398 Node[0] Epoch[23] Batch [220-240]	Speed: 165675.93 samples/sec	accuracy=nan
2021-11-05 21:19:34,791 Node[0] Epoch[23] Batch [240-260]	Speed: 166033.29 samples/sec	accuracy=nan
2021-11-05 21:19:35,185 Node[0] Epoch[23] Batch [260-280]	Speed: 165577.75 samples/sec	accuracy=nan
2021-11-05 21:19:35,577 Node[0] Epoch[23] Batch [280-300]	Speed: 166538.33 samples/sec	accuracy=nan
2021-11-05 21:19:35,973 Node[0] Epoch[23] Batch [300-320]	Speed: 164911.27 samples/sec	accuracy=nan
2021-11-05 21:19:36,368 Node[0] Epoch[23] Batch [320-340]	Speed: 165151.00 samples/sec	accuracy=nan
2021-11-05 21:19:36,764 Node[0] Epoch[23] Batch [340-360]	Speed: 165135.46 samples/sec	accuracy=nan
2021-11-05 21:19:37,162 Node[0] Epoch[23] Batch [360-380]	Speed: 163655.80 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147177399, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 24}}
2021-11-05 21:19:37,399 Node[0] Epoch[23] Time cost=7.732
:::MLLOG {"namespace": "", "time_ms": 1636147177399, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165688.2519562229}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 24}}
:::MLLOG {"namespace": "", "time_ms": 1636147177399, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165688.2519562229, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147177399, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 25}}
2021-11-05 21:19:37,821 Node[0] Epoch[24] Batch [0-20]	Speed: 170266.16 samples/sec	accuracy=nan
2021-11-05 21:19:38,214 Node[0] Epoch[24] Batch [20-40]	Speed: 166206.94 samples/sec	accuracy=nan
2021-11-05 21:19:38,608 Node[0] Epoch[24] Batch [40-60]	Speed: 165641.45 samples/sec	accuracy=nan
2021-11-05 21:19:39,000 Node[0] Epoch[24] Batch [60-80]	Speed: 166607.84 samples/sec	accuracy=nan
2021-11-05 21:19:39,395 Node[0] Epoch[24] Batch [80-100]	Speed: 165153.59 samples/sec	accuracy=nan
2021-11-05 21:19:39,787 Node[0] Epoch[24] Batch [100-120]	Speed: 166716.39 samples/sec	accuracy=nan
2021-11-05 21:19:40,179 Node[0] Epoch[24] Batch [120-140]	Speed: 166579.36 samples/sec	accuracy=nan
2021-11-05 21:19:40,571 Node[0] Epoch[24] Batch [140-160]	Speed: 166394.51 samples/sec	accuracy=nan
2021-11-05 21:19:40,964 Node[0] Epoch[24] Batch [160-180]	Speed: 166008.12 samples/sec	accuracy=nan
2021-11-05 21:19:41,357 Node[0] Epoch[24] Batch [180-200]	Speed: 166208.15 samples/sec	accuracy=nan
2021-11-05 21:19:41,750 Node[0] Epoch[24] Batch [200-220]	Speed: 166234.49 samples/sec	accuracy=nan
2021-11-05 21:19:42,142 Node[0] Epoch[24] Batch [220-240]	Speed: 166238.23 samples/sec	accuracy=nan
2021-11-05 21:19:42,537 Node[0] Epoch[24] Batch [240-260]	Speed: 165235.71 samples/sec	accuracy=nan
2021-11-05 21:19:42,933 Node[0] Epoch[24] Batch [260-280]	Speed: 165202.81 samples/sec	accuracy=nan
2021-11-05 21:19:43,325 Node[0] Epoch[24] Batch [280-300]	Speed: 166406.34 samples/sec	accuracy=nan
2021-11-05 21:19:43,719 Node[0] Epoch[24] Batch [300-320]	Speed: 165682.45 samples/sec	accuracy=nan
2021-11-05 21:19:44,116 Node[0] Epoch[24] Batch [320-340]	Speed: 164412.58 samples/sec	accuracy=nan
2021-11-05 21:19:44,514 Node[0] Epoch[24] Batch [340-360]	Speed: 164000.06 samples/sec	accuracy=nan
2021-11-05 21:19:44,911 Node[0] Epoch[24] Batch [360-380]	Speed: 164271.43 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147185147, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1636147185147, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165362.5747173127}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 25}}
2021-11-05 21:19:45,147 Node[0] Epoch[24] Time cost=7.748
:::MLLOG {"namespace": "", "time_ms": 1636147185147, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165362.5747173127, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147185147, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 26}}
2021-11-05 21:19:45,562 Node[0] Epoch[25] Batch [0-20]	Speed: 165010.96 samples/sec	accuracy=nan
2021-11-05 21:19:45,955 Node[0] Epoch[25] Batch [20-40]	Speed: 166139.57 samples/sec	accuracy=nan
2021-11-05 21:19:46,351 Node[0] Epoch[25] Batch [40-60]	Speed: 165021.30 samples/sec	accuracy=nan
2021-11-05 21:19:46,744 Node[0] Epoch[25] Batch [60-80]	Speed: 165930.76 samples/sec	accuracy=nan
2021-11-05 21:19:47,136 Node[0] Epoch[25] Batch [80-100]	Speed: 166443.37 samples/sec	accuracy=nan
2021-11-05 21:19:47,529 Node[0] Epoch[25] Batch [100-120]	Speed: 166302.24 samples/sec	accuracy=nan
2021-11-05 21:19:47,923 Node[0] Epoch[25] Batch [120-140]	Speed: 165582.25 samples/sec	accuracy=nan
2021-11-05 21:19:48,315 Node[0] Epoch[25] Batch [140-160]	Speed: 166551.80 samples/sec	accuracy=nan
2021-11-05 21:19:48,708 Node[0] Epoch[25] Batch [160-180]	Speed: 166280.32 samples/sec	accuracy=nan
2021-11-05 21:19:49,099 Node[0] Epoch[25] Batch [180-200]	Speed: 166789.72 samples/sec	accuracy=nan
2021-11-05 21:19:49,494 Node[0] Epoch[25] Batch [200-220]	Speed: 165122.21 samples/sec	accuracy=nan
2021-11-05 21:19:49,888 Node[0] Epoch[25] Batch [220-240]	Speed: 165934.68 samples/sec	accuracy=nan
2021-11-05 21:19:50,281 Node[0] Epoch[25] Batch [240-260]	Speed: 166066.92 samples/sec	accuracy=nan
2021-11-05 21:19:50,675 Node[0] Epoch[25] Batch [260-280]	Speed: 165548.71 samples/sec	accuracy=nan
2021-11-05 21:19:51,067 Node[0] Epoch[25] Batch [280-300]	Speed: 166719.44 samples/sec	accuracy=nan
2021-11-05 21:19:51,462 Node[0] Epoch[25] Batch [300-320]	Speed: 165191.75 samples/sec	accuracy=nan
2021-11-05 21:19:51,857 Node[0] Epoch[25] Batch [320-340]	Speed: 165292.37 samples/sec	accuracy=nan
2021-11-05 21:19:52,257 Node[0] Epoch[25] Batch [340-360]	Speed: 163078.85 samples/sec	accuracy=nan
2021-11-05 21:19:52,654 Node[0] Epoch[25] Batch [360-380]	Speed: 164449.12 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147192892, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 26}}
2021-11-05 21:19:52,892 Node[0] Epoch[25] Time cost=7.745
:::MLLOG {"namespace": "", "time_ms": 1636147192892, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165420.1685805648}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 26}}
:::MLLOG {"namespace": "", "time_ms": 1636147192893, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165420.1685805648, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147192893, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 27}}
2021-11-05 21:19:53,305 Node[0] Epoch[26] Batch [0-20]	Speed: 166284.57 samples/sec	accuracy=nan
2021-11-05 21:19:53,699 Node[0] Epoch[26] Batch [20-40]	Speed: 165619.71 samples/sec	accuracy=nan
2021-11-05 21:19:54,091 Node[0] Epoch[26] Batch [40-60]	Speed: 166276.18 samples/sec	accuracy=nan
2021-11-05 21:19:54,484 Node[0] Epoch[26] Batch [60-80]	Speed: 166377.83 samples/sec	accuracy=nan
2021-11-05 21:19:54,879 Node[0] Epoch[26] Batch [80-100]	Speed: 165131.07 samples/sec	accuracy=nan
2021-11-05 21:19:55,270 Node[0] Epoch[26] Batch [100-120]	Speed: 166751.93 samples/sec	accuracy=nan
2021-11-05 21:19:55,662 Node[0] Epoch[26] Batch [120-140]	Speed: 166715.58 samples/sec	accuracy=nan
2021-11-05 21:19:56,054 Node[0] Epoch[26] Batch [140-160]	Speed: 166480.91 samples/sec	accuracy=nan
2021-11-05 21:19:56,448 Node[0] Epoch[26] Batch [160-180]	Speed: 165599.28 samples/sec	accuracy=nan
2021-11-05 21:19:56,843 Node[0] Epoch[26] Batch [180-200]	Speed: 165219.06 samples/sec	accuracy=nan
2021-11-05 21:19:57,238 Node[0] Epoch[26] Batch [200-220]	Speed: 165276.21 samples/sec	accuracy=nan
2021-11-05 21:19:57,632 Node[0] Epoch[26] Batch [220-240]	Speed: 165946.85 samples/sec	accuracy=nan
2021-11-05 21:19:58,025 Node[0] Epoch[26] Batch [240-260]	Speed: 165984.87 samples/sec	accuracy=nan
2021-11-05 21:19:58,417 Node[0] Epoch[26] Batch [260-280]	Speed: 166787.79 samples/sec	accuracy=nan
2021-11-05 21:19:58,811 Node[0] Epoch[26] Batch [280-300]	Speed: 165305.54 samples/sec	accuracy=nan
2021-11-05 21:19:59,204 Node[0] Epoch[26] Batch [300-320]	Speed: 166208.56 samples/sec	accuracy=nan
2021-11-05 21:19:59,603 Node[0] Epoch[26] Batch [320-340]	Speed: 163796.19 samples/sec	accuracy=nan
2021-11-05 21:20:00,001 Node[0] Epoch[26] Batch [340-360]	Speed: 163767.58 samples/sec	accuracy=nan
2021-11-05 21:20:00,397 Node[0] Epoch[26] Batch [360-380]	Speed: 165068.16 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147200633, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636147200633, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165517.82970871642}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 27}}
2021-11-05 21:20:00,633 Node[0] Epoch[26] Time cost=7.740
:::MLLOG {"namespace": "", "time_ms": 1636147200633, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165517.82970871642, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147200649, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 27}}
2021-11-05 21:20:00,771 Node[0] Epoch[26] Validation-accuracy=0.745198
2021-11-05 21:20:00,771 Node[0] Epoch[26] Validation-correct-count=582.000000
2021-11-05 21:20:00,771 Node[0] Epoch[26] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636147200782, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636147200782, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.73116, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636147200782, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1636147200782, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 28, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636147200782, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 28}}
2021-11-05 21:20:01,179 Node[0] Epoch[27] Batch [0-20]	Speed: 166730.30 samples/sec	accuracy=nan
2021-11-05 21:20:01,572 Node[0] Epoch[27] Batch [20-40]	Speed: 166076.29 samples/sec	accuracy=nan
2021-11-05 21:20:01,965 Node[0] Epoch[27] Batch [40-60]	Speed: 165977.23 samples/sec	accuracy=nan
2021-11-05 21:20:02,358 Node[0] Epoch[27] Batch [60-80]	Speed: 166336.29 samples/sec	accuracy=nan
2021-11-05 21:20:02,750 Node[0] Epoch[27] Batch [80-100]	Speed: 166332.04 samples/sec	accuracy=nan
2021-11-05 21:20:03,143 Node[0] Epoch[27] Batch [100-120]	Speed: 166295.78 samples/sec	accuracy=nan
2021-11-05 21:20:03,537 Node[0] Epoch[27] Batch [120-140]	Speed: 165510.09 samples/sec	accuracy=nan
2021-11-05 21:20:03,929 Node[0] Epoch[27] Batch [140-160]	Speed: 166510.98 samples/sec	accuracy=nan
2021-11-05 21:20:04,322 Node[0] Epoch[27] Batch [160-180]	Speed: 166347.10 samples/sec	accuracy=nan
2021-11-05 21:20:04,715 Node[0] Epoch[27] Batch [180-200]	Speed: 165948.46 samples/sec	accuracy=nan
2021-11-05 21:20:05,109 Node[0] Epoch[27] Batch [200-220]	Speed: 165818.81 samples/sec	accuracy=nan
2021-11-05 21:20:05,501 Node[0] Epoch[27] Batch [220-240]	Speed: 166306.08 samples/sec	accuracy=nan
2021-11-05 21:20:05,893 Node[0] Epoch[27] Batch [240-260]	Speed: 166433.05 samples/sec	accuracy=nan
2021-11-05 21:20:06,286 Node[0] Epoch[27] Batch [260-280]	Speed: 166378.13 samples/sec	accuracy=nan
2021-11-05 21:20:06,679 Node[0] Epoch[27] Batch [280-300]	Speed: 166180.82 samples/sec	accuracy=nan
2021-11-05 21:20:07,074 Node[0] Epoch[27] Batch [300-320]	Speed: 165302.65 samples/sec	accuracy=nan
2021-11-05 21:20:07,471 Node[0] Epoch[27] Batch [320-340]	Speed: 164362.64 samples/sec	accuracy=nan
2021-11-05 21:20:07,867 Node[0] Epoch[27] Batch [340-360]	Speed: 164786.71 samples/sec	accuracy=nan
2021-11-05 21:20:08,265 Node[0] Epoch[27] Batch [360-380]	Speed: 163873.73 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147208501, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 28}}
2021-11-05 21:20:08,502 Node[0] Epoch[27] Time cost=7.719
:::MLLOG {"namespace": "", "time_ms": 1636147208502, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165975.22847964347}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 28}}
:::MLLOG {"namespace": "", "time_ms": 1636147208502, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165975.22847964347, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147208502, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 29}}
2021-11-05 21:20:08,915 Node[0] Epoch[28] Batch [0-20]	Speed: 165644.46 samples/sec	accuracy=nan
2021-11-05 21:20:09,309 Node[0] Epoch[28] Batch [20-40]	Speed: 165888.43 samples/sec	accuracy=nan
2021-11-05 21:20:09,701 Node[0] Epoch[28] Batch [40-60]	Speed: 166450.25 samples/sec	accuracy=nan
2021-11-05 21:20:10,094 Node[0] Epoch[28] Batch [60-80]	Speed: 166122.54 samples/sec	accuracy=nan
2021-11-05 21:20:10,486 Node[0] Epoch[28] Batch [80-100]	Speed: 166674.27 samples/sec	accuracy=nan
2021-11-05 21:20:10,880 Node[0] Epoch[28] Batch [100-120]	Speed: 165654.48 samples/sec	accuracy=nan
2021-11-05 21:20:11,273 Node[0] Epoch[28] Batch [120-140]	Speed: 165940.41 samples/sec	accuracy=nan
2021-11-05 21:20:11,667 Node[0] Epoch[28] Batch [140-160]	Speed: 165680.04 samples/sec	accuracy=nan
2021-11-05 21:20:12,060 Node[0] Epoch[28] Batch [160-180]	Speed: 165903.91 samples/sec	accuracy=nan
2021-11-05 21:20:12,452 Node[0] Epoch[28] Batch [180-200]	Speed: 166643.23 samples/sec	accuracy=nan
2021-11-05 21:20:12,846 Node[0] Epoch[28] Batch [200-220]	Speed: 165897.28 samples/sec	accuracy=nan
2021-11-05 21:20:13,238 Node[0] Epoch[28] Batch [220-240]	Speed: 166246.00 samples/sec	accuracy=nan
2021-11-05 21:20:13,630 Node[0] Epoch[28] Batch [240-260]	Speed: 166737.51 samples/sec	accuracy=nan
2021-11-05 21:20:14,025 Node[0] Epoch[28] Batch [260-280]	Speed: 165421.49 samples/sec	accuracy=nan
2021-11-05 21:20:14,418 Node[0] Epoch[28] Batch [280-300]	Speed: 165765.40 samples/sec	accuracy=nan
2021-11-05 21:20:14,811 Node[0] Epoch[28] Batch [300-320]	Speed: 166067.73 samples/sec	accuracy=nan
2021-11-05 21:20:15,209 Node[0] Epoch[28] Batch [320-340]	Speed: 164395.80 samples/sec	accuracy=nan
2021-11-05 21:20:15,605 Node[0] Epoch[28] Batch [340-360]	Speed: 164594.14 samples/sec	accuracy=nan
2021-11-05 21:20:16,000 Node[0] Epoch[28] Batch [360-380]	Speed: 165207.60 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147216238, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 29}}
2021-11-05 21:20:16,238 Node[0] Epoch[28] Time cost=7.736
:::MLLOG {"namespace": "", "time_ms": 1636147216238, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165601.6879417552}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 29}}
:::MLLOG {"namespace": "", "time_ms": 1636147216238, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165601.6879417552, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147216239, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 30}}
2021-11-05 21:20:16,651 Node[0] Epoch[29] Batch [0-20]	Speed: 165900.79 samples/sec	accuracy=nan
2021-11-05 21:20:17,045 Node[0] Epoch[29] Batch [20-40]	Speed: 165692.58 samples/sec	accuracy=nan
2021-11-05 21:20:17,438 Node[0] Epoch[29] Batch [40-60]	Speed: 166206.94 samples/sec	accuracy=nan
2021-11-05 21:20:17,830 Node[0] Epoch[29] Batch [60-80]	Speed: 166502.27 samples/sec	accuracy=nan
2021-11-05 21:20:18,222 Node[0] Epoch[29] Batch [80-100]	Speed: 166421.01 samples/sec	accuracy=nan
2021-11-05 21:20:18,616 Node[0] Epoch[29] Batch [100-120]	Speed: 165761.99 samples/sec	accuracy=nan
2021-11-05 21:20:19,008 Node[0] Epoch[29] Batch [120-140]	Speed: 166437.40 samples/sec	accuracy=nan
2021-11-05 21:20:19,400 Node[0] Epoch[29] Batch [140-160]	Speed: 166733.14 samples/sec	accuracy=nan
2021-11-05 21:20:19,793 Node[0] Epoch[29] Batch [160-180]	Speed: 166285.68 samples/sec	accuracy=nan
2021-11-05 21:20:20,186 Node[0] Epoch[29] Batch [180-200]	Speed: 165941.11 samples/sec	accuracy=nan
2021-11-05 21:20:20,579 Node[0] Epoch[29] Batch [200-220]	Speed: 166175.17 samples/sec	accuracy=nan
2021-11-05 21:20:20,974 Node[0] Epoch[29] Batch [220-240]	Speed: 165110.46 samples/sec	accuracy=nan
2021-11-05 21:20:21,368 Node[0] Epoch[29] Batch [240-260]	Speed: 165589.36 samples/sec	accuracy=nan
2021-11-05 21:20:21,760 Node[0] Epoch[29] Batch [260-280]	Speed: 166557.17 samples/sec	accuracy=nan
2021-11-05 21:20:22,152 Node[0] Epoch[29] Batch [280-300]	Speed: 166585.04 samples/sec	accuracy=nan
2021-11-05 21:20:22,546 Node[0] Epoch[29] Batch [300-320]	Speed: 165977.93 samples/sec	accuracy=nan
2021-11-05 21:20:22,942 Node[0] Epoch[29] Batch [320-340]	Speed: 164502.47 samples/sec	accuracy=nan
2021-11-05 21:20:23,340 Node[0] Epoch[29] Batch [340-360]	Speed: 164045.85 samples/sec	accuracy=nan
2021-11-05 21:20:23,737 Node[0] Epoch[29] Batch [360-380]	Speed: 164542.11 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147223973, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 30}}
2021-11-05 21:20:23,973 Node[0] Epoch[29] Time cost=7.734
:::MLLOG {"namespace": "", "time_ms": 1636147223973, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165647.6981169672}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 30}}
:::MLLOG {"namespace": "", "time_ms": 1636147223973, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165647.6981169672, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147223973, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 31}}
2021-11-05 21:20:24,385 Node[0] Epoch[30] Batch [0-20]	Speed: 166258.11 samples/sec	accuracy=nan
2021-11-05 21:20:24,779 Node[0] Epoch[30] Batch [20-40]	Speed: 165636.85 samples/sec	accuracy=nan
2021-11-05 21:20:25,171 Node[0] Epoch[30] Batch [40-60]	Speed: 166634.82 samples/sec	accuracy=nan
2021-11-05 21:20:25,562 Node[0] Epoch[30] Batch [60-80]	Speed: 167078.86 samples/sec	accuracy=nan
2021-11-05 21:20:25,957 Node[0] Epoch[30] Batch [80-100]	Speed: 165377.53 samples/sec	accuracy=nan
2021-11-05 21:20:26,349 Node[0] Epoch[30] Batch [100-120]	Speed: 166513.82 samples/sec	accuracy=nan
2021-11-05 21:20:26,740 Node[0] Epoch[30] Batch [120-140]	Speed: 166642.63 samples/sec	accuracy=nan
2021-11-05 21:20:27,135 Node[0] Epoch[30] Batch [140-160]	Speed: 165437.18 samples/sec	accuracy=nan
2021-11-05 21:20:27,527 Node[0] Epoch[30] Batch [160-180]	Speed: 166639.38 samples/sec	accuracy=nan
2021-11-05 21:20:27,921 Node[0] Epoch[30] Batch [180-200]	Speed: 165432.09 samples/sec	accuracy=nan
2021-11-05 21:20:28,317 Node[0] Epoch[30] Batch [200-220]	Speed: 165063.98 samples/sec	accuracy=nan
2021-11-05 21:20:28,709 Node[0] Epoch[30] Batch [220-240]	Speed: 166219.05 samples/sec	accuracy=nan
2021-11-05 21:20:29,102 Node[0] Epoch[30] Batch [240-260]	Speed: 166305.88 samples/sec	accuracy=nan
2021-11-05 21:20:29,498 Node[0] Epoch[30] Batch [260-280]	Speed: 164788.60 samples/sec	accuracy=nan
2021-11-05 21:20:29,891 Node[0] Epoch[30] Batch [280-300]	Speed: 166040.33 samples/sec	accuracy=nan
2021-11-05 21:20:30,286 Node[0] Epoch[30] Batch [300-320]	Speed: 165304.64 samples/sec	accuracy=nan
2021-11-05 21:20:30,682 Node[0] Epoch[30] Batch [320-340]	Speed: 164859.54 samples/sec	accuracy=nan
2021-11-05 21:20:31,081 Node[0] Epoch[30] Batch [340-360]	Speed: 163666.85 samples/sec	accuracy=nan
2021-11-05 21:20:31,482 Node[0] Epoch[30] Batch [360-380]	Speed: 162904.39 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147231717, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 31}}
2021-11-05 21:20:31,717 Node[0] Epoch[30] Time cost=7.743
:::MLLOG {"namespace": "", "time_ms": 1636147231717, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165453.98306000727}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636147231717, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165453.98306000727, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147231734, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 31}}
2021-11-05 21:20:31,846 Node[0] Epoch[30] Validation-accuracy=0.761844
2021-11-05 21:20:31,846 Node[0] Epoch[30] Validation-correct-count=595.000000
2021-11-05 21:20:31,846 Node[0] Epoch[30] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636147231863, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636147231864, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.75136, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636147231864, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1636147231864, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 32, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636147231864, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 32}}
2021-11-05 21:20:32,261 Node[0] Epoch[31] Batch [0-20]	Speed: 166294.56 samples/sec	accuracy=nan
2021-11-05 21:20:32,654 Node[0] Epoch[31] Batch [20-40]	Speed: 166222.18 samples/sec	accuracy=nan
2021-11-05 21:20:33,046 Node[0] Epoch[31] Batch [40-60]	Speed: 166393.20 samples/sec	accuracy=nan
2021-11-05 21:20:33,439 Node[0] Epoch[31] Batch [60-80]	Speed: 166141.89 samples/sec	accuracy=nan
2021-11-05 21:20:33,835 Node[0] Epoch[31] Batch [80-100]	Speed: 164938.39 samples/sec	accuracy=nan
2021-11-05 21:20:34,228 Node[0] Epoch[31] Batch [100-120]	Speed: 166042.45 samples/sec	accuracy=nan
2021-11-05 21:20:34,621 Node[0] Epoch[31] Batch [120-140]	Speed: 165987.09 samples/sec	accuracy=nan
2021-11-05 21:20:35,015 Node[0] Epoch[31] Batch [140-160]	Speed: 165719.75 samples/sec	accuracy=nan
2021-11-05 21:20:35,409 Node[0] Epoch[31] Batch [160-180]	Speed: 165993.33 samples/sec	accuracy=nan
2021-11-05 21:20:35,802 Node[0] Epoch[31] Batch [180-200]	Speed: 165730.69 samples/sec	accuracy=nan
2021-11-05 21:20:36,194 Node[0] Epoch[31] Batch [200-220]	Speed: 166690.51 samples/sec	accuracy=nan
2021-11-05 21:20:36,586 Node[0] Epoch[31] Batch [220-240]	Speed: 166373.68 samples/sec	accuracy=nan
2021-11-05 21:20:36,980 Node[0] Epoch[31] Batch [240-260]	Speed: 165789.89 samples/sec	accuracy=nan
2021-11-05 21:20:37,374 Node[0] Epoch[31] Batch [260-280]	Speed: 165934.48 samples/sec	accuracy=nan
2021-11-05 21:20:37,766 Node[0] Epoch[31] Batch [280-300]	Speed: 166376.72 samples/sec	accuracy=nan
2021-11-05 21:20:38,160 Node[0] Epoch[31] Batch [300-320]	Speed: 165798.13 samples/sec	accuracy=nan
2021-11-05 21:20:38,556 Node[0] Epoch[31] Batch [320-340]	Speed: 164815.38 samples/sec	accuracy=nan
2021-11-05 21:20:38,955 Node[0] Epoch[31] Batch [340-360]	Speed: 163403.91 samples/sec	accuracy=nan
2021-11-05 21:20:39,351 Node[0] Epoch[31] Batch [360-380]	Speed: 165086.47 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147239587, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 32}}
2021-11-05 21:20:39,587 Node[0] Epoch[31] Time cost=7.723
:::MLLOG {"namespace": "", "time_ms": 1636147239587, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165887.32483783967}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 32}}
:::MLLOG {"namespace": "", "time_ms": 1636147239587, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165887.32483783967, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147239587, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 33}}
2021-11-05 21:20:39,998 Node[0] Epoch[32] Batch [0-20]	Speed: 166746.95 samples/sec	accuracy=nan
2021-11-05 21:20:40,392 Node[0] Epoch[32] Batch [20-40]	Speed: 165873.76 samples/sec	accuracy=nan
2021-11-05 21:20:40,783 Node[0] Epoch[32] Batch [40-60]	Speed: 167061.43 samples/sec	accuracy=nan
2021-11-05 21:20:41,177 Node[0] Epoch[32] Batch [60-80]	Speed: 165682.55 samples/sec	accuracy=nan
2021-11-05 21:20:41,571 Node[0] Epoch[32] Batch [80-100]	Speed: 165529.40 samples/sec	accuracy=nan
2021-11-05 21:20:41,966 Node[0] Epoch[32] Batch [100-120]	Speed: 165448.38 samples/sec	accuracy=nan
2021-11-05 21:20:42,359 Node[0] Epoch[32] Batch [120-140]	Speed: 165867.03 samples/sec	accuracy=nan
2021-11-05 21:20:42,753 Node[0] Epoch[32] Batch [140-160]	Speed: 165740.22 samples/sec	accuracy=nan
2021-11-05 21:20:43,147 Node[0] Epoch[32] Batch [160-180]	Speed: 165712.33 samples/sec	accuracy=nan
2021-11-05 21:20:43,542 Node[0] Epoch[32] Batch [180-200]	Speed: 165302.95 samples/sec	accuracy=nan
2021-11-05 21:20:43,934 Node[0] Epoch[32] Batch [200-220]	Speed: 166535.69 samples/sec	accuracy=nan
2021-11-05 21:20:44,326 Node[0] Epoch[32] Batch [220-240]	Speed: 166507.03 samples/sec	accuracy=nan
2021-11-05 21:20:44,720 Node[0] Epoch[32] Batch [240-260]	Speed: 165756.57 samples/sec	accuracy=nan
2021-11-05 21:20:45,114 Node[0] Epoch[32] Batch [260-280]	Speed: 165631.03 samples/sec	accuracy=nan
2021-11-05 21:20:45,506 Node[0] Epoch[32] Batch [280-300]	Speed: 166447.21 samples/sec	accuracy=nan
2021-11-05 21:20:45,903 Node[0] Epoch[32] Batch [300-320]	Speed: 164575.44 samples/sec	accuracy=nan
2021-11-05 21:20:46,298 Node[0] Epoch[32] Batch [320-340]	Speed: 165392.21 samples/sec	accuracy=nan
2021-11-05 21:20:46,695 Node[0] Epoch[32] Batch [340-360]	Speed: 164334.72 samples/sec	accuracy=nan
2021-11-05 21:20:47,090 Node[0] Epoch[32] Batch [360-380]	Speed: 165053.73 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147247325, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 33}}
2021-11-05 21:20:47,325 Node[0] Epoch[32] Time cost=7.738
:::MLLOG {"namespace": "", "time_ms": 1636147247325, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165569.26696854216}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 33}}
:::MLLOG {"namespace": "", "time_ms": 1636147247326, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165569.26696854216, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147247326, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 34}}
2021-11-05 21:20:47,739 Node[0] Epoch[33] Batch [0-20]	Speed: 165663.00 samples/sec	accuracy=nan
2021-11-05 21:20:48,133 Node[0] Epoch[33] Batch [20-40]	Speed: 165700.20 samples/sec	accuracy=nan
2021-11-05 21:20:48,527 Node[0] Epoch[33] Batch [40-60]	Speed: 165655.89 samples/sec	accuracy=nan
2021-11-05 21:20:48,920 Node[0] Epoch[33] Batch [60-80]	Speed: 165838.70 samples/sec	accuracy=nan
2021-11-05 21:20:49,314 Node[0] Epoch[33] Batch [80-100]	Speed: 165812.58 samples/sec	accuracy=nan
2021-11-05 21:20:49,706 Node[0] Epoch[33] Batch [100-120]	Speed: 166708.07 samples/sec	accuracy=nan
2021-11-05 21:20:50,099 Node[0] Epoch[33] Batch [120-140]	Speed: 165825.54 samples/sec	accuracy=nan
2021-11-05 21:20:50,491 Node[0] Epoch[33] Batch [140-160]	Speed: 166404.52 samples/sec	accuracy=nan
2021-11-05 21:20:50,886 Node[0] Epoch[33] Batch [160-180]	Speed: 165671.72 samples/sec	accuracy=nan
2021-11-05 21:20:51,279 Node[0] Epoch[33] Batch [180-200]	Speed: 166021.00 samples/sec	accuracy=nan
2021-11-05 21:20:51,671 Node[0] Epoch[33] Batch [200-220]	Speed: 166217.94 samples/sec	accuracy=nan
2021-11-05 21:20:52,066 Node[0] Epoch[33] Batch [220-240]	Speed: 165520.89 samples/sec	accuracy=nan
2021-11-05 21:20:52,458 Node[0] Epoch[33] Batch [240-260]	Speed: 166565.48 samples/sec	accuracy=nan
2021-11-05 21:20:52,851 Node[0] Epoch[33] Batch [260-280]	Speed: 165991.82 samples/sec	accuracy=nan
2021-11-05 21:20:53,244 Node[0] Epoch[33] Batch [280-300]	Speed: 166309.41 samples/sec	accuracy=nan
2021-11-05 21:20:53,640 Node[0] Epoch[33] Batch [300-320]	Speed: 164818.26 samples/sec	accuracy=nan
2021-11-05 21:20:54,035 Node[0] Epoch[33] Batch [320-340]	Speed: 164958.76 samples/sec	accuracy=nan
2021-11-05 21:20:54,432 Node[0] Epoch[33] Batch [340-360]	Speed: 164485.97 samples/sec	accuracy=nan
2021-11-05 21:20:54,832 Node[0] Epoch[33] Batch [360-380]	Speed: 163487.04 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147255068, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 34}}
2021-11-05 21:20:55,068 Node[0] Epoch[33] Time cost=7.742
:::MLLOG {"namespace": "", "time_ms": 1636147255068, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165478.67906154538}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 34}}
:::MLLOG {"namespace": "", "time_ms": 1636147255068, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165478.67906154538, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147255068, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 35}}
2021-11-05 21:20:55,480 Node[0] Epoch[34] Batch [0-20]	Speed: 165979.64 samples/sec	accuracy=nan
2021-11-05 21:20:55,872 Node[0] Epoch[34] Batch [20-40]	Speed: 166534.07 samples/sec	accuracy=nan
2021-11-05 21:20:56,264 Node[0] Epoch[34] Batch [40-60]	Speed: 166453.49 samples/sec	accuracy=nan
2021-11-05 21:20:56,656 Node[0] Epoch[34] Batch [60-80]	Speed: 166838.09 samples/sec	accuracy=nan
2021-11-05 21:20:57,049 Node[0] Epoch[34] Batch [80-100]	Speed: 166000.17 samples/sec	accuracy=nan
2021-11-05 21:20:57,439 Node[0] Epoch[34] Batch [100-120]	Speed: 167147.10 samples/sec	accuracy=nan
2021-11-05 21:20:57,831 Node[0] Epoch[34] Batch [120-140]	Speed: 166646.99 samples/sec	accuracy=nan
2021-11-05 21:20:58,224 Node[0] Epoch[34] Batch [140-160]	Speed: 166093.42 samples/sec	accuracy=nan
2021-11-05 21:20:58,617 Node[0] Epoch[34] Batch [160-180]	Speed: 166082.13 samples/sec	accuracy=nan
2021-11-05 21:20:59,012 Node[0] Epoch[34] Batch [180-200]	Speed: 165440.98 samples/sec	accuracy=nan
2021-11-05 21:20:59,407 Node[0] Epoch[34] Batch [200-220]	Speed: 165280.30 samples/sec	accuracy=nan
2021-11-05 21:20:59,799 Node[0] Epoch[34] Batch [220-240]	Speed: 166289.41 samples/sec	accuracy=nan
2021-11-05 21:21:00,192 Node[0] Epoch[34] Batch [240-260]	Speed: 166204.12 samples/sec	accuracy=nan
2021-11-05 21:21:00,584 Node[0] Epoch[34] Batch [260-280]	Speed: 166622.44 samples/sec	accuracy=nan
2021-11-05 21:21:00,977 Node[0] Epoch[34] Batch [280-300]	Speed: 166028.66 samples/sec	accuracy=nan
2021-11-05 21:21:01,373 Node[0] Epoch[34] Batch [300-320]	Speed: 165067.06 samples/sec	accuracy=nan
2021-11-05 21:21:01,768 Node[0] Epoch[34] Batch [320-340]	Speed: 165256.35 samples/sec	accuracy=nan
2021-11-05 21:21:02,167 Node[0] Epoch[34] Batch [340-360]	Speed: 163426.83 samples/sec	accuracy=nan
2021-11-05 21:21:02,561 Node[0] Epoch[34] Batch [360-380]	Speed: 165796.22 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636147262798, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 35}}
2021-11-05 21:21:02,798 Node[0] Epoch[34] Time cost=7.730
:::MLLOG {"namespace": "", "time_ms": 1636147262798, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165745.1578355677}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636147262798, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165745.1578355677, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636147262815, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 35}}
2021-11-05 21:21:02,929 Node[0] Epoch[34] Validation-accuracy=0.770807
2021-11-05 21:21:02,929 Node[0] Epoch[34] Validation-correct-count=602.000000
2021-11-05 21:21:02,929 Node[0] Epoch[34] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636147262947, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636147262947, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.76026, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636147262947, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1636147262947, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1051, "status": "success"}}
ENDING TIMING RUN AT 2021-11-05 09:21:22 PM
RESULT,IMAGE_CLASSIFICATION,,429,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:22 PM
RESULT,IMAGE_CLASSIFICATION,,429,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:24 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:24 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:24 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:24 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:24 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:24 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:24 PM
ENDING TIMING RUN AT 2021-11-05 09:21:24 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:14:13 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:25 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:25 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:25 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:25 PM
ENDING TIMING RUN AT 2021-11-05 09:21:25 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 09:14:13 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:25 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:25 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:25 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:26 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:27 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:27 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:27 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:27 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:27 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:27 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:27 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:27 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:27 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:27 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:27 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:27 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:28 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:28 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:28 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:28 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:28 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:29 PM
ENDING TIMING RUN AT 2021-11-05 09:21:29 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 09:14:13 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:29 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:29 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:29 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:29 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:29 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:31 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:32 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 09:14:13 PM
ENDING TIMING RUN AT 2021-11-05 09:21:32 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 09:14:13 PM
