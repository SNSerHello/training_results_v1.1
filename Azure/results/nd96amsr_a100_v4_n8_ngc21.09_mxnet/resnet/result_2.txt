+ : DGXA100_multi_8x8x51
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/resnetv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211105205907015738801
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data
+ : /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.205906
+ : ''
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ echo

+ '[' '!' -z ']'
+ LOGBASE=rsnt50_8x8x51_211105205907015738801
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _seed_override=
+ _seed_override=
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.205906/rsnt50_8x8x51_211105205907015738801
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.205906/rsnt50_8x8x51_211105205907015738801
+ readonly _cont_name=image_classification
+ _cont_name=image_classification
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data:/data,/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.205906:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job10871/slurm_script: line 48: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.205906
+ srun --ntasks=8 mkdir -p /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.205906
+ srun --ntasks=8 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/resnetv11.sqsh --container-name=image_classification true
+ echo 'RUN_NCCL_BW_TEST = 0'
RUN_NCCL_BW_TEST = 0
+ [[ 0 -eq 1 ]]
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.205906/rsnt50_8x8x51_211105205907015738801_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ srun -N1 -n1 --container-name=image_classification python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.RESNET)'
:::MLLOG {"namespace": "", "time_ms": 1636145950410, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "resnet", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 70}}
:::MLLOG {"namespace": "", "time_ms": 1636145950417, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1636145950417, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 79}}
:::MLLOG {"namespace": "", "time_ms": 1636145950417, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 83}}
:::MLLOG {"namespace": "", "time_ms": 1636145950417, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 87}}
[1636145950.391539] [ip-0A0C0406:91278:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C0406
Clearing cache on ip-0A0C0409
Clearing cache on ip-0A0C040A
Clearing cache on ip-0A0C040D
Clearing cache on ip-0A0C0408
Clearing cache on ip-0A0C040C
Clearing cache on ip-0A0C040F
Clearing cache on ip-0A0C0407
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=image_classification python -c '
from mlperf_logging.mllog import constants
from mlperf_log_utils import mx_resnet_print_event
mx_resnet_print_event(key=constants.CACHE_CLEAR, val=True)'
:::MLLOG {"namespace": "", "time_ms": 1636145955322, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
[1636145955.236164] [ip-0A0C040A:89968:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145955.132205] [ip-0A0C0409:89452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145955.244316] [ip-0A0C0408:90344:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145955.124704] [ip-0A0C040D:90235:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145955.107743] [ip-0A0C040F:90197:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145955.298728] [ip-0A0C0407:90131:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145955.076206] [ip-0A0C040C:89638:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145955.264993] [ip-0A0C0406:91788:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
+ export SEED=1246
+ SEED=1246
+ srun --kill-on-bad-exit=0 --mpi=pmix --ntasks=64 --ntasks-per-node=8 --container-name=image_classification --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data:/data,/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.205906:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:59:16 PM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
--dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 num_sockets = 2 num_nodes=4 cores_per_socket=48
--dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 -+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
-dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 num_sockets = 2 num_nodes=4 cores_per_socket=48
--dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 num_sockets = 2 num_nodes=4 cores_per_socket=48
--dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 1246 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
:::MLLOG {"namespace": "", "time_ms": 1636145962007, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962008, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962007, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962007, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962007, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962008, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962008, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962008, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962008, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962009, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962008, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962008, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962007, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962007, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962007, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962008, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962013, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962012, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962012, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962013, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962013, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962013, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962013, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962013, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962006, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962006, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962010, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962006, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962006, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962006, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962006, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962006, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145962006, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
[1636145961.668792] [ip-0A0C0409:90303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.884203] [ip-0A0C0409:90310:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.824714] [ip-0A0C0409:90309:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.884003] [ip-0A0C0409:90306:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145961.879729] [ip-0A0C040C:90493:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.707203] [ip-0A0C040C:90491:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.846107] [ip-0A0C0409:90307:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.893242] [ip-0A0C0409:90305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.879517] [ip-0A0C0409:90308:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.898900] [ip-0A0C0408:91214:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.852499] [ip-0A0C040C:90490:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.809022] [ip-0A0C0409:90304:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.893952] [ip-0A0C040C:90488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.690697] [ip-0A0C040C:90492:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.710853] [ip-0A0C0408:91211:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.892406] [ip-0A0C040C:90486:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.852384] [ip-0A0C040C:90489:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.850753] [ip-0A0C040C:90487:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.868437] [ip-0A0C0408:91213:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.918297] [ip-0A0C0408:91209:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.919192] [ip-0A0C0408:91210:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.877487] [ip-0A0C0408:91212:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.880990] [ip-0A0C040F:91066:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.988059] [ip-0A0C040F:91062:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.868325] [ip-0A0C0408:91215:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.920426] [ip-0A0C0408:91208:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.988008] [ip-0A0C040F:91068:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.762988] [ip-0A0C040F:91065:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.988725] [ip-0A0C040F:91063:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.805368] [ip-0A0C040F:91067:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.918762] [ip-0A0C040F:91069:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.941176] [ip-0A0C040F:91064:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.954320] [ip-0A0C0407:90988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.936065] [ip-0A0C0407:90991:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.891050] [ip-0A0C040A:90836:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.536323] [ip-0A0C0406:92669:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145961.890734] [ip-0A0C040A:90832:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.692471] [ip-0A0C0406:92662:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.936326] [ip-0A0C0407:90989:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.896320] [ip-0A0C040A:90833:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.822205] [ip-0A0C040A:90838:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.804306] [ip-0A0C0407:90993:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.782386] [ip-0A0C040A:90837:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.739103] [ip-0A0C0406:92665:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.657758] [ip-0A0C0406:92664:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.896206] [ip-0A0C040A:90834:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.737050] [ip-0A0C0406:92663:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.669073] [ip-0A0C040A:90835:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.744666] [ip-0A0C0406:92666:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.553926] [ip-0A0C0406:92668:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.748883] [ip-0A0C0407:90990:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.805817] [ip-0A0C040A:90831:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.954516] [ip-0A0C0407:90994:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.955098] [ip-0A0C0407:90995:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.763352] [ip-0A0C040D:91085:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.803137] [ip-0A0C0407:90992:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.865155] [ip-0A0C040D:91083:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.821369] [ip-0A0C040D:91105:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.730888] [ip-0A0C0406:92661:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
:::MLLOG {"namespace": "", "time_ms": 1636145975133, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1246, "metadata": {"file": "train_imagenet.py", "lineno": 176}}
[1636145961.863623] [ip-0A0C040D:91088:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.859308] [ip-0A0C040D:91082:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.657172] [ip-0A0C040D:91090:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.725173] [ip-0A0C040D:91086:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145961.722854] [ip-0A0C040D:91091:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:59:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
NCCL version 2.11.4+cuda11.4

ip-0A0C040F:91066:91264 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90988:91188 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90832:91029 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91088:91287 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90306:90502 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91213:91408 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90486:90681 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:92661 - context.c:584] INFO job (ID: 867530710675806047) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92661 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92661 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92661:92857 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90489:90687 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90833:91032 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90309:90501 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90989:91183 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91065:91259 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91212:91404 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91105:91283 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:92662 - context.c:584] INFO job (ID: 867531218685248763) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92662 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92662 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92662:92859 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90994:91189 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91069:91262 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91215:91405 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90310:90504 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91090:91280 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90493:90688 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90834:91027 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:92669 - context.c:584] INFO job (ID: 867530436468160597) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92669 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92669 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92669:92858 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90305:90499 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90993:91185 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91067:91258 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91211:91406 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90492:90686 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90831:91033 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91083:91284 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:92664 - context.c:584] INFO job (ID: 867530575905747218) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92664 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92664 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92664:92864 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90990:91184 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91064:91263 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91091:91282 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91208:91407 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90490:90685 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90835:91028 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90307:90500 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:92666 - context.c:584] INFO job (ID: 867531089893422115) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92666 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92666 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92666:92860 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90995:91186 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91062:91257 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91210:91409 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90487:90683 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90838:91026 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90304:90498 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91082:91286 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:92665 - context.c:584] INFO job (ID: 867530947275174658) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92665 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92665 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92665:92861 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91068:91261 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91086:91281 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90491:90684 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91214:91411 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90303:90505 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90991:91190 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90836:91031 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:92668 - context.c:584] INFO job (ID: 867531269119816198) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92668 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92668 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92668:92863 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90308:90503 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90992:91187 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91063:91260 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91085:91285 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91209:91410 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90488:90682 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90837:91030 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91066:91264 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0408:91213:91408 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0409:90306:90502 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040A:90832:91029 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040D:91088:91287 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0407:90988:91188 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040C:90486:90681 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
[ip-0A0C0406:0:92663 - context.c:584] INFO job (ID: 867530441309619298) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92663 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92663 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92663:92862 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0406:92661:92857 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0409:90306:90502 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90988:91188 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91213:91408 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91088:91287 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91066:91264 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90486:90681 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90832:91029 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:92661 - context.c:584] INFO job (ID: 867530710915408698) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92661 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92661 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92661:92857 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90309:90501 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90989:91183 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91065:91259 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91105:91283 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91212:91404 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90489:90687 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90833:91032 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:92662 - context.c:584] INFO job (ID: 867531219905325837) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92662 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92662 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92662:92859 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91090:91280 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90310:90504 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91069:91262 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91215:91405 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90493:90688 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90834:91027 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90994:91189 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:92669 - context.c:584] INFO job (ID: 867530436051548634) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92669 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92669 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92669:92858 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91067:91258 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90492:90686 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90831:91033 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90305:90499 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90993:91185 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91083:91284 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91211:91406 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:92664 - context.c:584] INFO job (ID: 867530575503137021) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92664 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92664 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92664:92864 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90307:90500 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91091:91282 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91208:91407 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91064:91263 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90490:90685 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90835:91028 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90990:91184 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:92666 - context.c:584] INFO job (ID: 867531091196982832) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92666 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92666 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92666:92860 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90304:90498 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91062:91257 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91082:91286 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91210:91409 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90487:90683 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90838:91026 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90995:91186 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:92665 - context.c:584] INFO job (ID: 867530946999402973) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92665 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92665 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92665:92861 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90303:90505 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91068:91261 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91086:91281 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90491:90684 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91214:91411 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90836:91031 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90991:91190 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:92668 - context.c:584] INFO job (ID: 867531268867161944) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92668 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92668 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92668:92863 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:91085:91285 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91209:91410 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:90308:90503 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:90488:90682 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:90992:91187 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:91063:91260 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:90837:91030 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:91213:91408 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040F:91066:91264 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040C:90486:90681 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0409:90306:90502 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0407:90988:91188 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040D:91088:91287 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040A:90832:91029 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
[ip-0A0C0406:0:92663 - context.c:584] INFO job (ID: 867530442261301598) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:92663 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:92663 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:92663:92862 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0406:92661:92857 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
:::MLLOG {"namespace": "", "time_ms": 1636146046864, "event_type": "POINT_IN_TIME", "key": "model_bn_span", "value": 51, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 309}}
[21:00:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1636146052812, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "bn0_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052813, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "bn0_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052813, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "conv0_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052813, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 81, "tensor": "fc1_bias"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052813, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 72, "tensor": "fc1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052814, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052814, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052814, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052814, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052815, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052815, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052815, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052815, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052815, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052816, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052816, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052816, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052816, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052817, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052817, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052817, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052817, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052817, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052818, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052818, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052818, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052818, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052818, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052819, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052819, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052819, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052819, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052820, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052820, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052820, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052820, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052820, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052821, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052821, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052821, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052821, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052822, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052822, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052822, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052822, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052822, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052823, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052823, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052823, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052823, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052823, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052824, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052824, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052824, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052824, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052825, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052825, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052825, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052825, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052825, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052826, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052826, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052826, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052826, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052826, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052827, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052827, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052827, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052827, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052828, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052828, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052828, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052828, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052828, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052829, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052829, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052829, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052829, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052830, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052830, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052830, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052830, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052830, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052831, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052831, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052831, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052831, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052831, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052832, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052832, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052832, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052832, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052833, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052833, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052833, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052833, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052833, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052834, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052834, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052834, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052834, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052835, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052835, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052835, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052835, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052835, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052836, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052836, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052836, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052836, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052836, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052837, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052837, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052837, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052837, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052837, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052838, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052838, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052838, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052838, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052839, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052839, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052839, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052839, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052839, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052840, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052840, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052840, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052840, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052840, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052841, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052841, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052841, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052841, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052842, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052842, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052842, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052842, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052842, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052843, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052843, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052843, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052843, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052843, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052844, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052844, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052844, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052844, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052845, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052845, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052845, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052845, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052845, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052846, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052846, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052846, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052846, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052846, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052847, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052847, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146052847, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv3_weight"}}
[21:00:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:00:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
:::MLLOG {"namespace": "", "time_ms": 1636146054813, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 233}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,813 Node[7] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=43937, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,811 Node[15] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=59068, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,813 Node[4] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=48795, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,813 Node[0] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=17506, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,814 Node[6] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=17364, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:00:54,812 Node[10] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=59072, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,808 Node[50] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=28021, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,812 Node[12] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:00:54,817 Node[18] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=58965, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=63447, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:00:54,813 Node[9] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',   op_instances.append(_OperatorInstance(input_set, self, **kwargs))
kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=59680, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,809 Node[48] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=79, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,814 Node[56] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=35791, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,817 Node[21] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=26899, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,809 Node[49] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=38729, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:00:54,815 Node[58] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=5110, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,814 Node[32] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=19422, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,815 Node[35] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:00:54,809 Node[54] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=31273, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=26856, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,815 Node[38] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:00:54,809 Node[51] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=54601, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,809 Node[53] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=2212, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=49351, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:00:54,813 Node[13] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=47599, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,815 Node[57] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,815 Node[33] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=19397, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=45550, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:00:54,814 Node[14] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,810 Node[52] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=8746, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,815 Node[59] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=12598, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=55119, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,815 Node[42] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:00:54,818 Node[16] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=18150, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=53467, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:00:54,815 Node[61] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=8089, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:00:54,815 Node[47] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=28090, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,815 Node[44] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=26121, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,814 Node[24] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=55384, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,819 Node[17] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:00:54,815 Node[36] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=5639, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=46478, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,819 Node[19] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=8253, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,815 Node[41] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=3961, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,816 Node[37] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=64632, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,815 Node[27] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=51930, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:00:54,810 Node[55] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=47884, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,815 Node[31] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=29426, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:00:54,819 Node[20] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=27381, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,815 Node[30] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:00:54,816 Node[45] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=28316, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=41872, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,819 Node[22] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=6463, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:00:54,815 Node[11] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:00:54,816 Node[39] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=16379, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=53392, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,817 Node[43] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=46320, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,817 Node[63] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:00:54,816 Node[26] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=60687, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=20797, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,816 Node[29] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:00:54,815 Node[8] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=1529, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=37227, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,816 Node[25] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=46186, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,817 Node[34] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=35924, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,817 Node[60] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=3770, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:00:54,818 Node[46] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=53630, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,818 Node[40] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=42905, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,818 Node[62] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=12089, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:00:54,817 Node[28] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=50358, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,821 Node[23] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=50754, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,814 Node[5] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=42760, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
:::MLLOG {"namespace": "", "time_ms": 1636146054813, "event_type": "POINT_IN_TIME", "key": "sgd_opt_learning_rate_decay_poly_power", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 711}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,814 Node[1] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=23673, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,814 Node[2] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=16697, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:00:54,814 Node[3] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=36630, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
:::MLLOG {"namespace": "", "time_ms": 1636146054814, "event_type": "POINT_IN_TIME", "key": "sgd_opt_end_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 712}}
:::MLLOG {"namespace": "", "time_ms": 1636146054814, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_decay_poly_power", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 713}}
:::MLLOG {"namespace": "", "time_ms": 1636146054814, "event_type": "POINT_IN_TIME", "key": "lars_opt_end_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 714}}
:::MLLOG {"namespace": "", "time_ms": 1636146054814, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 51, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1164}}
:::MLLOG {"namespace": "", "time_ms": 1636146054814, "event_type": "POINT_IN_TIME", "key": "s_optimizer", "value": "sgdwfastlars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1165}}
:::MLLOG {"namespace": "", "time_ms": 1636146054815, "event_type": "POINT_IN_TIME", "key": "s_network", "value": "resnet-v1b-fl", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1166}}
:::MLLOG {"namespace": "", "time_ms": 1636146054815, "event_type": "POINT_IN_TIME", "key": "s_process", "value": "horovod", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1167}}
:::MLLOG {"namespace": "", "time_ms": 1636146054815, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 3264, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1168}}
:::MLLOG {"namespace": "", "time_ms": 1636146054815, "event_type": "POINT_IN_TIME", "key": "s_optimizer", "value": "sgdwfastlars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1169}}
:::MLLOG {"namespace": "", "time_ms": 1636146054815, "event_type": "POINT_IN_TIME", "key": "s_network", "value": "resnet-v1b-fl", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1170}}
:::MLLOG {"namespace": "", "time_ms": 1636146054815, "event_type": "POINT_IN_TIME", "key": "s_process", "value": "horovod", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1171}}
:::MLLOG {"namespace": "", "time_ms": 1636146054815, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1172}}
:::MLLOG {"namespace": "", "time_ms": 1636146054815, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "lars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1178}}
:::MLLOG {"namespace": "", "time_ms": 1636146054815, "event_type": "POINT_IN_TIME", "key": "lars_epsilon", "value": 0, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1636146054815, "event_type": "POINT_IN_TIME", "key": "lars_opt_weight_decay", "value": 5e-05, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1182}}
:::MLLOG {"namespace": "", "time_ms": 1636146054815, "event_type": "POINT_IN_TIME", "key": "lars_opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1184}}
:::MLLOG {"namespace": "", "time_ms": 1636146054815, "event_type": "POINT_IN_TIME", "key": "lars_opt_base_learning_rate", "value": 10.5, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1185}}
:::MLLOG {"namespace": "", "time_ms": 1636146054815, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_warmup_epochs", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1186}}
:::MLLOG {"namespace": "", "time_ms": 1636146054815, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_decay_steps", "value": 37, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1187}}
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:01:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
:::MLLOG {"namespace": "", "time_ms": 1636146089004, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1336}}
:::MLLOG {"namespace": "", "time_ms": 1636146089004, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1281167, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 486}}
:::MLLOG {"namespace": "", "time_ms": 1636146089231, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 50000, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 508}}
:::MLLOG {"namespace": "", "time_ms": 1636146089231, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 903, "first_epoch_num": 1, "epoch_count": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636146089231, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 1}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:30,134 Node[0] Epoch[0] Batch [0-20]	Speed: 107366.10 samples/sec	accuracy=nan
2021-11-05 21:01:30,624 Node[0] Epoch[0] Batch [20-40]	Speed: 133470.36 samples/sec	accuracy=nan
2021-11-05 21:01:31,119 Node[0] Epoch[0] Batch [40-60]	Speed: 131777.77 samples/sec	accuracy=nan
2021-11-05 21:01:31,593 Node[0] Epoch[0] Batch [60-80]	Speed: 137640.45 samples/sec	accuracy=nan
2021-11-05 21:01:32,070 Node[0] Epoch[0] Batch [80-100]	Speed: 136807.07 samples/sec	accuracy=nan
2021-11-05 21:01:32,549 Node[0] Epoch[0] Batch [100-120]	Speed: 136429.01 samples/sec	accuracy=nan
2021-11-05 21:01:33,014 Node[0] Epoch[0] Batch [120-140]	Speed: 140451.43 samples/sec	accuracy=nan
2021-11-05 21:01:33,543 Node[0] Epoch[0] Batch [140-160]	Speed: 123426.22 samples/sec	accuracy=nan
2021-11-05 21:01:34,074 Node[0] Epoch[0] Batch [160-180]	Speed: 122834.80 samples/sec	accuracy=nan
2021-11-05 21:01:34,570 Node[0] Epoch[0] Batch [180-200]	Speed: 131715.01 samples/sec	accuracy=nan
2021-11-05 21:01:35,070 Node[0] Epoch[0] Batch [200-220]	Speed: 130346.19 samples/sec	accuracy=nan
2021-11-05 21:01:35,542 Node[0] Epoch[0] Batch [220-240]	Speed: 138437.42 samples/sec	accuracy=nan
2021-11-05 21:01:36,015 Node[0] Epoch[0] Batch [240-260]	Speed: 138113.06 samples/sec	accuracy=nan
2021-11-05 21:01:36,499 Node[0] Epoch[0] Batch [260-280]	Speed: 134672.78 samples/sec	accuracy=nan
2021-11-05 21:01:36,992 Node[0] Epoch[0] Batch [280-300]	Speed: 132534.41 samples/sec	accuracy=nan
2021-11-05 21:01:37,510 Node[0] Epoch[0] Batch [300-320]	Speed: 126022.96 samples/sec	accuracy=nan
2021-11-05 21:01:38,005 Node[0] Epoch[0] Batch [320-340]	Speed: 131722.30 samples/sec	accuracy=nan
2021-11-05 21:01:38,469 Node[0] Epoch[0] Batch [340-360]	Speed: 140982.54 samples/sec	accuracy=nan
2021-11-05 21:01:38,931 Node[0] Epoch[0] Batch [360-380]	Speed: 141152.68 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146099169, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1636146099170, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 128913.04147421946}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 1}}
2021-11-05 21:01:39,169 Node[0] Epoch[0] Time cost=9.938
:::MLLOG {"namespace": "", "time_ms": 1636146099170, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 128913.04147421946, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146099170, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 2}}
2021-11-05 21:01:39,589 Node[0] Epoch[1] Batch [0-20]	Speed: 163160.09 samples/sec	accuracy=nan
2021-11-05 21:01:39,986 Node[0] Epoch[1] Batch [20-40]	Speed: 164307.21 samples/sec	accuracy=nan
2021-11-05 21:01:40,381 Node[0] Epoch[1] Batch [40-60]	Speed: 165282.09 samples/sec	accuracy=nan
2021-11-05 21:01:40,779 Node[0] Epoch[1] Batch [60-80]	Speed: 164190.45 samples/sec	accuracy=nan
2021-11-05 21:01:41,172 Node[0] Epoch[1] Batch [80-100]	Speed: 165945.44 samples/sec	accuracy=nan
2021-11-05 21:01:41,567 Node[0] Epoch[1] Batch [100-120]	Speed: 165277.80 samples/sec	accuracy=nan
2021-11-05 21:01:41,968 Node[0] Epoch[1] Batch [120-140]	Speed: 162987.79 samples/sec	accuracy=nan
2021-11-05 21:01:42,364 Node[0] Epoch[1] Batch [140-160]	Speed: 164874.13 samples/sec	accuracy=nan
2021-11-05 21:01:42,760 Node[0] Epoch[1] Batch [160-180]	Speed: 164618.58 samples/sec	accuracy=nan
2021-11-05 21:01:43,157 Node[0] Epoch[1] Batch [180-200]	Speed: 164601.46 samples/sec	accuracy=nan
2021-11-05 21:01:43,556 Node[0] Epoch[1] Batch [200-220]	Speed: 163309.66 samples/sec	accuracy=nan
2021-11-05 21:01:43,958 Node[0] Epoch[1] Batch [220-240]	Speed: 162624.67 samples/sec	accuracy=nan
2021-11-05 21:01:44,358 Node[0] Epoch[1] Batch [240-260]	Speed: 163349.32 samples/sec	accuracy=nan
2021-11-05 21:01:44,755 Node[0] Epoch[1] Batch [260-280]	Speed: 164207.10 samples/sec	accuracy=nan
2021-11-05 21:01:45,154 Node[0] Epoch[1] Batch [280-300]	Speed: 163672.72 samples/sec	accuracy=nan
2021-11-05 21:01:45,554 Node[0] Epoch[1] Batch [300-320]	Speed: 163257.57 samples/sec	accuracy=nan
2021-11-05 21:01:45,953 Node[0] Epoch[1] Batch [320-340]	Speed: 163665.48 samples/sec	accuracy=nan
2021-11-05 21:01:46,353 Node[0] Epoch[1] Batch [340-360]	Speed: 163129.37 samples/sec	accuracy=nan
2021-11-05 21:01:46,750 Node[0] Epoch[1] Batch [360-380]	Speed: 164473.02 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146106989, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 2}}
2021-11-05 21:01:46,989 Node[0] Epoch[1] Time cost=7.819
:::MLLOG {"namespace": "", "time_ms": 1636146106989, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 163847.49950613442}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1636146106989, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 163847.49950613442, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146106989, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 3}}
2021-11-05 21:01:47,403 Node[0] Epoch[2] Batch [0-20]	Speed: 165246.28 samples/sec	accuracy=nan
2021-11-05 21:01:47,802 Node[0] Epoch[2] Batch [20-40]	Speed: 163436.78 samples/sec	accuracy=nan
2021-11-05 21:01:48,202 Node[0] Epoch[2] Batch [40-60]	Speed: 163416.88 samples/sec	accuracy=nan
2021-11-05 21:01:48,594 Node[0] Epoch[2] Batch [60-80]	Speed: 166321.94 samples/sec	accuracy=nan
2021-11-05 21:01:48,988 Node[0] Epoch[2] Batch [80-100]	Speed: 165811.78 samples/sec	accuracy=nan
2021-11-05 21:01:49,383 Node[0] Epoch[2] Batch [100-120]	Speed: 165447.78 samples/sec	accuracy=nan
2021-11-05 21:01:49,779 Node[0] Epoch[2] Batch [120-140]	Speed: 164865.20 samples/sec	accuracy=nan
2021-11-05 21:01:50,172 Node[0] Epoch[2] Batch [140-160]	Speed: 166014.36 samples/sec	accuracy=nan
2021-11-05 21:01:50,567 Node[0] Epoch[2] Batch [160-180]	Speed: 165372.04 samples/sec	accuracy=nan
2021-11-05 21:01:50,964 Node[0] Epoch[2] Batch [180-200]	Speed: 164234.18 samples/sec	accuracy=nan
2021-11-05 21:01:51,362 Node[0] Epoch[2] Batch [200-220]	Speed: 164067.87 samples/sec	accuracy=nan
2021-11-05 21:01:51,758 Node[0] Epoch[2] Batch [220-240]	Speed: 164926.67 samples/sec	accuracy=nan
2021-11-05 21:01:52,153 Node[0] Epoch[2] Batch [240-260]	Speed: 165275.01 samples/sec	accuracy=nan
2021-11-05 21:01:52,550 Node[0] Epoch[2] Batch [260-280]	Speed: 164116.74 samples/sec	accuracy=nan
2021-11-05 21:01:52,946 Node[0] Epoch[2] Batch [280-300]	Speed: 164862.72 samples/sec	accuracy=nan
2021-11-05 21:01:53,340 Node[0] Epoch[2] Batch [300-320]	Speed: 165736.10 samples/sec	accuracy=nan
2021-11-05 21:01:53,740 Node[0] Epoch[2] Batch [320-340]	Speed: 163461.95 samples/sec	accuracy=nan
2021-11-05 21:01:54,139 Node[0] Epoch[2] Batch [340-360]	Speed: 163478.54 samples/sec	accuracy=nan
2021-11-05 21:01:54,538 Node[0] Epoch[2] Batch [360-380]	Speed: 163601.72 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146114776, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636146114776, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164540.67866269092}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 3}}
2021-11-05 21:01:54,776 Node[0] Epoch[2] Time cost=7.786
:::MLLOG {"namespace": "", "time_ms": 1636146114776, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164540.67866269092, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146114793, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 3}}
2021-11-05 21:01:54,793 Node[0] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[2] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[3] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,788 Node[48] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[6] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,788 Node[49] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[1] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[24] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,788 Node[52] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[5] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[25] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,788 Node[53] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,797 Node[16] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[40] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[32] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[7] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[28] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,792 Node[8] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,788 Node[54] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,797 Node[18] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[41] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[36] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[4] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[29] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,792 Node[10] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[57] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,797 Node[19] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[42] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[37] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[30] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,792 Node[11] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[58] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,797 Node[17] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[43] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[38] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,792 Node[12] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[59] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,797 Node[20] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[44] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[39] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,792 Node[13] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[63] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[56] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,788 Node[55] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,788 Node[50] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,788 Node[51] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[45] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[31] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[46] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[26] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[47] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[27] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,792 Node[9] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,792 Node[14] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,792 Node[15] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[33] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[34] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,797 Node[21] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[35] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,797 Node[22] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[60] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,797 Node[23] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[61] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:01:54,793 Node[62] DALI iterator does not support resetting while epoch is not finished. Ignoring...
2021-11-05 21:01:55,172 Node[0] Epoch[2] Validation-accuracy=0.290653
2021-11-05 21:01:55,172 Node[0] Epoch[2] Validation-correct-count=227.000000
2021-11-05 21:01:55,172 Node[0] Epoch[2] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146115226, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636146115227, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.31118, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636146115227, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1636146115227, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 4, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146115227, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 4}}
2021-11-05 21:01:55,631 Node[0] Epoch[3] Batch [0-20]	Speed: 163519.74 samples/sec	accuracy=nan
2021-11-05 21:01:56,029 Node[0] Epoch[3] Batch [20-40]	Speed: 163883.93 samples/sec	accuracy=nan
2021-11-05 21:01:56,426 Node[0] Epoch[3] Batch [40-60]	Speed: 164575.54 samples/sec	accuracy=nan
2021-11-05 21:01:56,820 Node[0] Epoch[3] Batch [60-80]	Speed: 165525.50 samples/sec	accuracy=nan
2021-11-05 21:01:57,218 Node[0] Epoch[3] Batch [80-100]	Speed: 164011.06 samples/sec	accuracy=nan
2021-11-05 21:01:57,613 Node[0] Epoch[3] Batch [100-120]	Speed: 165594.07 samples/sec	accuracy=nan
2021-11-05 21:01:58,006 Node[0] Epoch[3] Batch [120-140]	Speed: 165931.36 samples/sec	accuracy=nan
2021-11-05 21:01:58,398 Node[0] Epoch[3] Batch [140-160]	Speed: 166703.30 samples/sec	accuracy=nan
2021-11-05 21:01:58,796 Node[0] Epoch[3] Batch [160-180]	Speed: 163951.45 samples/sec	accuracy=nan
2021-11-05 21:01:59,192 Node[0] Epoch[3] Batch [180-200]	Speed: 164800.10 samples/sec	accuracy=nan
2021-11-05 21:01:59,596 Node[0] Epoch[3] Batch [200-220]	Speed: 161696.65 samples/sec	accuracy=nan
2021-11-05 21:01:59,992 Node[0] Epoch[3] Batch [220-240]	Speed: 164718.71 samples/sec	accuracy=nan
2021-11-05 21:02:00,387 Node[0] Epoch[3] Batch [240-260]	Speed: 165390.42 samples/sec	accuracy=nan
2021-11-05 21:02:00,782 Node[0] Epoch[3] Batch [260-280]	Speed: 165077.21 samples/sec	accuracy=nan
2021-11-05 21:02:01,177 Node[0] Epoch[3] Batch [280-300]	Speed: 165356.96 samples/sec	accuracy=nan
2021-11-05 21:02:01,572 Node[0] Epoch[3] Batch [300-320]	Speed: 165139.94 samples/sec	accuracy=nan
2021-11-05 21:02:01,968 Node[0] Epoch[3] Batch [320-340]	Speed: 164783.84 samples/sec	accuracy=nan
2021-11-05 21:02:02,366 Node[0] Epoch[3] Batch [340-360]	Speed: 164277.44 samples/sec	accuracy=nan
2021-11-05 21:02:02,765 Node[0] Epoch[3] Batch [360-380]	Speed: 163504.02 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146123003, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 4}}
2021-11-05 21:02:03,004 Node[0] Epoch[3] Time cost=7.777
:::MLLOG {"namespace": "", "time_ms": 1636146123004, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164747.09801973126}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146123004, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164747.09801973126, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146123004, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 5}}
2021-11-05 21:02:03,441 Node[0] Epoch[4] Batch [0-20]	Speed: 156267.00 samples/sec	accuracy=nan
2021-11-05 21:02:03,817 Node[0] Epoch[4] Batch [20-40]	Speed: 173626.85 samples/sec	accuracy=nan
2021-11-05 21:02:04,209 Node[0] Epoch[4] Batch [40-60]	Speed: 166340.83 samples/sec	accuracy=nan
2021-11-05 21:02:04,604 Node[0] Epoch[4] Batch [60-80]	Speed: 165326.80 samples/sec	accuracy=nan
2021-11-05 21:02:05,002 Node[0] Epoch[4] Batch [80-100]	Speed: 164062.16 samples/sec	accuracy=nan
2021-11-05 21:02:05,397 Node[0] Epoch[4] Batch [100-120]	Speed: 165018.91 samples/sec	accuracy=nan
2021-11-05 21:02:05,792 Node[0] Epoch[4] Batch [120-140]	Speed: 165453.58 samples/sec	accuracy=nan
2021-11-05 21:02:06,183 Node[0] Epoch[4] Batch [140-160]	Speed: 166794.19 samples/sec	accuracy=nan
2021-11-05 21:02:06,575 Node[0] Epoch[4] Batch [160-180]	Speed: 166552.41 samples/sec	accuracy=nan
2021-11-05 21:02:06,971 Node[0] Epoch[4] Batch [180-200]	Speed: 164996.84 samples/sec	accuracy=nan
2021-11-05 21:02:07,365 Node[0] Epoch[4] Batch [200-220]	Speed: 165719.95 samples/sec	accuracy=nan
2021-11-05 21:02:07,760 Node[0] Epoch[4] Batch [220-240]	Speed: 165177.70 samples/sec	accuracy=nan
2021-11-05 21:02:08,151 Node[0] Epoch[4] Batch [240-260]	Speed: 166825.99 samples/sec	accuracy=nan
2021-11-05 21:02:08,549 Node[0] Epoch[4] Batch [260-280]	Speed: 164384.15 samples/sec	accuracy=nan
2021-11-05 21:02:08,943 Node[0] Epoch[4] Batch [280-300]	Speed: 165402.41 samples/sec	accuracy=nan
2021-11-05 21:02:09,339 Node[0] Epoch[4] Batch [300-320]	Speed: 165108.47 samples/sec	accuracy=nan
2021-11-05 21:02:09,738 Node[0] Epoch[4] Batch [320-340]	Speed: 163525.51 samples/sec	accuracy=nan
2021-11-05 21:02:10,137 Node[0] Epoch[4] Batch [340-360]	Speed: 163626.06 samples/sec	accuracy=nan
2021-11-05 21:02:10,536 Node[0] Epoch[4] Batch [360-380]	Speed: 163623.42 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146130773, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 5}}
2021-11-05 21:02:10,773 Node[0] Epoch[4] Time cost=7.769
:::MLLOG {"namespace": "", "time_ms": 1636146130773, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164905.42948550286}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 5}}
:::MLLOG {"namespace": "", "time_ms": 1636146130773, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164905.42948550286, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146130773, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 6}}
2021-11-05 21:02:11,188 Node[0] Epoch[5] Batch [0-20]	Speed: 165113.15 samples/sec	accuracy=nan
2021-11-05 21:02:11,585 Node[0] Epoch[5] Batch [20-40]	Speed: 164248.07 samples/sec	accuracy=nan
2021-11-05 21:02:11,982 Node[0] Epoch[5] Batch [40-60]	Speed: 164662.64 samples/sec	accuracy=nan
2021-11-05 21:02:12,374 Node[0] Epoch[5] Batch [60-80]	Speed: 166591.93 samples/sec	accuracy=nan
2021-11-05 21:02:12,771 Node[0] Epoch[5] Batch [80-100]	Speed: 164171.36 samples/sec	accuracy=nan
2021-11-05 21:02:13,164 Node[0] Epoch[5] Batch [100-120]	Speed: 166430.62 samples/sec	accuracy=nan
2021-11-05 21:02:13,559 Node[0] Epoch[5] Batch [120-140]	Speed: 165277.70 samples/sec	accuracy=nan
2021-11-05 21:02:13,952 Node[0] Epoch[5] Batch [140-160]	Speed: 165991.82 samples/sec	accuracy=nan
2021-11-05 21:02:14,348 Node[0] Epoch[5] Batch [160-180]	Speed: 164976.56 samples/sec	accuracy=nan
2021-11-05 21:02:14,745 Node[0] Epoch[5] Batch [180-200]	Speed: 164120.09 samples/sec	accuracy=nan
2021-11-05 21:02:15,139 Node[0] Epoch[5] Batch [200-220]	Speed: 165925.93 samples/sec	accuracy=nan
2021-11-05 21:02:15,532 Node[0] Epoch[5] Batch [220-240]	Speed: 165896.57 samples/sec	accuracy=nan
2021-11-05 21:02:15,928 Node[0] Epoch[5] Batch [240-260]	Speed: 164776.50 samples/sec	accuracy=nan
2021-11-05 21:02:16,321 Node[0] Epoch[5] Batch [260-280]	Speed: 166415.65 samples/sec	accuracy=nan
2021-11-05 21:02:16,715 Node[0] Epoch[5] Batch [280-300]	Speed: 165396.11 samples/sec	accuracy=nan
2021-11-05 21:02:17,108 Node[0] Epoch[5] Batch [300-320]	Speed: 166212.09 samples/sec	accuracy=nan
2021-11-05 21:02:17,506 Node[0] Epoch[5] Batch [320-340]	Speed: 164258.42 samples/sec	accuracy=nan
2021-11-05 21:02:17,905 Node[0] Epoch[5] Batch [340-360]	Speed: 163489.67 samples/sec	accuracy=nan
2021-11-05 21:02:18,301 Node[0] Epoch[5] Batch [360-380]	Speed: 164574.36 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146138539, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 6}}
2021-11-05 21:02:18,539 Node[0] Epoch[5] Time cost=7.766
:::MLLOG {"namespace": "", "time_ms": 1636146138539, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164981.04965979437}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 6}}
:::MLLOG {"namespace": "", "time_ms": 1636146138539, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164981.04965979437, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146138539, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 7}}
2021-11-05 21:02:18,954 Node[0] Epoch[6] Batch [0-20]	Speed: 164795.54 samples/sec	accuracy=nan
2021-11-05 21:02:19,351 Node[0] Epoch[6] Batch [20-40]	Speed: 164596.81 samples/sec	accuracy=nan
2021-11-05 21:02:19,746 Node[0] Epoch[6] Batch [40-60]	Speed: 165184.27 samples/sec	accuracy=nan
2021-11-05 21:02:20,139 Node[0] Epoch[6] Batch [60-80]	Speed: 166220.56 samples/sec	accuracy=nan
2021-11-05 21:02:20,531 Node[0] Epoch[6] Batch [80-100]	Speed: 166608.66 samples/sec	accuracy=nan
2021-11-05 21:02:20,923 Node[0] Epoch[6] Batch [100-120]	Speed: 166452.68 samples/sec	accuracy=nan
2021-11-05 21:02:21,315 Node[0] Epoch[6] Batch [120-140]	Speed: 166438.81 samples/sec	accuracy=nan
2021-11-05 21:02:21,708 Node[0] Epoch[6] Batch [140-160]	Speed: 166041.44 samples/sec	accuracy=nan
2021-11-05 21:02:22,105 Node[0] Epoch[6] Batch [160-180]	Speed: 164415.25 samples/sec	accuracy=nan
2021-11-05 21:02:22,502 Node[0] Epoch[6] Batch [180-200]	Speed: 164593.75 samples/sec	accuracy=nan
2021-11-05 21:02:22,896 Node[0] Epoch[6] Batch [200-220]	Speed: 165723.56 samples/sec	accuracy=nan
2021-11-05 21:02:23,288 Node[0] Epoch[6] Batch [220-240]	Speed: 166353.87 samples/sec	accuracy=nan
2021-11-05 21:02:23,687 Node[0] Epoch[6] Batch [240-260]	Speed: 163646.11 samples/sec	accuracy=nan
2021-11-05 21:02:24,085 Node[0] Epoch[6] Batch [260-280]	Speed: 164056.07 samples/sec	accuracy=nan
2021-11-05 21:02:24,479 Node[0] Epoch[6] Batch [280-300]	Speed: 165574.34 samples/sec	accuracy=nan
2021-11-05 21:02:24,874 Node[0] Epoch[6] Batch [300-320]	Speed: 165523.19 samples/sec	accuracy=nan
2021-11-05 21:02:25,271 Node[0] Epoch[6] Batch [320-340]	Speed: 164236.94 samples/sec	accuracy=nan
2021-11-05 21:02:25,666 Node[0] Epoch[6] Batch [340-360]	Speed: 165183.48 samples/sec	accuracy=nan
2021-11-05 21:02:26,063 Node[0] Epoch[6] Batch [360-380]	Speed: 164765.39 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146146299, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 7}}
2021-11-05 21:02:26,299 Node[0] Epoch[6] Time cost=7.760
:::MLLOG {"namespace": "", "time_ms": 1636146146299, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165107.12929673895}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636146146299, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165107.12929673895, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146146316, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 7}}
2021-11-05 21:02:26,433 Node[0] Epoch[6] Validation-accuracy=0.428937
2021-11-05 21:02:26,433 Node[0] Epoch[6] Validation-correct-count=335.000000
2021-11-05 21:02:26,433 Node[0] Epoch[6] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146146446, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636146146446, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.44918, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636146146446, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146146447, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 8, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146146447, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 8}}
2021-11-05 21:02:26,844 Node[0] Epoch[7] Batch [0-20]	Speed: 166299.51 samples/sec	accuracy=nan
2021-11-05 21:02:27,239 Node[0] Epoch[7] Batch [20-40]	Speed: 165109.86 samples/sec	accuracy=nan
2021-11-05 21:02:27,635 Node[0] Epoch[7] Batch [40-60]	Speed: 164978.05 samples/sec	accuracy=nan
2021-11-05 21:02:28,031 Node[0] Epoch[7] Batch [60-80]	Speed: 164731.39 samples/sec	accuracy=nan
2021-11-05 21:02:28,425 Node[0] Epoch[7] Batch [80-100]	Speed: 165945.34 samples/sec	accuracy=nan
2021-11-05 21:02:28,818 Node[0] Epoch[7] Batch [100-120]	Speed: 166020.20 samples/sec	accuracy=nan
2021-11-05 21:02:29,212 Node[0] Epoch[7] Batch [120-140]	Speed: 165521.79 samples/sec	accuracy=nan
2021-11-05 21:02:29,603 Node[0] Epoch[7] Batch [140-160]	Speed: 166967.20 samples/sec	accuracy=nan
2021-11-05 21:02:29,995 Node[0] Epoch[7] Batch [160-180]	Speed: 166580.88 samples/sec	accuracy=nan
2021-11-05 21:02:30,393 Node[0] Epoch[7] Batch [180-200]	Speed: 164207.00 samples/sec	accuracy=nan
2021-11-05 21:02:30,786 Node[0] Epoch[7] Batch [200-220]	Speed: 165810.58 samples/sec	accuracy=nan
2021-11-05 21:02:31,182 Node[0] Epoch[7] Batch [220-240]	Speed: 165108.17 samples/sec	accuracy=nan
2021-11-05 21:02:31,575 Node[0] Epoch[7] Batch [240-260]	Speed: 166139.27 samples/sec	accuracy=nan
2021-11-05 21:02:31,967 Node[0] Epoch[7] Batch [260-280]	Speed: 166412.61 samples/sec	accuracy=nan
2021-11-05 21:02:32,361 Node[0] Epoch[7] Batch [280-300]	Speed: 165853.86 samples/sec	accuracy=nan
2021-11-05 21:02:32,756 Node[0] Epoch[7] Batch [300-320]	Speed: 165161.46 samples/sec	accuracy=nan
2021-11-05 21:02:33,152 Node[0] Epoch[7] Batch [320-340]	Speed: 164949.03 samples/sec	accuracy=nan
2021-11-05 21:02:33,548 Node[0] Epoch[7] Batch [340-360]	Speed: 164614.43 samples/sec	accuracy=nan
2021-11-05 21:02:33,945 Node[0] Epoch[7] Batch [360-380]	Speed: 164500.59 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146154183, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 8}}
2021-11-05 21:02:34,184 Node[0] Epoch[7] Time cost=7.737
:::MLLOG {"namespace": "", "time_ms": 1636146154184, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165586.60351749868}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 8}}
:::MLLOG {"namespace": "", "time_ms": 1636146154184, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165586.60351749868, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146154184, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 9}}
2021-11-05 21:02:34,598 Node[0] Epoch[8] Batch [0-20]	Speed: 165337.68 samples/sec	accuracy=nan
2021-11-05 21:02:34,990 Node[0] Epoch[8] Batch [20-40]	Speed: 166507.64 samples/sec	accuracy=nan
2021-11-05 21:02:35,384 Node[0] Epoch[8] Batch [40-60]	Speed: 165692.48 samples/sec	accuracy=nan
2021-11-05 21:02:35,778 Node[0] Epoch[8] Batch [60-80]	Speed: 165611.30 samples/sec	accuracy=nan
2021-11-05 21:02:36,169 Node[0] Epoch[8] Batch [80-100]	Speed: 166838.40 samples/sec	accuracy=nan
2021-11-05 21:02:36,563 Node[0] Epoch[8] Batch [100-120]	Speed: 165835.88 samples/sec	accuracy=nan
2021-11-05 21:02:36,957 Node[0] Epoch[8] Batch [120-140]	Speed: 165675.53 samples/sec	accuracy=nan
2021-11-05 21:02:37,349 Node[0] Epoch[8] Batch [140-160]	Speed: 166621.13 samples/sec	accuracy=nan
2021-11-05 21:02:37,741 Node[0] Epoch[8] Batch [160-180]	Speed: 166602.67 samples/sec	accuracy=nan
2021-11-05 21:02:38,133 Node[0] Epoch[8] Batch [180-200]	Speed: 166592.23 samples/sec	accuracy=nan
2021-11-05 21:02:38,528 Node[0] Epoch[8] Batch [200-220]	Speed: 165229.23 samples/sec	accuracy=nan
2021-11-05 21:02:38,923 Node[0] Epoch[8] Batch [220-240]	Speed: 165036.32 samples/sec	accuracy=nan
2021-11-05 21:02:39,315 Node[0] Epoch[8] Batch [240-260]	Speed: 166474.13 samples/sec	accuracy=nan
2021-11-05 21:02:39,708 Node[0] Epoch[8] Batch [260-280]	Speed: 166139.47 samples/sec	accuracy=nan
2021-11-05 21:02:40,101 Node[0] Epoch[8] Batch [280-300]	Speed: 166131.01 samples/sec	accuracy=nan
2021-11-05 21:02:40,495 Node[0] Epoch[8] Batch [300-320]	Speed: 165692.88 samples/sec	accuracy=nan
2021-11-05 21:02:40,891 Node[0] Epoch[8] Batch [320-340]	Speed: 164920.81 samples/sec	accuracy=nan
2021-11-05 21:02:41,293 Node[0] Epoch[8] Batch [340-360]	Speed: 162229.90 samples/sec	accuracy=nan
2021-11-05 21:02:41,691 Node[0] Epoch[8] Batch [360-380]	Speed: 164009.10 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146161928, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 9}}
2021-11-05 21:02:41,929 Node[0] Epoch[8] Time cost=7.744
:::MLLOG {"namespace": "", "time_ms": 1636146161929, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165434.83561335085}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 9}}
:::MLLOG {"namespace": "", "time_ms": 1636146161929, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165434.83561335085, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146161929, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 10}}
2021-11-05 21:02:42,340 Node[0] Epoch[9] Batch [0-20]	Speed: 166301.94 samples/sec	accuracy=nan
2021-11-05 21:02:42,736 Node[0] Epoch[9] Batch [20-40]	Speed: 165014.93 samples/sec	accuracy=nan
2021-11-05 21:02:43,129 Node[0] Epoch[9] Batch [40-60]	Speed: 166145.22 samples/sec	accuracy=nan
2021-11-05 21:02:43,523 Node[0] Epoch[9] Batch [60-80]	Speed: 165854.47 samples/sec	accuracy=nan
2021-11-05 21:02:43,916 Node[0] Epoch[9] Batch [80-100]	Speed: 166104.00 samples/sec	accuracy=nan
2021-11-05 21:02:44,310 Node[0] Epoch[9] Batch [100-120]	Speed: 165345.27 samples/sec	accuracy=nan
2021-11-05 21:02:44,704 Node[0] Epoch[9] Batch [120-140]	Speed: 165738.41 samples/sec	accuracy=nan
2021-11-05 21:02:45,096 Node[0] Epoch[9] Batch [140-160]	Speed: 166576.12 samples/sec	accuracy=nan
2021-11-05 21:02:45,490 Node[0] Epoch[9] Batch [160-180]	Speed: 165540.21 samples/sec	accuracy=nan
2021-11-05 21:02:45,886 Node[0] Epoch[9] Batch [180-200]	Speed: 164976.46 samples/sec	accuracy=nan
2021-11-05 21:02:46,278 Node[0] Epoch[9] Batch [200-220]	Speed: 166703.09 samples/sec	accuracy=nan
2021-11-05 21:02:46,671 Node[0] Epoch[9] Batch [220-240]	Speed: 165965.86 samples/sec	accuracy=nan
2021-11-05 21:02:47,063 Node[0] Epoch[9] Batch [240-260]	Speed: 166523.64 samples/sec	accuracy=nan
2021-11-05 21:02:47,457 Node[0] Epoch[9] Batch [260-280]	Speed: 165711.03 samples/sec	accuracy=nan
2021-11-05 21:02:47,849 Node[0] Epoch[9] Batch [280-300]	Speed: 166763.51 samples/sec	accuracy=nan
2021-11-05 21:02:48,241 Node[0] Epoch[9] Batch [300-320]	Speed: 166248.82 samples/sec	accuracy=nan
2021-11-05 21:02:48,636 Node[0] Epoch[9] Batch [320-340]	Speed: 165482.28 samples/sec	accuracy=nan
2021-11-05 21:02:49,033 Node[0] Epoch[9] Batch [340-360]	Speed: 164467.79 samples/sec	accuracy=nan
2021-11-05 21:02:49,430 Node[0] Epoch[9] Batch [360-380]	Speed: 164140.65 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146169668, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 10}}
2021-11-05 21:02:49,668 Node[0] Epoch[9] Time cost=7.739
:::MLLOG {"namespace": "", "time_ms": 1636146169668, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165540.7394636904}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 10}}
:::MLLOG {"namespace": "", "time_ms": 1636146169668, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165540.7394636904, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146169668, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 11}}
2021-11-05 21:02:50,081 Node[0] Epoch[10] Batch [0-20]	Speed: 166048.99 samples/sec	accuracy=nan
2021-11-05 21:02:50,475 Node[0] Epoch[10] Batch [20-40]	Speed: 165788.49 samples/sec	accuracy=nan
2021-11-05 21:02:50,874 Node[0] Epoch[10] Batch [40-60]	Speed: 163605.73 samples/sec	accuracy=nan
2021-11-05 21:02:51,266 Node[0] Epoch[10] Batch [60-80]	Speed: 166365.49 samples/sec	accuracy=nan
2021-11-05 21:02:51,661 Node[0] Epoch[10] Batch [80-100]	Speed: 165189.95 samples/sec	accuracy=nan
2021-11-05 21:02:52,055 Node[0] Epoch[10] Batch [100-120]	Speed: 165849.34 samples/sec	accuracy=nan
2021-11-05 21:02:52,450 Node[0] Epoch[10] Batch [120-140]	Speed: 165386.42 samples/sec	accuracy=nan
2021-11-05 21:02:52,841 Node[0] Epoch[10] Batch [140-160]	Speed: 166612.81 samples/sec	accuracy=nan
2021-11-05 21:02:53,235 Node[0] Epoch[10] Batch [160-180]	Speed: 165959.02 samples/sec	accuracy=nan
2021-11-05 21:02:53,631 Node[0] Epoch[10] Batch [180-200]	Speed: 164946.04 samples/sec	accuracy=nan
2021-11-05 21:02:54,025 Node[0] Epoch[10] Batch [200-220]	Speed: 165440.18 samples/sec	accuracy=nan
2021-11-05 21:02:54,421 Node[0] Epoch[10] Batch [220-240]	Speed: 165088.26 samples/sec	accuracy=nan
2021-11-05 21:02:54,815 Node[0] Epoch[10] Batch [240-260]	Speed: 165460.18 samples/sec	accuracy=nan
2021-11-05 21:02:55,214 Node[0] Epoch[10] Batch [260-280]	Speed: 163803.34 samples/sec	accuracy=nan
2021-11-05 21:02:55,608 Node[0] Epoch[10] Batch [280-300]	Speed: 165659.59 samples/sec	accuracy=nan
2021-11-05 21:02:56,004 Node[0] Epoch[10] Batch [300-320]	Speed: 164634.72 samples/sec	accuracy=nan
2021-11-05 21:02:56,398 Node[0] Epoch[10] Batch [320-340]	Speed: 165577.65 samples/sec	accuracy=nan
2021-11-05 21:02:56,795 Node[0] Epoch[10] Batch [340-360]	Speed: 164632.54 samples/sec	accuracy=nan
2021-11-05 21:02:57,192 Node[0] Epoch[10] Batch [360-380]	Speed: 164601.27 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146177429, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 11}}
2021-11-05 21:02:57,429 Node[0] Epoch[10] Time cost=7.761
:::MLLOG {"namespace": "", "time_ms": 1636146177429, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165083.41129398163}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636146177429, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165083.41129398163, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146177446, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 11}}
2021-11-05 21:02:57,560 Node[0] Epoch[10] Validation-accuracy=0.542894
2021-11-05 21:02:57,560 Node[0] Epoch[10] Validation-correct-count=424.000000
2021-11-05 21:02:57,560 Node[0] Epoch[10] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146177576, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636146177576, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.54034, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636146177577, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1636146177577, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 12, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146177577, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 12}}
2021-11-05 21:02:57,974 Node[0] Epoch[11] Batch [0-20]	Speed: 166382.68 samples/sec	accuracy=nan
2021-11-05 21:02:58,368 Node[0] Epoch[11] Batch [20-40]	Speed: 165668.52 samples/sec	accuracy=nan
2021-11-05 21:02:58,761 Node[0] Epoch[11] Batch [40-60]	Speed: 166206.74 samples/sec	accuracy=nan
2021-11-05 21:02:59,154 Node[0] Epoch[11] Batch [60-80]	Speed: 165968.37 samples/sec	accuracy=nan
2021-11-05 21:02:59,547 Node[0] Epoch[11] Batch [80-100]	Speed: 165910.95 samples/sec	accuracy=nan
2021-11-05 21:02:59,940 Node[0] Epoch[11] Batch [100-120]	Speed: 166293.76 samples/sec	accuracy=nan
2021-11-05 21:03:00,333 Node[0] Epoch[11] Batch [120-140]	Speed: 166025.43 samples/sec	accuracy=nan
2021-11-05 21:03:00,728 Node[0] Epoch[11] Batch [140-160]	Speed: 165233.42 samples/sec	accuracy=nan
2021-11-05 21:03:01,121 Node[0] Epoch[11] Batch [160-180]	Speed: 165982.76 samples/sec	accuracy=nan
2021-11-05 21:03:01,517 Node[0] Epoch[11] Batch [180-200]	Speed: 164947.44 samples/sec	accuracy=nan
2021-11-05 21:03:01,910 Node[0] Epoch[11] Batch [200-220]	Speed: 166022.51 samples/sec	accuracy=nan
2021-11-05 21:03:02,303 Node[0] Epoch[11] Batch [220-240]	Speed: 166239.03 samples/sec	accuracy=nan
2021-11-05 21:03:02,697 Node[0] Epoch[11] Batch [240-260]	Speed: 165868.73 samples/sec	accuracy=nan
2021-11-05 21:03:03,089 Node[0] Epoch[11] Batch [260-280]	Speed: 166213.70 samples/sec	accuracy=nan
2021-11-05 21:03:03,481 Node[0] Epoch[11] Batch [280-300]	Speed: 166800.99 samples/sec	accuracy=nan
2021-11-05 21:03:03,876 Node[0] Epoch[11] Batch [300-320]	Speed: 165313.53 samples/sec	accuracy=nan
2021-11-05 21:03:04,274 Node[0] Epoch[11] Batch [320-340]	Speed: 163999.67 samples/sec	accuracy=nan
2021-11-05 21:03:04,672 Node[0] Epoch[11] Batch [340-360]	Speed: 163850.88 samples/sec	accuracy=nan
2021-11-05 21:03:05,072 Node[0] Epoch[11] Batch [360-380]	Speed: 163196.65 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146185310, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 12}}
2021-11-05 21:03:05,310 Node[0] Epoch[11] Time cost=7.733
:::MLLOG {"namespace": "", "time_ms": 1636146185310, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165675.26132984454}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 12}}
:::MLLOG {"namespace": "", "time_ms": 1636146185310, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165675.26132984454, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146185310, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 13}}
2021-11-05 21:03:05,727 Node[0] Epoch[12] Batch [0-20]	Speed: 164252.90 samples/sec	accuracy=nan
2021-11-05 21:03:06,121 Node[0] Epoch[12] Batch [20-40]	Speed: 165565.83 samples/sec	accuracy=nan
2021-11-05 21:03:06,513 Node[0] Epoch[12] Batch [40-60]	Speed: 166505.82 samples/sec	accuracy=nan
2021-11-05 21:03:06,905 Node[0] Epoch[12] Batch [60-80]	Speed: 166548.96 samples/sec	accuracy=nan
2021-11-05 21:03:07,298 Node[0] Epoch[12] Batch [80-100]	Speed: 166182.53 samples/sec	accuracy=nan
2021-11-05 21:03:07,693 Node[0] Epoch[12] Batch [100-120]	Speed: 165297.56 samples/sec	accuracy=nan
2021-11-05 21:03:08,086 Node[0] Epoch[12] Batch [120-140]	Speed: 166165.18 samples/sec	accuracy=nan
2021-11-05 21:03:08,477 Node[0] Epoch[12] Batch [140-160]	Speed: 166988.28 samples/sec	accuracy=nan
2021-11-05 21:03:08,871 Node[0] Epoch[12] Batch [160-180]	Speed: 165684.25 samples/sec	accuracy=nan
2021-11-05 21:03:09,265 Node[0] Epoch[12] Batch [180-200]	Speed: 165587.86 samples/sec	accuracy=nan
2021-11-05 21:03:09,663 Node[0] Epoch[12] Batch [200-220]	Speed: 164056.17 samples/sec	accuracy=nan
2021-11-05 21:03:10,058 Node[0] Epoch[12] Batch [220-240]	Speed: 165421.79 samples/sec	accuracy=nan
2021-11-05 21:03:10,450 Node[0] Epoch[12] Batch [240-260]	Speed: 166300.72 samples/sec	accuracy=nan
2021-11-05 21:03:10,842 Node[0] Epoch[12] Batch [260-280]	Speed: 166446.91 samples/sec	accuracy=nan
2021-11-05 21:03:11,235 Node[0] Epoch[12] Batch [280-300]	Speed: 166303.25 samples/sec	accuracy=nan
2021-11-05 21:03:11,627 Node[0] Epoch[12] Batch [300-320]	Speed: 166660.07 samples/sec	accuracy=nan
2021-11-05 21:03:12,022 Node[0] Epoch[12] Batch [320-340]	Speed: 165304.54 samples/sec	accuracy=nan
2021-11-05 21:03:12,422 Node[0] Epoch[12] Batch [340-360]	Speed: 162943.66 samples/sec	accuracy=nan
2021-11-05 21:03:12,817 Node[0] Epoch[12] Batch [360-380]	Speed: 165510.29 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146193055, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 13}}
2021-11-05 21:03:13,055 Node[0] Epoch[12] Time cost=7.745
:::MLLOG {"namespace": "", "time_ms": 1636146193055, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165426.04017421562}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 13}}
:::MLLOG {"namespace": "", "time_ms": 1636146193055, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165426.04017421562, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146193055, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 14}}
2021-11-05 21:03:13,467 Node[0] Epoch[13] Batch [0-20]	Speed: 166130.40 samples/sec	accuracy=nan
2021-11-05 21:03:13,862 Node[0] Epoch[13] Batch [20-40]	Speed: 165632.84 samples/sec	accuracy=nan
2021-11-05 21:03:14,255 Node[0] Epoch[13] Batch [40-60]	Speed: 165777.35 samples/sec	accuracy=nan
2021-11-05 21:03:14,647 Node[0] Epoch[13] Batch [60-80]	Speed: 166530.12 samples/sec	accuracy=nan
2021-11-05 21:03:15,040 Node[0] Epoch[13] Batch [80-100]	Speed: 166409.68 samples/sec	accuracy=nan
2021-11-05 21:03:15,432 Node[0] Epoch[13] Batch [100-120]	Speed: 166270.02 samples/sec	accuracy=nan
2021-11-05 21:03:15,824 Node[0] Epoch[13] Batch [120-140]	Speed: 166741.47 samples/sec	accuracy=nan
2021-11-05 21:03:16,217 Node[0] Epoch[13] Batch [140-160]	Speed: 166016.98 samples/sec	accuracy=nan
2021-11-05 21:03:16,609 Node[0] Epoch[13] Batch [160-180]	Speed: 166620.11 samples/sec	accuracy=nan
2021-11-05 21:03:17,005 Node[0] Epoch[13] Batch [180-200]	Speed: 164583.95 samples/sec	accuracy=nan
2021-11-05 21:03:17,401 Node[0] Epoch[13] Batch [200-220]	Speed: 165105.58 samples/sec	accuracy=nan
2021-11-05 21:03:17,797 Node[0] Epoch[13] Batch [220-240]	Speed: 164787.61 samples/sec	accuracy=nan
2021-11-05 21:03:18,190 Node[0] Epoch[13] Batch [240-260]	Speed: 166182.53 samples/sec	accuracy=nan
2021-11-05 21:03:18,583 Node[0] Epoch[13] Batch [260-280]	Speed: 165948.56 samples/sec	accuracy=nan
2021-11-05 21:03:18,975 Node[0] Epoch[13] Batch [280-300]	Speed: 166500.76 samples/sec	accuracy=nan
2021-11-05 21:03:19,370 Node[0] Epoch[13] Batch [300-320]	Speed: 165473.48 samples/sec	accuracy=nan
2021-11-05 21:03:19,766 Node[0] Epoch[13] Batch [320-340]	Speed: 164872.74 samples/sec	accuracy=nan
2021-11-05 21:03:20,163 Node[0] Epoch[13] Batch [340-360]	Speed: 164189.57 samples/sec	accuracy=nan
2021-11-05 21:03:20,562 Node[0] Epoch[13] Batch [360-380]	Speed: 163636.82 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146200800, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 14}}
2021-11-05 21:03:20,800 Node[0] Epoch[13] Time cost=7.745
:::MLLOG {"namespace": "", "time_ms": 1636146200800, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165423.85546492008}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 14}}
:::MLLOG {"namespace": "", "time_ms": 1636146200800, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165423.85546492008, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146200800, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 15}}
2021-11-05 21:03:21,212 Node[0] Epoch[14] Batch [0-20]	Speed: 166308.30 samples/sec	accuracy=nan
2021-11-05 21:03:21,608 Node[0] Epoch[14] Batch [20-40]	Speed: 164846.84 samples/sec	accuracy=nan
2021-11-05 21:03:22,004 Node[0] Epoch[14] Batch [40-60]	Speed: 165158.07 samples/sec	accuracy=nan
2021-11-05 21:03:22,396 Node[0] Epoch[14] Batch [60-80]	Speed: 166286.79 samples/sec	accuracy=nan
2021-11-05 21:03:22,789 Node[0] Epoch[14] Batch [80-100]	Speed: 166224.40 samples/sec	accuracy=nan
2021-11-05 21:03:23,182 Node[0] Epoch[14] Batch [100-120]	Speed: 166130.30 samples/sec	accuracy=nan
2021-11-05 21:03:23,576 Node[0] Epoch[14] Batch [120-140]	Speed: 165642.56 samples/sec	accuracy=nan
2021-11-05 21:03:23,967 Node[0] Epoch[14] Batch [140-160]	Speed: 166911.32 samples/sec	accuracy=nan
2021-11-05 21:03:24,362 Node[0] Epoch[14] Batch [160-180]	Speed: 165504.79 samples/sec	accuracy=nan
2021-11-05 21:03:24,755 Node[0] Epoch[14] Batch [180-200]	Speed: 165733.90 samples/sec	accuracy=nan
2021-11-05 21:03:25,149 Node[0] Epoch[14] Batch [200-220]	Speed: 165697.29 samples/sec	accuracy=nan
2021-11-05 21:03:25,543 Node[0] Epoch[14] Batch [220-240]	Speed: 166032.48 samples/sec	accuracy=nan
2021-11-05 21:03:25,936 Node[0] Epoch[14] Batch [240-260]	Speed: 165841.91 samples/sec	accuracy=nan
2021-11-05 21:03:26,331 Node[0] Epoch[14] Batch [260-280]	Speed: 165345.27 samples/sec	accuracy=nan
2021-11-05 21:03:26,725 Node[0] Epoch[14] Batch [280-300]	Speed: 165767.31 samples/sec	accuracy=nan
2021-11-05 21:03:27,122 Node[0] Epoch[14] Batch [300-320]	Speed: 164253.20 samples/sec	accuracy=nan
2021-11-05 21:03:27,517 Node[0] Epoch[14] Batch [320-340]	Speed: 165233.12 samples/sec	accuracy=nan
2021-11-05 21:03:27,916 Node[0] Epoch[14] Batch [340-360]	Speed: 163855.69 samples/sec	accuracy=nan
2021-11-05 21:03:28,313 Node[0] Epoch[14] Batch [360-380]	Speed: 164120.87 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146208549, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 15}}
2021-11-05 21:03:28,549 Node[0] Epoch[14] Time cost=7.749
:::MLLOG {"namespace": "", "time_ms": 1636146208550, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165335.20191990043}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636146208550, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165335.20191990043, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146208566, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 15}}
2021-11-05 21:03:28,681 Node[0] Epoch[14] Validation-accuracy=0.563380
2021-11-05 21:03:28,681 Node[0] Epoch[14] Validation-correct-count=440.000000
2021-11-05 21:03:28,682 Node[0] Epoch[14] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146208706, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636146208706, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.58112, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636146208706, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1636146208706, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 16, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146208706, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 16}}
2021-11-05 21:03:29,102 Node[0] Epoch[15] Batch [0-20]	Speed: 167378.33 samples/sec	accuracy=nan
2021-11-05 21:03:29,494 Node[0] Epoch[15] Batch [20-40]	Speed: 166206.64 samples/sec	accuracy=nan
2021-11-05 21:03:29,889 Node[0] Epoch[15] Batch [40-60]	Speed: 165561.43 samples/sec	accuracy=nan
2021-11-05 21:03:30,281 Node[0] Epoch[15] Batch [60-80]	Speed: 166280.63 samples/sec	accuracy=nan
2021-11-05 21:03:30,672 Node[0] Epoch[15] Batch [80-100]	Speed: 166934.83 samples/sec	accuracy=nan
2021-11-05 21:03:31,066 Node[0] Epoch[15] Batch [100-120]	Speed: 165740.22 samples/sec	accuracy=nan
2021-11-05 21:03:31,459 Node[0] Epoch[15] Batch [120-140]	Speed: 166258.31 samples/sec	accuracy=nan
2021-11-05 21:03:31,851 Node[0] Epoch[15] Batch [140-160]	Speed: 166571.86 samples/sec	accuracy=nan
2021-11-05 21:03:32,245 Node[0] Epoch[15] Batch [160-180]	Speed: 165501.88 samples/sec	accuracy=nan
2021-11-05 21:03:32,638 Node[0] Epoch[15] Batch [180-200]	Speed: 166130.40 samples/sec	accuracy=nan
2021-11-05 21:03:33,031 Node[0] Epoch[15] Batch [200-220]	Speed: 166315.88 samples/sec	accuracy=nan
2021-11-05 21:03:33,426 Node[0] Epoch[15] Batch [220-240]	Speed: 165209.29 samples/sec	accuracy=nan
2021-11-05 21:03:33,818 Node[0] Epoch[15] Batch [240-260]	Speed: 166411.80 samples/sec	accuracy=nan
2021-11-05 21:03:34,216 Node[0] Epoch[15] Batch [260-280]	Speed: 164012.73 samples/sec	accuracy=nan
2021-11-05 21:03:34,608 Node[0] Epoch[15] Batch [280-300]	Speed: 166451.06 samples/sec	accuracy=nan
2021-11-05 21:03:35,001 Node[0] Epoch[15] Batch [300-320]	Speed: 166284.36 samples/sec	accuracy=nan
2021-11-05 21:03:35,399 Node[0] Epoch[15] Batch [320-340]	Speed: 164046.73 samples/sec	accuracy=nan
2021-11-05 21:03:35,796 Node[0] Epoch[15] Batch [340-360]	Speed: 164300.41 samples/sec	accuracy=nan
2021-11-05 21:03:36,195 Node[0] Epoch[15] Batch [360-380]	Speed: 163723.02 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146216431, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 16}}
2021-11-05 21:03:36,432 Node[0] Epoch[15] Time cost=7.725
:::MLLOG {"namespace": "", "time_ms": 1636146216432, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165844.18591855612}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 16}}
:::MLLOG {"namespace": "", "time_ms": 1636146216432, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165844.18591855612, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146216432, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 17}}
2021-11-05 21:03:36,848 Node[0] Epoch[16] Batch [0-20]	Speed: 164517.69 samples/sec	accuracy=nan
2021-11-05 21:03:37,241 Node[0] Epoch[16] Batch [20-40]	Speed: 166198.97 samples/sec	accuracy=nan
2021-11-05 21:03:37,634 Node[0] Epoch[16] Batch [40-60]	Speed: 165856.78 samples/sec	accuracy=nan
2021-11-05 21:03:38,027 Node[0] Epoch[16] Batch [60-80]	Speed: 166327.80 samples/sec	accuracy=nan
2021-11-05 21:03:38,418 Node[0] Epoch[16] Batch [80-100]	Speed: 166663.01 samples/sec	accuracy=nan
2021-11-05 21:03:38,811 Node[0] Epoch[16] Batch [100-120]	Speed: 166450.45 samples/sec	accuracy=nan
2021-11-05 21:03:39,203 Node[0] Epoch[16] Batch [120-140]	Speed: 166410.29 samples/sec	accuracy=nan
2021-11-05 21:03:39,597 Node[0] Epoch[16] Batch [140-160]	Speed: 165643.46 samples/sec	accuracy=nan
2021-11-05 21:03:39,990 Node[0] Epoch[16] Batch [160-180]	Speed: 166274.67 samples/sec	accuracy=nan
2021-11-05 21:03:40,385 Node[0] Epoch[16] Batch [180-200]	Speed: 165224.64 samples/sec	accuracy=nan
2021-11-05 21:03:40,778 Node[0] Epoch[16] Batch [200-220]	Speed: 165935.58 samples/sec	accuracy=nan
2021-11-05 21:03:41,172 Node[0] Epoch[16] Batch [220-240]	Speed: 165767.91 samples/sec	accuracy=nan
2021-11-05 21:03:41,566 Node[0] Epoch[16] Batch [240-260]	Speed: 165687.46 samples/sec	accuracy=nan
2021-11-05 21:03:41,959 Node[0] Epoch[16] Batch [260-280]	Speed: 166233.48 samples/sec	accuracy=nan
2021-11-05 21:03:42,353 Node[0] Epoch[16] Batch [280-300]	Speed: 165496.48 samples/sec	accuracy=nan
2021-11-05 21:03:42,748 Node[0] Epoch[16] Batch [300-320]	Speed: 165423.59 samples/sec	accuracy=nan
2021-11-05 21:03:43,142 Node[0] Epoch[16] Batch [320-340]	Speed: 165459.58 samples/sec	accuracy=nan
2021-11-05 21:03:43,541 Node[0] Epoch[16] Batch [340-360]	Speed: 163840.69 samples/sec	accuracy=nan
2021-11-05 21:03:43,938 Node[0] Epoch[16] Batch [360-380]	Speed: 164453.56 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146224174, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 17}}
2021-11-05 21:03:44,174 Node[0] Epoch[16] Time cost=7.742
:::MLLOG {"namespace": "", "time_ms": 1636146224174, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165473.43557623334}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 17}}
:::MLLOG {"namespace": "", "time_ms": 1636146224175, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165473.43557623334, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146224175, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 18}}
2021-11-05 21:03:44,588 Node[0] Epoch[17] Batch [0-20]	Speed: 165914.77 samples/sec	accuracy=nan
2021-11-05 21:03:44,980 Node[0] Epoch[17] Batch [20-40]	Speed: 166382.78 samples/sec	accuracy=nan
2021-11-05 21:03:45,374 Node[0] Epoch[17] Batch [40-60]	Speed: 165683.35 samples/sec	accuracy=nan
2021-11-05 21:03:45,768 Node[0] Epoch[17] Batch [60-80]	Speed: 165486.98 samples/sec	accuracy=nan
2021-11-05 21:03:46,164 Node[0] Epoch[17] Batch [80-100]	Speed: 165086.17 samples/sec	accuracy=nan
2021-11-05 21:03:46,559 Node[0] Epoch[17] Batch [100-120]	Speed: 165110.16 samples/sec	accuracy=nan
2021-11-05 21:03:46,951 Node[0] Epoch[17] Batch [120-140]	Speed: 166545.32 samples/sec	accuracy=nan
2021-11-05 21:03:47,344 Node[0] Epoch[17] Batch [140-160]	Speed: 166290.83 samples/sec	accuracy=nan
2021-11-05 21:03:47,737 Node[0] Epoch[17] Batch [160-180]	Speed: 166082.64 samples/sec	accuracy=nan
2021-11-05 21:03:48,130 Node[0] Epoch[17] Batch [180-200]	Speed: 166203.71 samples/sec	accuracy=nan
2021-11-05 21:03:48,526 Node[0] Epoch[17] Batch [200-220]	Speed: 164827.68 samples/sec	accuracy=nan
2021-11-05 21:03:48,920 Node[0] Epoch[17] Batch [220-240]	Speed: 165585.76 samples/sec	accuracy=nan
2021-11-05 21:03:49,311 Node[0] Epoch[17] Batch [240-260]	Speed: 166980.54 samples/sec	accuracy=nan
2021-11-05 21:03:49,704 Node[0] Epoch[17] Batch [260-280]	Speed: 166179.30 samples/sec	accuracy=nan
2021-11-05 21:03:50,096 Node[0] Epoch[17] Batch [280-300]	Speed: 166531.54 samples/sec	accuracy=nan
2021-11-05 21:03:50,491 Node[0] Epoch[17] Batch [300-320]	Speed: 165004.29 samples/sec	accuracy=nan
2021-11-05 21:03:50,888 Node[0] Epoch[17] Batch [320-340]	Speed: 164518.39 samples/sec	accuracy=nan
2021-11-05 21:03:51,285 Node[0] Epoch[17] Batch [340-360]	Speed: 164613.34 samples/sec	accuracy=nan
2021-11-05 21:03:51,682 Node[0] Epoch[17] Batch [360-380]	Speed: 164273.60 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146231918, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 18}}
2021-11-05 21:03:51,918 Node[0] Epoch[17] Time cost=7.743
:::MLLOG {"namespace": "", "time_ms": 1636146231918, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165456.8308508412}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 18}}
:::MLLOG {"namespace": "", "time_ms": 1636146231918, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165456.8308508412, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146231918, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 19}}
2021-11-05 21:03:52,331 Node[0] Epoch[18] Batch [0-20]	Speed: 165832.67 samples/sec	accuracy=nan
2021-11-05 21:03:52,724 Node[0] Epoch[18] Batch [20-40]	Speed: 165922.71 samples/sec	accuracy=nan
2021-11-05 21:03:53,117 Node[0] Epoch[18] Batch [40-60]	Speed: 166501.77 samples/sec	accuracy=nan
2021-11-05 21:03:53,509 Node[0] Epoch[18] Batch [60-80]	Speed: 166344.88 samples/sec	accuracy=nan
2021-11-05 21:03:53,903 Node[0] Epoch[18] Batch [80-100]	Speed: 165511.49 samples/sec	accuracy=nan
2021-11-05 21:03:54,296 Node[0] Epoch[18] Batch [100-120]	Speed: 166412.82 samples/sec	accuracy=nan
2021-11-05 21:03:54,687 Node[0] Epoch[18] Batch [120-140]	Speed: 166973.00 samples/sec	accuracy=nan
2021-11-05 21:03:55,079 Node[0] Epoch[18] Batch [140-160]	Speed: 166354.58 samples/sec	accuracy=nan
2021-11-05 21:03:55,474 Node[0] Epoch[18] Batch [160-180]	Speed: 165434.59 samples/sec	accuracy=nan
2021-11-05 21:03:55,869 Node[0] Epoch[18] Batch [180-200]	Speed: 165164.94 samples/sec	accuracy=nan
2021-11-05 21:03:56,260 Node[0] Epoch[18] Batch [200-220]	Speed: 167086.00 samples/sec	accuracy=nan
2021-11-05 21:03:56,653 Node[0] Epoch[18] Batch [220-240]	Speed: 165885.22 samples/sec	accuracy=nan
2021-11-05 21:03:57,045 Node[0] Epoch[18] Batch [240-260]	Speed: 166717.10 samples/sec	accuracy=nan
2021-11-05 21:03:57,439 Node[0] Epoch[18] Batch [260-280]	Speed: 165606.59 samples/sec	accuracy=nan
2021-11-05 21:03:57,831 Node[0] Epoch[18] Batch [280-300]	Speed: 166304.16 samples/sec	accuracy=nan
2021-11-05 21:03:58,224 Node[0] Epoch[18] Batch [300-320]	Speed: 166412.51 samples/sec	accuracy=nan
2021-11-05 21:03:58,619 Node[0] Epoch[18] Batch [320-340]	Speed: 165066.76 samples/sec	accuracy=nan
2021-11-05 21:03:59,022 Node[0] Epoch[18] Batch [340-360]	Speed: 162198.48 samples/sec	accuracy=nan
2021-11-05 21:03:59,418 Node[0] Epoch[18] Batch [360-380]	Speed: 164725.35 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146239653, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 19}}
2021-11-05 21:03:59,653 Node[0] Epoch[18] Time cost=7.735
:::MLLOG {"namespace": "", "time_ms": 1636146239653, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165635.28055959631}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636146239653, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165635.28055959631, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146239670, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 19}}
2021-11-05 21:03:59,783 Node[0] Epoch[18] Validation-accuracy=0.651729
2021-11-05 21:03:59,783 Node[0] Epoch[18] Validation-correct-count=509.000000
2021-11-05 21:03:59,783 Node[0] Epoch[18] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146239802, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636146239802, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.65694, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636146239802, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1636146239802, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 20, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146239802, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 20}}
2021-11-05 21:04:00,202 Node[0] Epoch[19] Batch [0-20]	Speed: 165099.31 samples/sec	accuracy=nan
2021-11-05 21:04:00,595 Node[0] Epoch[19] Batch [20-40]	Speed: 166364.79 samples/sec	accuracy=nan
2021-11-05 21:04:00,991 Node[0] Epoch[19] Batch [40-60]	Speed: 164826.10 samples/sec	accuracy=nan
2021-11-05 21:04:01,383 Node[0] Epoch[19] Batch [60-80]	Speed: 166282.95 samples/sec	accuracy=nan
2021-11-05 21:04:01,775 Node[0] Epoch[19] Batch [80-100]	Speed: 166822.64 samples/sec	accuracy=nan
2021-11-05 21:04:02,169 Node[0] Epoch[19] Batch [100-120]	Speed: 165606.49 samples/sec	accuracy=nan
2021-11-05 21:04:02,563 Node[0] Epoch[19] Batch [120-140]	Speed: 165730.79 samples/sec	accuracy=nan
2021-11-05 21:04:02,955 Node[0] Epoch[19] Batch [140-160]	Speed: 166426.67 samples/sec	accuracy=nan
2021-11-05 21:04:03,350 Node[0] Epoch[19] Batch [160-180]	Speed: 165350.36 samples/sec	accuracy=nan
2021-11-05 21:04:03,743 Node[0] Epoch[19] Batch [180-200]	Speed: 166227.02 samples/sec	accuracy=nan
2021-11-05 21:04:04,135 Node[0] Epoch[19] Batch [200-220]	Speed: 166143.00 samples/sec	accuracy=nan
2021-11-05 21:04:04,531 Node[0] Epoch[19] Batch [220-240]	Speed: 165008.17 samples/sec	accuracy=nan
2021-11-05 21:04:04,924 Node[0] Epoch[19] Batch [240-260]	Speed: 166147.03 samples/sec	accuracy=nan
2021-11-05 21:04:05,320 Node[0] Epoch[19] Batch [260-280]	Speed: 165008.27 samples/sec	accuracy=nan
2021-11-05 21:04:05,716 Node[0] Epoch[19] Batch [280-300]	Speed: 164745.57 samples/sec	accuracy=nan
2021-11-05 21:04:06,110 Node[0] Epoch[19] Batch [300-320]	Speed: 165805.56 samples/sec	accuracy=nan
2021-11-05 21:04:06,505 Node[0] Epoch[19] Batch [320-340]	Speed: 165042.69 samples/sec	accuracy=nan
2021-11-05 21:04:06,901 Node[0] Epoch[19] Batch [340-360]	Speed: 164784.43 samples/sec	accuracy=nan
2021-11-05 21:04:07,305 Node[0] Epoch[19] Batch [360-380]	Speed: 161815.72 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146247540, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 20}}
2021-11-05 21:04:07,540 Node[0] Epoch[19] Time cost=7.738
:::MLLOG {"namespace": "", "time_ms": 1636146247540, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165567.76715524364}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1636146247541, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165567.76715524364, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146247541, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 21}}
2021-11-05 21:04:07,957 Node[0] Epoch[20] Batch [0-20]	Speed: 165832.97 samples/sec	accuracy=nan
2021-11-05 21:04:08,351 Node[0] Epoch[20] Batch [20-40]	Speed: 165677.34 samples/sec	accuracy=nan
2021-11-05 21:04:08,746 Node[0] Epoch[20] Batch [40-60]	Speed: 165211.08 samples/sec	accuracy=nan
2021-11-05 21:04:09,139 Node[0] Epoch[20] Batch [60-80]	Speed: 165973.60 samples/sec	accuracy=nan
2021-11-05 21:04:09,533 Node[0] Epoch[20] Batch [80-100]	Speed: 165913.16 samples/sec	accuracy=nan
2021-11-05 21:04:09,924 Node[0] Epoch[20] Batch [100-120]	Speed: 166705.53 samples/sec	accuracy=nan
2021-11-05 21:04:10,316 Node[0] Epoch[20] Batch [120-140]	Speed: 166766.86 samples/sec	accuracy=nan
2021-11-05 21:04:10,708 Node[0] Epoch[20] Batch [140-160]	Speed: 166272.75 samples/sec	accuracy=nan
2021-11-05 21:04:11,101 Node[0] Epoch[20] Batch [160-180]	Speed: 166247.21 samples/sec	accuracy=nan
2021-11-05 21:04:11,497 Node[0] Epoch[20] Batch [180-200]	Speed: 164709.89 samples/sec	accuracy=nan
2021-11-05 21:04:11,891 Node[0] Epoch[20] Batch [200-220]	Speed: 166061.89 samples/sec	accuracy=nan
2021-11-05 21:04:12,283 Node[0] Epoch[20] Batch [220-240]	Speed: 166397.54 samples/sec	accuracy=nan
2021-11-05 21:04:12,676 Node[0] Epoch[20] Batch [240-260]	Speed: 165957.41 samples/sec	accuracy=nan
2021-11-05 21:04:13,069 Node[0] Epoch[20] Batch [260-280]	Speed: 166062.39 samples/sec	accuracy=nan
2021-11-05 21:04:13,461 Node[0] Epoch[20] Batch [280-300]	Speed: 166779.35 samples/sec	accuracy=nan
2021-11-05 21:04:13,854 Node[0] Epoch[20] Batch [300-320]	Speed: 165957.31 samples/sec	accuracy=nan
2021-11-05 21:04:14,252 Node[0] Epoch[20] Batch [320-340]	Speed: 163902.67 samples/sec	accuracy=nan
2021-11-05 21:04:14,649 Node[0] Epoch[20] Batch [340-360]	Speed: 164448.72 samples/sec	accuracy=nan
2021-11-05 21:04:15,049 Node[0] Epoch[20] Batch [360-380]	Speed: 163428.39 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146255285, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 21}}
2021-11-05 21:04:15,285 Node[0] Epoch[20] Time cost=7.744
:::MLLOG {"namespace": "", "time_ms": 1636146255285, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165430.1754929176}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 21}}
:::MLLOG {"namespace": "", "time_ms": 1636146255286, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165430.1754929176, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146255286, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 22}}
2021-11-05 21:04:15,698 Node[0] Epoch[21] Batch [0-20]	Speed: 165840.40 samples/sec	accuracy=nan
2021-11-05 21:04:16,094 Node[0] Epoch[21] Batch [20-40]	Speed: 165187.86 samples/sec	accuracy=nan
2021-11-05 21:04:16,487 Node[0] Epoch[21] Batch [40-60]	Speed: 165907.13 samples/sec	accuracy=nan
2021-11-05 21:04:16,881 Node[0] Epoch[21] Batch [60-80]	Speed: 165821.22 samples/sec	accuracy=nan
2021-11-05 21:04:17,273 Node[0] Epoch[21] Batch [80-100]	Speed: 166456.32 samples/sec	accuracy=nan
2021-11-05 21:04:17,665 Node[0] Epoch[21] Batch [100-120]	Speed: 166596.19 samples/sec	accuracy=nan
2021-11-05 21:04:18,057 Node[0] Epoch[21] Batch [120-140]	Speed: 166272.35 samples/sec	accuracy=nan
2021-11-05 21:04:18,452 Node[0] Epoch[21] Batch [140-160]	Speed: 165421.79 samples/sec	accuracy=nan
2021-11-05 21:04:18,847 Node[0] Epoch[21] Batch [160-180]	Speed: 165439.28 samples/sec	accuracy=nan
2021-11-05 21:04:19,241 Node[0] Epoch[21] Batch [180-200]	Speed: 165538.61 samples/sec	accuracy=nan
2021-11-05 21:04:19,635 Node[0] Epoch[21] Batch [200-220]	Speed: 165692.38 samples/sec	accuracy=nan
2021-11-05 21:04:20,028 Node[0] Epoch[21] Batch [220-240]	Speed: 166223.29 samples/sec	accuracy=nan
2021-11-05 21:04:20,423 Node[0] Epoch[21] Batch [240-260]	Speed: 165192.94 samples/sec	accuracy=nan
2021-11-05 21:04:20,818 Node[0] Epoch[21] Batch [260-280]	Speed: 165371.24 samples/sec	accuracy=nan
2021-11-05 21:04:21,209 Node[0] Epoch[21] Batch [280-300]	Speed: 166646.28 samples/sec	accuracy=nan
2021-11-05 21:04:21,602 Node[0] Epoch[21] Batch [300-320]	Speed: 166031.27 samples/sec	accuracy=nan
2021-11-05 21:04:21,998 Node[0] Epoch[21] Batch [320-340]	Speed: 164997.13 samples/sec	accuracy=nan
2021-11-05 21:04:22,396 Node[0] Epoch[21] Batch [340-360]	Speed: 164206.70 samples/sec	accuracy=nan
2021-11-05 21:04:22,791 Node[0] Epoch[21] Batch [360-380]	Speed: 165039.00 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146263028, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 22}}
2021-11-05 21:04:23,028 Node[0] Epoch[21] Time cost=7.743
:::MLLOG {"namespace": "", "time_ms": 1636146263028, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165468.0140905138}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 22}}
:::MLLOG {"namespace": "", "time_ms": 1636146263029, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165468.0140905138, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146263029, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 23}}
2021-11-05 21:04:23,440 Node[0] Epoch[22] Batch [0-20]	Speed: 166305.67 samples/sec	accuracy=nan
2021-11-05 21:04:23,834 Node[0] Epoch[22] Batch [20-40]	Speed: 165564.63 samples/sec	accuracy=nan
2021-11-05 21:04:24,228 Node[0] Epoch[22] Batch [40-60]	Speed: 165895.27 samples/sec	accuracy=nan
2021-11-05 21:04:24,619 Node[0] Epoch[22] Batch [60-80]	Speed: 166968.73 samples/sec	accuracy=nan
2021-11-05 21:04:25,014 Node[0] Epoch[22] Batch [80-100]	Speed: 165183.08 samples/sec	accuracy=nan
2021-11-05 21:04:25,408 Node[0] Epoch[22] Batch [100-120]	Speed: 165537.61 samples/sec	accuracy=nan
2021-11-05 21:04:25,802 Node[0] Epoch[22] Batch [120-140]	Speed: 165937.19 samples/sec	accuracy=nan
2021-11-05 21:04:26,193 Node[0] Epoch[22] Batch [140-160]	Speed: 166964.35 samples/sec	accuracy=nan
2021-11-05 21:04:26,586 Node[0] Epoch[22] Batch [160-180]	Speed: 166046.38 samples/sec	accuracy=nan
2021-11-05 21:04:26,980 Node[0] Epoch[22] Batch [180-200]	Speed: 165496.58 samples/sec	accuracy=nan
2021-11-05 21:04:27,375 Node[0] Epoch[22] Batch [200-220]	Speed: 165281.09 samples/sec	accuracy=nan
2021-11-05 21:04:27,771 Node[0] Epoch[22] Batch [220-240]	Speed: 165054.03 samples/sec	accuracy=nan
2021-11-05 21:04:28,166 Node[0] Epoch[22] Batch [240-260]	Speed: 165144.22 samples/sec	accuracy=nan
2021-11-05 21:04:28,561 Node[0] Epoch[22] Batch [260-280]	Speed: 165444.28 samples/sec	accuracy=nan
2021-11-05 21:04:28,953 Node[0] Epoch[22] Batch [280-300]	Speed: 166563.96 samples/sec	accuracy=nan
2021-11-05 21:04:29,347 Node[0] Epoch[22] Batch [300-320]	Speed: 165711.43 samples/sec	accuracy=nan
2021-11-05 21:04:29,746 Node[0] Epoch[22] Batch [320-340]	Speed: 163324.57 samples/sec	accuracy=nan
2021-11-05 21:04:30,143 Node[0] Epoch[22] Batch [340-360]	Speed: 164773.43 samples/sec	accuracy=nan
2021-11-05 21:04:30,538 Node[0] Epoch[22] Batch [360-380]	Speed: 164955.88 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146270776, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 23}}
2021-11-05 21:04:30,777 Node[0] Epoch[22] Time cost=7.748
:::MLLOG {"namespace": "", "time_ms": 1636146270777, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165357.5472119367}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636146270777, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165357.5472119367, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146270794, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 23}}
2021-11-05 21:04:30,904 Node[0] Epoch[22] Validation-accuracy=0.685019
2021-11-05 21:04:30,904 Node[0] Epoch[22] Validation-correct-count=535.000000
2021-11-05 21:04:30,904 Node[0] Epoch[22] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146270926, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636146270926, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.69168, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636146270926, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1636146270926, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 24, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146270926, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 24}}
2021-11-05 21:04:31,323 Node[0] Epoch[23] Batch [0-20]	Speed: 166665.55 samples/sec	accuracy=nan
2021-11-05 21:04:31,715 Node[0] Epoch[23] Batch [20-40]	Speed: 166380.46 samples/sec	accuracy=nan
2021-11-05 21:04:32,111 Node[0] Epoch[23] Batch [40-60]	Speed: 164992.96 samples/sec	accuracy=nan
2021-11-05 21:04:32,503 Node[0] Epoch[23] Batch [60-80]	Speed: 166557.37 samples/sec	accuracy=nan
2021-11-05 21:04:32,895 Node[0] Epoch[23] Batch [80-100]	Speed: 166160.24 samples/sec	accuracy=nan
2021-11-05 21:04:33,290 Node[0] Epoch[23] Batch [100-120]	Speed: 165501.68 samples/sec	accuracy=nan
2021-11-05 21:04:33,681 Node[0] Epoch[23] Batch [120-140]	Speed: 166957.73 samples/sec	accuracy=nan
2021-11-05 21:04:34,075 Node[0] Epoch[23] Batch [140-160]	Speed: 165552.52 samples/sec	accuracy=nan
2021-11-05 21:04:34,467 Node[0] Epoch[23] Batch [160-180]	Speed: 166583.72 samples/sec	accuracy=nan
2021-11-05 21:04:34,863 Node[0] Epoch[23] Batch [180-200]	Speed: 165056.42 samples/sec	accuracy=nan
2021-11-05 21:04:35,257 Node[0] Epoch[23] Batch [200-220]	Speed: 165383.02 samples/sec	accuracy=nan
2021-11-05 21:04:35,652 Node[0] Epoch[23] Batch [220-240]	Speed: 165549.72 samples/sec	accuracy=nan
2021-11-05 21:04:36,045 Node[0] Epoch[23] Batch [240-260]	Speed: 166140.58 samples/sec	accuracy=nan
2021-11-05 21:04:36,438 Node[0] Epoch[23] Batch [260-280]	Speed: 165971.29 samples/sec	accuracy=nan
2021-11-05 21:04:36,830 Node[0] Epoch[23] Batch [280-300]	Speed: 166459.56 samples/sec	accuracy=nan
2021-11-05 21:04:37,226 Node[0] Epoch[23] Batch [300-320]	Speed: 164698.49 samples/sec	accuracy=nan
2021-11-05 21:04:37,621 Node[0] Epoch[23] Batch [320-340]	Speed: 165237.51 samples/sec	accuracy=nan
2021-11-05 21:04:38,020 Node[0] Epoch[23] Batch [340-360]	Speed: 163993.18 samples/sec	accuracy=nan
2021-11-05 21:04:38,415 Node[0] Epoch[23] Batch [360-380]	Speed: 164977.25 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146278651, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 24}}
2021-11-05 21:04:38,652 Node[0] Epoch[23] Time cost=7.725
:::MLLOG {"namespace": "", "time_ms": 1636146278652, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165837.76768403323}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 24}}
:::MLLOG {"namespace": "", "time_ms": 1636146278652, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165837.76768403323, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146278652, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 25}}
2021-11-05 21:04:39,071 Node[0] Epoch[24] Batch [0-20]	Speed: 173417.69 samples/sec	accuracy=nan
2021-11-05 21:04:39,465 Node[0] Epoch[24] Batch [20-40]	Speed: 165889.64 samples/sec	accuracy=nan
2021-11-05 21:04:39,857 Node[0] Epoch[24] Batch [40-60]	Speed: 166281.33 samples/sec	accuracy=nan
2021-11-05 21:04:40,251 Node[0] Epoch[24] Batch [60-80]	Speed: 165941.82 samples/sec	accuracy=nan
2021-11-05 21:04:40,642 Node[0] Epoch[24] Batch [80-100]	Speed: 166721.67 samples/sec	accuracy=nan
2021-11-05 21:04:41,034 Node[0] Epoch[24] Batch [100-120]	Speed: 166620.21 samples/sec	accuracy=nan
2021-11-05 21:04:41,426 Node[0] Epoch[24] Batch [120-140]	Speed: 166671.84 samples/sec	accuracy=nan
2021-11-05 21:04:41,818 Node[0] Epoch[24] Batch [140-160]	Speed: 166336.19 samples/sec	accuracy=nan
2021-11-05 21:04:42,211 Node[0] Epoch[24] Batch [160-180]	Speed: 166165.18 samples/sec	accuracy=nan
2021-11-05 21:04:42,605 Node[0] Epoch[24] Batch [180-200]	Speed: 165719.45 samples/sec	accuracy=nan
2021-11-05 21:04:42,998 Node[0] Epoch[24] Batch [200-220]	Speed: 166005.20 samples/sec	accuracy=nan
2021-11-05 21:04:43,389 Node[0] Epoch[24] Batch [220-240]	Speed: 166859.04 samples/sec	accuracy=nan
2021-11-05 21:04:43,785 Node[0] Epoch[24] Batch [240-260]	Speed: 165130.38 samples/sec	accuracy=nan
2021-11-05 21:04:44,177 Node[0] Epoch[24] Batch [260-280]	Speed: 166500.35 samples/sec	accuracy=nan
2021-11-05 21:04:44,569 Node[0] Epoch[24] Batch [280-300]	Speed: 166349.22 samples/sec	accuracy=nan
2021-11-05 21:04:44,963 Node[0] Epoch[24] Batch [300-320]	Speed: 165840.71 samples/sec	accuracy=nan
2021-11-05 21:04:45,358 Node[0] Epoch[24] Batch [320-340]	Speed: 165270.02 samples/sec	accuracy=nan
2021-11-05 21:04:45,757 Node[0] Epoch[24] Batch [340-360]	Speed: 163659.12 samples/sec	accuracy=nan
2021-11-05 21:04:46,154 Node[0] Epoch[24] Batch [360-380]	Speed: 164245.61 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146286392, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 25}}
2021-11-05 21:04:46,392 Node[0] Epoch[24] Time cost=7.740
:::MLLOG {"namespace": "", "time_ms": 1636146286392, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165521.42917461556}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 25}}
:::MLLOG {"namespace": "", "time_ms": 1636146286393, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165521.42917461556, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146286393, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 26}}
2021-11-05 21:04:46,805 Node[0] Epoch[25] Batch [0-20]	Speed: 166148.65 samples/sec	accuracy=nan
2021-11-05 21:04:47,197 Node[0] Epoch[25] Batch [20-40]	Speed: 166533.47 samples/sec	accuracy=nan
2021-11-05 21:04:47,589 Node[0] Epoch[25] Batch [40-60]	Speed: 166135.84 samples/sec	accuracy=nan
2021-11-05 21:04:47,983 Node[0] Epoch[25] Batch [60-80]	Speed: 166008.82 samples/sec	accuracy=nan
2021-11-05 21:04:48,375 Node[0] Epoch[25] Batch [80-100]	Speed: 166386.93 samples/sec	accuracy=nan
2021-11-05 21:04:48,767 Node[0] Epoch[25] Batch [100-120]	Speed: 166543.49 samples/sec	accuracy=nan
2021-11-05 21:04:49,159 Node[0] Epoch[25] Batch [120-140]	Speed: 166392.19 samples/sec	accuracy=nan
2021-11-05 21:04:49,554 Node[0] Epoch[25] Batch [140-160]	Speed: 165598.08 samples/sec	accuracy=nan
2021-11-05 21:04:49,948 Node[0] Epoch[25] Batch [160-180]	Speed: 165292.87 samples/sec	accuracy=nan
2021-11-05 21:04:50,345 Node[0] Epoch[25] Batch [180-200]	Speed: 164650.16 samples/sec	accuracy=nan
2021-11-05 21:04:50,740 Node[0] Epoch[25] Batch [200-220]	Speed: 165445.98 samples/sec	accuracy=nan
2021-11-05 21:04:51,133 Node[0] Epoch[25] Batch [220-240]	Speed: 165984.77 samples/sec	accuracy=nan
2021-11-05 21:04:51,527 Node[0] Epoch[25] Batch [240-260]	Speed: 165630.83 samples/sec	accuracy=nan
2021-11-05 21:04:51,919 Node[0] Epoch[25] Batch [260-280]	Speed: 166336.59 samples/sec	accuracy=nan
2021-11-05 21:04:52,311 Node[0] Epoch[25] Batch [280-300]	Speed: 166819.90 samples/sec	accuracy=nan
2021-11-05 21:04:52,707 Node[0] Epoch[25] Batch [300-320]	Speed: 164809.92 samples/sec	accuracy=nan
2021-11-05 21:04:53,105 Node[0] Epoch[25] Batch [320-340]	Speed: 163894.63 samples/sec	accuracy=nan
2021-11-05 21:04:53,503 Node[0] Epoch[25] Batch [340-360]	Speed: 164204.24 samples/sec	accuracy=nan
2021-11-05 21:04:53,900 Node[0] Epoch[25] Batch [360-380]	Speed: 164435.49 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146294137, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 26}}
2021-11-05 21:04:54,137 Node[0] Epoch[25] Time cost=7.744
:::MLLOG {"namespace": "", "time_ms": 1636146294137, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165437.82535891325}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 26}}
:::MLLOG {"namespace": "", "time_ms": 1636146294137, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165437.82535891325, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146294137, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 27}}
2021-11-05 21:04:54,549 Node[0] Epoch[26] Batch [0-20]	Speed: 166122.54 samples/sec	accuracy=nan
2021-11-05 21:04:54,943 Node[0] Epoch[26] Batch [20-40]	Speed: 165601.28 samples/sec	accuracy=nan
2021-11-05 21:04:55,336 Node[0] Epoch[26] Batch [40-60]	Speed: 166296.08 samples/sec	accuracy=nan
2021-11-05 21:04:55,728 Node[0] Epoch[26] Batch [60-80]	Speed: 166560.41 samples/sec	accuracy=nan
2021-11-05 21:04:56,123 Node[0] Epoch[26] Batch [80-100]	Speed: 165227.93 samples/sec	accuracy=nan
2021-11-05 21:04:56,516 Node[0] Epoch[26] Batch [100-120]	Speed: 165829.56 samples/sec	accuracy=nan
2021-11-05 21:04:56,907 Node[0] Epoch[26] Batch [120-140]	Speed: 166936.35 samples/sec	accuracy=nan
2021-11-05 21:04:57,301 Node[0] Epoch[26] Batch [140-160]	Speed: 165956.10 samples/sec	accuracy=nan
2021-11-05 21:04:57,694 Node[0] Epoch[26] Batch [160-180]	Speed: 166146.23 samples/sec	accuracy=nan
2021-11-05 21:04:58,086 Node[0] Epoch[26] Batch [180-200]	Speed: 166464.21 samples/sec	accuracy=nan
2021-11-05 21:04:58,480 Node[0] Epoch[26] Batch [200-220]	Speed: 165634.04 samples/sec	accuracy=nan
2021-11-05 21:04:58,872 Node[0] Epoch[26] Batch [220-240]	Speed: 166439.22 samples/sec	accuracy=nan
2021-11-05 21:04:59,265 Node[0] Epoch[26] Batch [240-260]	Speed: 166043.86 samples/sec	accuracy=nan
2021-11-05 21:04:59,659 Node[0] Epoch[26] Batch [260-280]	Speed: 166008.52 samples/sec	accuracy=nan
2021-11-05 21:05:00,052 Node[0] Epoch[26] Batch [280-300]	Speed: 166028.25 samples/sec	accuracy=nan
2021-11-05 21:05:00,446 Node[0] Epoch[26] Batch [300-320]	Speed: 165357.35 samples/sec	accuracy=nan
2021-11-05 21:05:00,840 Node[0] Epoch[26] Batch [320-340]	Speed: 165763.20 samples/sec	accuracy=nan
2021-11-05 21:05:01,238 Node[0] Epoch[26] Batch [340-360]	Speed: 164092.55 samples/sec	accuracy=nan
2021-11-05 21:05:01,634 Node[0] Epoch[26] Batch [360-380]	Speed: 164981.03 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146301870, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 27}}
2021-11-05 21:05:01,870 Node[0] Epoch[26] Time cost=7.733
:::MLLOG {"namespace": "", "time_ms": 1636146301870, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165677.1104413379}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636146301870, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165677.1104413379, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146301887, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 27}}
2021-11-05 21:05:02,001 Node[0] Epoch[26] Validation-accuracy=0.737516
2021-11-05 21:05:02,001 Node[0] Epoch[26] Validation-correct-count=576.000000
2021-11-05 21:05:02,001 Node[0] Epoch[26] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146302022, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636146302022, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.72648, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636146302022, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1636146302022, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 28, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146302023, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 28}}
2021-11-05 21:05:02,418 Node[0] Epoch[27] Batch [0-20]	Speed: 167113.03 samples/sec	accuracy=nan
2021-11-05 21:05:02,813 Node[0] Epoch[27] Batch [20-40]	Speed: 165356.36 samples/sec	accuracy=nan
2021-11-05 21:05:03,208 Node[0] Epoch[27] Batch [40-60]	Speed: 165260.34 samples/sec	accuracy=nan
2021-11-05 21:05:03,601 Node[0] Epoch[27] Batch [60-80]	Speed: 165851.96 samples/sec	accuracy=nan
2021-11-05 21:05:03,993 Node[0] Epoch[27] Batch [80-100]	Speed: 166531.34 samples/sec	accuracy=nan
2021-11-05 21:05:04,387 Node[0] Epoch[27] Batch [100-120]	Speed: 165753.76 samples/sec	accuracy=nan
2021-11-05 21:05:04,780 Node[0] Epoch[27] Batch [120-140]	Speed: 166345.89 samples/sec	accuracy=nan
2021-11-05 21:05:05,173 Node[0] Epoch[27] Batch [140-160]	Speed: 165995.74 samples/sec	accuracy=nan
2021-11-05 21:05:05,567 Node[0] Epoch[27] Batch [160-180]	Speed: 165872.85 samples/sec	accuracy=nan
2021-11-05 21:05:05,961 Node[0] Epoch[27] Batch [180-200]	Speed: 165654.18 samples/sec	accuracy=nan
2021-11-05 21:05:06,354 Node[0] Epoch[27] Batch [200-220]	Speed: 165741.32 samples/sec	accuracy=nan
2021-11-05 21:05:06,746 Node[0] Epoch[27] Batch [220-240]	Speed: 166893.11 samples/sec	accuracy=nan
2021-11-05 21:05:07,139 Node[0] Epoch[27] Batch [240-260]	Speed: 166073.37 samples/sec	accuracy=nan
2021-11-05 21:05:07,534 Node[0] Epoch[27] Batch [260-280]	Speed: 165147.41 samples/sec	accuracy=nan
2021-11-05 21:05:07,928 Node[0] Epoch[27] Batch [280-300]	Speed: 165860.80 samples/sec	accuracy=nan
2021-11-05 21:05:08,322 Node[0] Epoch[27] Batch [300-320]	Speed: 165399.81 samples/sec	accuracy=nan
2021-11-05 21:05:08,718 Node[0] Epoch[27] Batch [320-340]	Speed: 164753.50 samples/sec	accuracy=nan
2021-11-05 21:05:09,117 Node[0] Epoch[27] Batch [340-360]	Speed: 163922.98 samples/sec	accuracy=nan
2021-11-05 21:05:09,514 Node[0] Epoch[27] Batch [360-380]	Speed: 164283.65 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146309749, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 28}}
2021-11-05 21:05:09,750 Node[0] Epoch[27] Time cost=7.727
:::MLLOG {"namespace": "", "time_ms": 1636146309750, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165803.81663128085}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 28}}
:::MLLOG {"namespace": "", "time_ms": 1636146309750, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165803.81663128085, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146309750, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 29}}
2021-11-05 21:05:10,164 Node[0] Epoch[28] Batch [0-20]	Speed: 165179.39 samples/sec	accuracy=nan
2021-11-05 21:05:10,557 Node[0] Epoch[28] Batch [20-40]	Speed: 166201.19 samples/sec	accuracy=nan
2021-11-05 21:05:10,950 Node[0] Epoch[28] Batch [40-60]	Speed: 165995.44 samples/sec	accuracy=nan
2021-11-05 21:05:11,343 Node[0] Epoch[28] Batch [60-80]	Speed: 166179.50 samples/sec	accuracy=nan
2021-11-05 21:05:11,737 Node[0] Epoch[28] Batch [80-100]	Speed: 165635.34 samples/sec	accuracy=nan
2021-11-05 21:05:12,129 Node[0] Epoch[28] Batch [100-120]	Speed: 166550.99 samples/sec	accuracy=nan
2021-11-05 21:05:12,522 Node[0] Epoch[28] Batch [120-140]	Speed: 166024.43 samples/sec	accuracy=nan
2021-11-05 21:05:12,918 Node[0] Epoch[28] Batch [140-160]	Speed: 165160.56 samples/sec	accuracy=nan
2021-11-05 21:05:13,312 Node[0] Epoch[28] Batch [160-180]	Speed: 165319.42 samples/sec	accuracy=nan
2021-11-05 21:05:13,707 Node[0] Epoch[28] Batch [180-200]	Speed: 165270.32 samples/sec	accuracy=nan
2021-11-05 21:05:14,103 Node[0] Epoch[28] Batch [200-220]	Speed: 165058.01 samples/sec	accuracy=nan
2021-11-05 21:05:14,494 Node[0] Epoch[28] Batch [220-240]	Speed: 166834.33 samples/sec	accuracy=nan
2021-11-05 21:05:14,889 Node[0] Epoch[28] Batch [240-260]	Speed: 165270.32 samples/sec	accuracy=nan
2021-11-05 21:05:15,287 Node[0] Epoch[28] Batch [260-280]	Speed: 164256.15 samples/sec	accuracy=nan
2021-11-05 21:05:15,679 Node[0] Epoch[28] Batch [280-300]	Speed: 166288.20 samples/sec	accuracy=nan
2021-11-05 21:05:16,076 Node[0] Epoch[28] Batch [300-320]	Speed: 164649.57 samples/sec	accuracy=nan
2021-11-05 21:05:16,471 Node[0] Epoch[28] Batch [320-340]	Speed: 165294.17 samples/sec	accuracy=nan
2021-11-05 21:05:16,866 Node[0] Epoch[28] Batch [340-360]	Speed: 164952.80 samples/sec	accuracy=nan
2021-11-05 21:05:17,265 Node[0] Epoch[28] Batch [360-380]	Speed: 163614.82 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146317502, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 29}}
2021-11-05 21:05:17,502 Node[0] Epoch[28] Time cost=7.752
:::MLLOG {"namespace": "", "time_ms": 1636146317502, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165273.67674637705}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 29}}
:::MLLOG {"namespace": "", "time_ms": 1636146317502, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165273.67674637705, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146317502, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 30}}
2021-11-05 21:05:17,916 Node[0] Epoch[29] Batch [0-20]	Speed: 165361.35 samples/sec	accuracy=nan
2021-11-05 21:05:18,308 Node[0] Epoch[29] Batch [20-40]	Speed: 166547.44 samples/sec	accuracy=nan
2021-11-05 21:05:18,701 Node[0] Epoch[29] Batch [40-60]	Speed: 165968.47 samples/sec	accuracy=nan
2021-11-05 21:05:19,094 Node[0] Epoch[29] Batch [60-80]	Speed: 166042.45 samples/sec	accuracy=nan
2021-11-05 21:05:19,487 Node[0] Epoch[29] Batch [80-100]	Speed: 166080.32 samples/sec	accuracy=nan
2021-11-05 21:05:19,879 Node[0] Epoch[29] Batch [100-120]	Speed: 166449.13 samples/sec	accuracy=nan
2021-11-05 21:05:20,271 Node[0] Epoch[29] Batch [120-140]	Speed: 166680.77 samples/sec	accuracy=nan
2021-11-05 21:05:20,665 Node[0] Epoch[29] Batch [140-160]	Speed: 165702.80 samples/sec	accuracy=nan
2021-11-05 21:05:21,058 Node[0] Epoch[29] Batch [160-180]	Speed: 166306.99 samples/sec	accuracy=nan
2021-11-05 21:05:21,455 Node[0] Epoch[29] Batch [180-200]	Speed: 164444.58 samples/sec	accuracy=nan
2021-11-05 21:05:21,846 Node[0] Epoch[29] Batch [200-220]	Speed: 166568.62 samples/sec	accuracy=nan
2021-11-05 21:05:22,238 Node[0] Epoch[29] Batch [220-240]	Speed: 166582.10 samples/sec	accuracy=nan
2021-11-05 21:05:22,633 Node[0] Epoch[29] Batch [240-260]	Speed: 165416.50 samples/sec	accuracy=nan
2021-11-05 21:05:23,025 Node[0] Epoch[29] Batch [260-280]	Speed: 166520.60 samples/sec	accuracy=nan
2021-11-05 21:05:23,420 Node[0] Epoch[29] Batch [280-300]	Speed: 165350.26 samples/sec	accuracy=nan
2021-11-05 21:05:23,815 Node[0] Epoch[29] Batch [300-320]	Speed: 165318.62 samples/sec	accuracy=nan
2021-11-05 21:05:24,210 Node[0] Epoch[29] Batch [320-340]	Speed: 165149.30 samples/sec	accuracy=nan
2021-11-05 21:05:24,608 Node[0] Epoch[29] Batch [340-360]	Speed: 163940.94 samples/sec	accuracy=nan
2021-11-05 21:05:25,006 Node[0] Epoch[29] Batch [360-380]	Speed: 164203.55 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146325241, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 30}}
2021-11-05 21:05:25,241 Node[0] Epoch[29] Time cost=7.739
:::MLLOG {"namespace": "", "time_ms": 1636146325241, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165552.63790537737}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 30}}
:::MLLOG {"namespace": "", "time_ms": 1636146325241, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165552.63790537737, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146325241, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 31}}
2021-11-05 21:05:25,653 Node[0] Epoch[30] Batch [0-20]	Speed: 166421.51 samples/sec	accuracy=nan
2021-11-05 21:05:26,046 Node[0] Epoch[30] Batch [20-40]	Speed: 166291.03 samples/sec	accuracy=nan
2021-11-05 21:05:26,441 Node[0] Epoch[30] Batch [40-60]	Speed: 165041.09 samples/sec	accuracy=nan
2021-11-05 21:05:26,833 Node[0] Epoch[30] Batch [60-80]	Speed: 166367.72 samples/sec	accuracy=nan
2021-11-05 21:05:27,227 Node[0] Epoch[30] Batch [80-100]	Speed: 166017.78 samples/sec	accuracy=nan
2021-11-05 21:05:27,620 Node[0] Epoch[30] Batch [100-120]	Speed: 165889.44 samples/sec	accuracy=nan
2021-11-05 21:05:28,015 Node[0] Epoch[30] Batch [120-140]	Speed: 165565.13 samples/sec	accuracy=nan
2021-11-05 21:05:28,407 Node[0] Epoch[30] Batch [140-160]	Speed: 166328.71 samples/sec	accuracy=nan
2021-11-05 21:05:28,800 Node[0] Epoch[30] Batch [160-180]	Speed: 166141.09 samples/sec	accuracy=nan
2021-11-05 21:05:29,193 Node[0] Epoch[30] Batch [180-200]	Speed: 166132.11 samples/sec	accuracy=nan
2021-11-05 21:05:29,587 Node[0] Epoch[30] Batch [200-220]	Speed: 165413.20 samples/sec	accuracy=nan
2021-11-05 21:05:29,982 Node[0] Epoch[30] Batch [220-240]	Speed: 165515.49 samples/sec	accuracy=nan
2021-11-05 21:05:30,374 Node[0] Epoch[30] Batch [240-260]	Speed: 166693.35 samples/sec	accuracy=nan
2021-11-05 21:05:30,767 Node[0] Epoch[30] Batch [260-280]	Speed: 166017.68 samples/sec	accuracy=nan
2021-11-05 21:05:31,160 Node[0] Epoch[30] Batch [280-300]	Speed: 166110.65 samples/sec	accuracy=nan
2021-11-05 21:05:31,553 Node[0] Epoch[30] Batch [300-320]	Speed: 165864.92 samples/sec	accuracy=nan
2021-11-05 21:05:31,950 Node[0] Epoch[30] Batch [320-340]	Speed: 164402.41 samples/sec	accuracy=nan
2021-11-05 21:05:32,344 Node[0] Epoch[30] Batch [340-360]	Speed: 165751.45 samples/sec	accuracy=nan
2021-11-05 21:05:32,740 Node[0] Epoch[30] Batch [360-380]	Speed: 165051.44 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146332976, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 31}}
2021-11-05 21:05:32,976 Node[0] Epoch[30] Time cost=7.735
:::MLLOG {"namespace": "", "time_ms": 1636146332976, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165632.6410474229}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636146332977, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165632.6410474229, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146332993, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 31}}
2021-11-05 21:05:33,106 Node[0] Epoch[30] Validation-accuracy=0.759283
2021-11-05 21:05:33,106 Node[0] Epoch[30] Validation-correct-count=593.000000
2021-11-05 21:05:33,107 Node[0] Epoch[30] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146333125, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636146333126, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.75156, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636146333126, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1636146333126, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 32, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146333126, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 32}}
2021-11-05 21:05:33,522 Node[0] Epoch[31] Batch [0-20]	Speed: 166666.56 samples/sec	accuracy=nan
2021-11-05 21:05:33,919 Node[0] Epoch[31] Batch [20-40]	Speed: 164468.08 samples/sec	accuracy=nan
2021-11-05 21:05:34,313 Node[0] Epoch[31] Batch [40-60]	Speed: 165704.01 samples/sec	accuracy=nan
2021-11-05 21:05:34,706 Node[0] Epoch[31] Batch [60-80]	Speed: 166212.59 samples/sec	accuracy=nan
2021-11-05 21:05:35,098 Node[0] Epoch[31] Batch [80-100]	Speed: 166353.87 samples/sec	accuracy=nan
2021-11-05 21:05:35,491 Node[0] Epoch[31] Batch [100-120]	Speed: 166313.55 samples/sec	accuracy=nan
2021-11-05 21:05:35,882 Node[0] Epoch[31] Batch [120-140]	Speed: 166728.98 samples/sec	accuracy=nan
2021-11-05 21:05:36,275 Node[0] Epoch[31] Batch [140-160]	Speed: 166369.84 samples/sec	accuracy=nan
2021-11-05 21:05:36,666 Node[0] Epoch[31] Batch [160-180]	Speed: 166618.90 samples/sec	accuracy=nan
2021-11-05 21:05:37,059 Node[0] Epoch[31] Batch [180-200]	Speed: 166374.19 samples/sec	accuracy=nan
2021-11-05 21:05:37,451 Node[0] Epoch[31] Batch [200-220]	Speed: 166531.44 samples/sec	accuracy=nan
2021-11-05 21:05:37,845 Node[0] Epoch[31] Batch [220-240]	Speed: 165477.48 samples/sec	accuracy=nan
2021-11-05 21:05:38,239 Node[0] Epoch[31] Batch [240-260]	Speed: 165978.74 samples/sec	accuracy=nan
2021-11-05 21:05:38,633 Node[0] Epoch[31] Batch [260-280]	Speed: 165531.90 samples/sec	accuracy=nan
2021-11-05 21:05:39,026 Node[0] Epoch[31] Batch [280-300]	Speed: 166150.56 samples/sec	accuracy=nan
2021-11-05 21:05:39,419 Node[0] Epoch[31] Batch [300-320]	Speed: 166036.61 samples/sec	accuracy=nan
2021-11-05 21:05:39,815 Node[0] Epoch[31] Batch [320-340]	Speed: 164681.36 samples/sec	accuracy=nan
2021-11-05 21:05:40,214 Node[0] Epoch[31] Batch [340-360]	Speed: 163621.08 samples/sec	accuracy=nan
2021-11-05 21:05:40,611 Node[0] Epoch[31] Batch [360-380]	Speed: 164635.81 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146340846, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 32}}
2021-11-05 21:05:40,847 Node[0] Epoch[31] Time cost=7.721
:::MLLOG {"namespace": "", "time_ms": 1636146340847, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165937.21394311325}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 32}}
:::MLLOG {"namespace": "", "time_ms": 1636146340847, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165937.21394311325, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146340847, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 33}}
2021-11-05 21:05:41,258 Node[0] Epoch[32] Batch [0-20]	Speed: 166472.71 samples/sec	accuracy=nan
2021-11-05 21:05:41,651 Node[0] Epoch[32] Batch [20-40]	Speed: 166486.18 samples/sec	accuracy=nan
2021-11-05 21:05:42,043 Node[0] Epoch[32] Batch [40-60]	Speed: 166196.35 samples/sec	accuracy=nan
2021-11-05 21:05:42,435 Node[0] Epoch[32] Batch [60-80]	Speed: 166526.48 samples/sec	accuracy=nan
2021-11-05 21:05:42,829 Node[0] Epoch[32] Batch [80-100]	Speed: 166044.16 samples/sec	accuracy=nan
2021-11-05 21:05:43,221 Node[0] Epoch[32] Batch [100-120]	Speed: 166212.09 samples/sec	accuracy=nan
2021-11-05 21:05:43,613 Node[0] Epoch[32] Batch [120-140]	Speed: 166797.64 samples/sec	accuracy=nan
2021-11-05 21:05:44,006 Node[0] Epoch[32] Batch [140-160]	Speed: 166075.38 samples/sec	accuracy=nan
2021-11-05 21:05:44,397 Node[0] Epoch[32] Batch [160-180]	Speed: 166910.30 samples/sec	accuracy=nan
2021-11-05 21:05:44,790 Node[0] Epoch[32] Batch [180-200]	Speed: 165817.00 samples/sec	accuracy=nan
2021-11-05 21:05:45,184 Node[0] Epoch[32] Batch [200-220]	Speed: 165778.25 samples/sec	accuracy=nan
2021-11-05 21:05:45,579 Node[0] Epoch[32] Batch [220-240]	Speed: 165487.58 samples/sec	accuracy=nan
2021-11-05 21:05:45,971 Node[0] Epoch[32] Batch [240-260]	Speed: 166584.94 samples/sec	accuracy=nan
2021-11-05 21:05:46,363 Node[0] Epoch[32] Batch [260-280]	Speed: 166284.06 samples/sec	accuracy=nan
2021-11-05 21:05:46,759 Node[0] Epoch[32] Batch [280-300]	Speed: 164962.54 samples/sec	accuracy=nan
2021-11-05 21:05:47,154 Node[0] Epoch[32] Batch [300-320]	Speed: 165178.79 samples/sec	accuracy=nan
2021-11-05 21:05:47,549 Node[0] Epoch[32] Batch [320-340]	Speed: 165437.58 samples/sec	accuracy=nan
2021-11-05 21:05:47,946 Node[0] Epoch[32] Batch [340-360]	Speed: 164438.75 samples/sec	accuracy=nan
2021-11-05 21:05:48,343 Node[0] Epoch[32] Batch [360-380]	Speed: 164330.29 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146348581, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 33}}
2021-11-05 21:05:48,581 Node[0] Epoch[32] Time cost=7.734
:::MLLOG {"namespace": "", "time_ms": 1636146348581, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165651.99772163932}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 33}}
:::MLLOG {"namespace": "", "time_ms": 1636146348581, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165651.99772163932, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146348581, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 34}}
2021-11-05 21:05:48,994 Node[0] Epoch[33] Batch [0-20]	Speed: 166237.72 samples/sec	accuracy=nan
2021-11-05 21:05:49,389 Node[0] Epoch[33] Batch [20-40]	Speed: 164995.05 samples/sec	accuracy=nan
2021-11-05 21:05:49,781 Node[0] Epoch[33] Batch [40-60]	Speed: 166656.83 samples/sec	accuracy=nan
2021-11-05 21:05:50,174 Node[0] Epoch[33] Batch [60-80]	Speed: 166041.34 samples/sec	accuracy=nan
2021-11-05 21:05:50,566 Node[0] Epoch[33] Batch [80-100]	Speed: 166468.97 samples/sec	accuracy=nan
2021-11-05 21:05:50,959 Node[0] Epoch[33] Batch [100-120]	Speed: 166347.40 samples/sec	accuracy=nan
2021-11-05 21:05:51,351 Node[0] Epoch[33] Batch [120-140]	Speed: 166509.67 samples/sec	accuracy=nan
2021-11-05 21:05:51,743 Node[0] Epoch[33] Batch [140-160]	Speed: 166412.41 samples/sec	accuracy=nan
2021-11-05 21:05:52,137 Node[0] Epoch[33] Batch [160-180]	Speed: 165878.38 samples/sec	accuracy=nan
2021-11-05 21:05:52,531 Node[0] Epoch[33] Batch [180-200]	Speed: 165566.03 samples/sec	accuracy=nan
2021-11-05 21:05:52,925 Node[0] Epoch[33] Batch [200-220]	Speed: 165865.52 samples/sec	accuracy=nan
2021-11-05 21:05:53,318 Node[0] Epoch[33] Batch [220-240]	Speed: 166052.52 samples/sec	accuracy=nan
2021-11-05 21:05:53,709 Node[0] Epoch[33] Batch [240-260]	Speed: 166812.17 samples/sec	accuracy=nan
2021-11-05 21:05:54,102 Node[0] Epoch[33] Batch [260-280]	Speed: 166185.56 samples/sec	accuracy=nan
2021-11-05 21:05:54,495 Node[0] Epoch[33] Batch [280-300]	Speed: 166150.76 samples/sec	accuracy=nan
2021-11-05 21:05:54,889 Node[0] Epoch[33] Batch [300-320]	Speed: 165565.63 samples/sec	accuracy=nan
2021-11-05 21:05:55,284 Node[0] Epoch[33] Batch [320-340]	Speed: 165160.26 samples/sec	accuracy=nan
2021-11-05 21:05:55,683 Node[0] Epoch[33] Batch [340-360]	Speed: 163897.96 samples/sec	accuracy=nan
2021-11-05 21:05:56,080 Node[0] Epoch[33] Batch [360-380]	Speed: 164307.01 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146356314, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 34}}
2021-11-05 21:05:56,315 Node[0] Epoch[33] Time cost=7.733
:::MLLOG {"namespace": "", "time_ms": 1636146356315, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165673.03427797765}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 34}}
:::MLLOG {"namespace": "", "time_ms": 1636146356315, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165673.03427797765, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146356315, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 35}}
2021-11-05 21:05:56,730 Node[0] Epoch[34] Batch [0-20]	Speed: 164918.62 samples/sec	accuracy=nan
2021-11-05 21:05:57,124 Node[0] Epoch[34] Batch [20-40]	Speed: 165880.79 samples/sec	accuracy=nan
2021-11-05 21:05:57,516 Node[0] Epoch[34] Batch [40-60]	Speed: 166549.47 samples/sec	accuracy=nan
2021-11-05 21:05:57,910 Node[0] Epoch[34] Batch [60-80]	Speed: 165693.98 samples/sec	accuracy=nan
2021-11-05 21:05:58,301 Node[0] Epoch[34] Batch [80-100]	Speed: 166703.60 samples/sec	accuracy=nan
2021-11-05 21:05:58,695 Node[0] Epoch[34] Batch [100-120]	Speed: 165787.69 samples/sec	accuracy=nan
2021-11-05 21:05:59,087 Node[0] Epoch[34] Batch [120-140]	Speed: 166406.75 samples/sec	accuracy=nan
2021-11-05 21:05:59,480 Node[0] Epoch[34] Batch [140-160]	Speed: 166393.80 samples/sec	accuracy=nan
2021-11-05 21:05:59,873 Node[0] Epoch[34] Batch [160-180]	Speed: 165989.10 samples/sec	accuracy=nan
2021-11-05 21:06:00,265 Node[0] Epoch[34] Batch [180-200]	Speed: 166267.40 samples/sec	accuracy=nan
2021-11-05 21:06:00,658 Node[0] Epoch[34] Batch [200-220]	Speed: 166452.68 samples/sec	accuracy=nan
2021-11-05 21:06:01,051 Node[0] Epoch[34] Batch [220-240]	Speed: 165936.69 samples/sec	accuracy=nan
2021-11-05 21:06:01,444 Node[0] Epoch[34] Batch [240-260]	Speed: 166032.78 samples/sec	accuracy=nan
2021-11-05 21:06:01,835 Node[0] Epoch[34] Batch [260-280]	Speed: 166890.67 samples/sec	accuracy=nan
2021-11-05 21:06:02,227 Node[0] Epoch[34] Batch [280-300]	Speed: 166641.10 samples/sec	accuracy=nan
2021-11-05 21:06:02,624 Node[0] Epoch[34] Batch [300-320]	Speed: 164627.89 samples/sec	accuracy=nan
2021-11-05 21:06:03,018 Node[0] Epoch[34] Batch [320-340]	Speed: 165711.83 samples/sec	accuracy=nan
2021-11-05 21:06:03,416 Node[0] Epoch[34] Batch [340-360]	Speed: 163886.09 samples/sec	accuracy=nan
2021-11-05 21:06:03,812 Node[0] Epoch[34] Batch [360-380]	Speed: 164620.46 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146364048, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 35}}
2021-11-05 21:06:04,048 Node[0] Epoch[34] Time cost=7.733
:::MLLOG {"namespace": "", "time_ms": 1636146364048, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165669.17283454214}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636146364049, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165669.17283454214, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146364065, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 35}}
2021-11-05 21:06:04,176 Node[0] Epoch[34] Validation-accuracy=0.758003
2021-11-05 21:06:04,176 Node[0] Epoch[34] Validation-correct-count=592.000000
2021-11-05 21:06:04,176 Node[0] Epoch[34] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146364196, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636146364196, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.75962, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636146364196, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1636146364196, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1051, "status": "success"}}
ENDING TIMING RUN AT 2021-11-05 09:06:23 PM
RESULT,IMAGE_CLASSIFICATION,,427,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:23 PM
RESULT,IMAGE_CLASSIFICATION,,427,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:25 PM
RESULT,IMAGE_CLASSIFICATION,,429,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:26 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:26 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:26 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:26 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:26 PM
ENDING TIMING RUN AT 2021-11-05 09:06:26 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:59:16 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:26 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:26 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:26 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:26 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:26 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:26 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:26 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:27 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:27 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:27 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:28 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:28 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:28 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:28 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:28 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:28 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:29 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:29 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:29 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:29 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:29 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:29 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:29 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:29 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:29 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:29 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:29 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:30 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:30 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:30 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:30 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:30 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:30 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:30 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:32 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:32 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:32 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:32 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:32 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:32 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:32 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:32 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:32 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:32 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:32 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:32 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:33 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:33 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:33 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:33 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:33 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:33 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:33 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:33 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:59:16 PM
ENDING TIMING RUN AT 2021-11-05 09:06:34 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:59:16 PM
